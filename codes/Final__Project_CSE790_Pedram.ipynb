{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYgCu5pZi53t",
        "outputId": "35aafcca-00ac-41e8-f9e2-0ab50e7d6ce6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  2 05:13:37 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    42W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfOE4LHHi7X3",
        "outputId": "993fa9c3-6c1a-45e9-eaa8-55e150877ab1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-a83e8acc-4764-04db-53fc-95a53281813b)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AZbmPRrJW0KY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from math import ceil\n",
        "\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
        "\n",
        "\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "from keras import models\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Add, AveragePooling2D, ReLU\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "from bayes_opt import BayesianOptimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0x1uC6DA7P9",
        "outputId": "de0a6734-a0f3-43ac-bd89-da4a54440b1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "print(type(y_train))\n",
        "print(y_train.ndim)  # should output 2\n",
        "print(y_train.shape) # should output (50000, 1)\n",
        "\n",
        "print(type(y_test))\n",
        "print(y_test.ndim)  # should output 2\n",
        "print(y_test.shape) # should output (10000, 1)\n",
        "\n",
        "print(X_train.ndim)  # should output 4\n",
        "print(X_train.shape) # should output (50000, 32, 32, 3)\n",
        "\n",
        "print(X_test.ndim)  # should output 4\n",
        "print(X_test.shape) # should output (10000, 32, 32, 3)\n",
        "\n",
        "X_train = X_train.astype('float64') / 255.0\n",
        "X_test = X_test.astype('float64') / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qglu3CqLqBSb",
        "outputId": "7baa23fd-584f-4c68-d051-4d6067be0d51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n",
            "<class 'numpy.ndarray'>\n",
            "2\n",
            "(50000, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "2\n",
            "(10000, 1)\n",
            "4\n",
            "(50000, 32, 32, 3)\n",
            "4\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image as a NumPy array\n",
        "image_array = X_train[5036,:,:,:]\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(image_array)\n",
        "plt.show()\n",
        "\n",
        "# Reshape the image to a 4D tensor with dimensions (batch_size, height, width, channels)\n",
        "# image_tensor = np.reshape(image_array, (1, 32, 32, 3))\n",
        "# Normalize the pixel values to be in the range [0, 1] and convert the data type to float32\n",
        "# image_tensor = image_tensor.astype('float32') / 255.0\n",
        "\n",
        "# Check the shape and data type of the image tensor\n",
        "print(\"Image tensor shape:\", image_array.shape)\n",
        "print(\"Image tensor data type:\", image_array.dtype)\n",
        "print(\"image_tensor type\",type(image_array))"
      ],
      "metadata": {
        "id": "3wyozWNbX-lP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "ad0b383b-3924-4e53-b9de-09c54cf6dcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwuUlEQVR4nO3de3Cc9X3v8c/uand1X1mWdcOSkW2wAV+SOGB0CK7BLrZ7ykDw6UCSc2JSDgxUZgpumsSdBAJtR5TMJCQZx/xRipuZGBJ6YjhwiimYWDSt7cQujrkkqu0ILGNJvupiSXvR7nP+oKhVsPHva0v+WeL9mtkZS/v1V79nn2f3q0e7+9lQEASBAAA4z8K+FwAA+HhiAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvMjzvYDflcvldOjQIZWUlCgUCvleDgDAKAgC9fX1qba2VuHw6c9zLrgBdOjQIdXV1fleBgDgHLW3t2vq1KmnvX7MBtC6dev0rW99S52dnZo/f76+//3v66qrrjrj/yspKXl/YYWF7mdAhjShcMT2V8e6umnOtcuW32jqvbDxvznXFhSVmHof6jrqXDtjhvs2SpJCtsPm3YPHnWt/ue01U+9f/eIV59ruY+63iSTVT2twrr3jf/9vU+9XXt1iqn/7rbeda0M5W7rWdYuuca7NLygy9Q7ixc61hzM5U+8X/9//da7N9bSbevflUqb6oQHD40ouY+o9OHjSuTZqfEhPxN0fVyrKKpxrs9msWvfuGX48P50xGUA//vGPtWbNGj3++ONauHChHnvsMS1btkytra2qrKz8yP/7wdAJhUJj8ic4a89IJOJcG4/HTb0LC93vzAVF7ndkSSooHHCuLSq29bYOoIJC9ztzLJ5v6h3Jc19L2LAvJSkvL+pcW1hYaOodi9mOlTzDdloHkOW4zc+37Z8gXuC+johtAIUNt4mM+z4Usv2iGvqIPzN9mLW3+2NWKLA9vn3Un8d+l+Wx8ANnerwdkxchfPvb39add96pL33pS7r88sv1+OOPq7CwUH/3d383Fj8OADAOjfoASqfT2rVrl5YuXfqfPyQc1tKlS7Vt27YP1adSKfX29o64AAAmvlEfQEePHlU2m1VVVdWI71dVVamzs/ND9c3NzUokEsMXXoAAAB8P3t8HtHbtWvX09Axf2tttTxYCAManUX8RQkVFhSKRiLq6ukZ8v6urS9XV1R+qj8fj5ifvAQDj36ifAcViMS1YsEBbtvzny0xzuZy2bNmixsbG0f5xAIBxakxehr1mzRqtWrVKn/70p3XVVVfpscceU39/v770pS+NxY8DAIxDYzKAbr31Vh05ckQPPPCAOjs79YlPfEKbN2/+0AsTAAAfX2OWhLB69WqtXr36rP9/UUm+85u7AkMSgvWNqMe7jzjX/uyVF029u48fdq698mr3d6tL0lTDu/hjYdsbF43v0ZOG3N8Ue/DdvabWx490nbnoPwwm3d9RLklJw7oLi41vLDW+6TKbTTvXFhWWmnqHw5Y3GNqOlekN7ikbwRH3xAxJutzQO3nUdr/vGOg21UemuL+pPEgNmnofO+p+jIeHbNs559IrnGuvMNSm0im9/ZvXz1jn/VVwAICPJwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAizGL4jlXefkx588rHxoacu5rqZUkZTPOpT0n3KN1JGnnL/7VuTaZtsV3fO4Lq5xrw0HW1DvI2uI+8mPutaVFtkibmOFz6pMR2+9bIcO9IxyyRdTE82xrSQ26xwIlU6bWOnqi27m2IBY19Z4RuEcOHTt0wNS7fvIk59rZn7zc1PtX771jqj/Q/uEP2zyd/sPu8V6SFCkrd669qOoiU+9Pzv2Uc+0ll8x2rh10PF45AwIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4ccFmwc2d9ynlRd1yp3I59yyzY8eOm9Zx/Kh7blNeYMsDS2XSzrWRPNuuKiktca7N5mzZbiHHjL4P5BfmO9eWJBLGtbhnkwVh222YGXI/rgLZbsM8w7olqaTQfX9Ovmi6qXdZ+WTn2lzKPZNOkooK3LP90n0nTL2nFLr3/sSsK0y9j+dsmZG/+tXbzrU9h22ZkQVx9zDFTy5YYOpdWVHlXHu8r9e5Npl0y67kDAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MUFG8XzP//XH6uwsMipNhKJOPf91a/2mNbx/P/d5Fx7tOOgqXdBkSFi48qFpt4VNTXOtUeP9Jl6B4HxsIm6b2dR2SRT68LSCufaoZgt/qagyD0WKCRrtE6Zqb62ut659hON15h6Ty51j0rqPdJh6l1aUuy+juJCU+++A+861/7bth2m3u/1HjXVZwyxWuGo7ff+rHLOtV3HbeseNMRN7XnDPW5oKJNxquMMCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFBZsFp3CBFClwKq2YMsW57cXTk6ZllJZOdq7tOX7M1Hv25XOdaz915dWm3kHYPX8tCNtyzLLu0VTv9w+FnGvr6t0zzyTpuqW/71zb299r6l1WVupcm59fYup9ccNMU/2eN1uda//55z839f7knEudaxtqK029J5W55+lVlttyAP/5//zUufa3pQdMvZd+6X+Z6q+9YYVzbVvrb0y9X3nln5xr2zsPmXqHjhx2rv1te5tzbS7rljHHGRAAwItRH0Df/OY3FQqFRlxmz5492j8GADDOjcmf4K644gq98sor//lD8i7cv/QBAPwYk8mQl5en6urqsWgNAJggxuQ5oL1796q2tlbTp0/XF77wBR04cPonAFOplHp7e0dcAAAT36gPoIULF2rDhg3avHmz1q9fr7a2Nl177bXq6zv1p242NzcrkUgMX+rq6kZ7SQCAC9CoD6AVK1boj/7ojzRv3jwtW7ZM//iP/6ju7m795Cc/OWX92rVr1dPTM3xpb28f7SUBAC5AY/7qgLKyMl166aXat2/fKa+Px+OKx+NjvQwAwAVmzN8HdPLkSe3fv181NTVj/aMAAOPIqA+gL3/5y2ppadE777yjf/3Xf9VnP/tZRSIRfe5znxvtHwUAGMdG/U9wBw8e1Oc+9zkdO3ZMU6ZM0Wc+8xlt375dUwxxOZL0f55/UdGY25/mLq67yLlvPGrb5GjMPdImUZhv6n1pQ4NzbVmxe6SJJCX7Us612XTa1DuXGzLV5ytwrp0xtdbUe5Zh3w/l3NchSQq5/34WyouYWl80033fS9KVi9yjmJ7f/JKp98mBk861ZZMvM/UuyHe//8SMEU/Hj7u/YjadV2zqXVBYbqrPhdyjmPqzttimXNh97VUXVZl6Hz7S6VxbXOoWjSZJ2SG3x4hRH0BPP/30aLcEAExAZMEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALwY849jOFvZ7JDCWbd8rfYD7zr3DQVZ0zoaptU7115SU2rqXVPhnjfVd+yIqXcozz23KU+2EK6QLfZM+aGoc20kZsvJilh+hTKsQ5Iyhuy4rPG4ihoy0iTp01df6VybX2LMPTPkIyYmlZl6DwwMONd2n+gy9U4k3Hf+iX7b/ael5RVT/cET7tv5XscJU28N9TuXziu03X+ikcPutYb7WtixljMgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXF2wUT1V5QrF43Kk2l0459+0+ccy0josqa5xry/Inm3rHY+43/1DypKl3SYl77EysuNDUO5Jn+70lyA451w6l3CNNJCma554LlFPI1PvIiR7n2qyttSIxWxRPyDXbRNK8uXNNvfPkHjlUYLi9Jam3t9e5NptNmnov+NRlzrXtxwdNvQe6j5rqe7rct/PYIVssUNkk9/tnPO4ewSVJpYXu8WED+e4RQkNDbvd5zoAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXlywWXA9RzoUdczLKil0zz8KZWyZUMePdDrXTpleZ+pdP63euXZyosTUu6Ag37k2HLEFmWUD92y39/tnnWszIVvvaMg9xywXsv2+FTesuz9jW3cgW6ZaZsh9O/Mitpy5gkL3rLGCPNuxkh7od66dMWO2qffsadOdaweGbPu+tc39fi9JXe2/cK5NHn3P1FvF7nmUhYb7vSRVVVY71+ZlMs616XTaqY4zIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXF2wW3Dt731Ykz215xYb8o+7jR0zrGJx6kXPtJz8xz9T7ovoG59p4QZGpdywed64Nsm65TR9ID/Sa6pOppHNtzJhLN9Dvnu0XitoO95IC90y1XNg9q02S+jMpU30m5367hIy/VwZBzrk2F9h65xuOw2kzrjD1fvfff+tc2/Gee60k1ZS650tKUl2hexZga6rD1DuadX98i0VNrVU4pcK5tiDivu9TKbfjmzMgAIAX5gH02muv6cYbb1Rtba1CoZCeffbZEdcHQaAHHnhANTU1Kigo0NKlS7V3797RWi8AYIIwD6D+/n7Nnz9f69atO+X1jz76qL73ve/p8ccf144dO1RUVKRly5YpmXT/MwwAYOIzPwe0YsUKrVix4pTXBUGgxx57TF//+td10003SZJ++MMfqqqqSs8++6xuu+22c1stAGDCGNXngNra2tTZ2amlS5cOfy+RSGjhwoXatm3bKf9PKpVSb2/viAsAYOIb1QHU2fn+pwhWVVWN+H5VVdXwdb+rublZiURi+FJXZ/tUUQDA+OT9VXBr165VT0/P8KW9vd33kgAA58GoDqDq6vc/X7yrq2vE97u6uoav+13xeFylpaUjLgCAiW9UB1BDQ4Oqq6u1ZcuW4e/19vZqx44damxsHM0fBQAY58yvgjt58qT27ds3/HVbW5t2796t8vJy1dfX67777tNf/dVf6ZJLLlFDQ4O+8Y1vqLa2VjfffPNorhsAMM6ZB9DOnTt13XXXDX+9Zs0aSdKqVau0YcMGfeUrX1F/f7/uuusudXd36zOf+Yw2b96s/Hz3OAlJ+tS8OYrF3KJQujrec+5bUeIeryJJddOmO9eWVU019Q7Fi51rgzzbukMR9/pQzhbFM9B7wlS/t/U3zrWZ1ICpd9YQaVPf4B59JEk1De77vrDAPXJGklIp9+gWSRpMuten07b9mXSMTZGkUNb2R5PCfMPtErfFTU2ud9/Offt2mXpPCmy34R9ee+qnGE6lovgyU++OwD0WqMCWIKRERaVzbV7FFOfawQG3iCzzAFq8eLGC4PS5V6FQSA8//LAefvhha2sAwMeI91fBAQA+nhhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL8xRPOfLwk/PU4FjsFFbW4lz3yCXNa2jwpDvVjqp3NQ7Eo0614bDEVPv3EfEJX2oNu2eBSZJe3/9lqn+pc0vOtcWFNgyAwcH3LPjyt/+tan3bV/8onNt8ZQaU+9MxH3/SNJg+qR7b2POXLLf/TYsLC409Y4VuoeT5UK2Y3xSdYVz7YwrZpl6Dx7cYaqf0+Ce6zhp8lxT73/+bZ9z7cCA7ROls8eOO9eW5rnfN5ODbllwnAEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALy4YKN4jh1vV35+3Kk2E7hHVWQD28yNl7hHiRQWukfrSFI45B4LFGRzpt6WXZtJucVmfODfW1tN9W3vHnCujeXbol6Gcu63S3/GFn/T2+t+u5RW2vZ9nmyRUAUxt/uCJAXGKJ60Ic5I+TFTb4UMt7mlVlIo4n6blNXaonhSve7HrCQd7zvoXDsQJE29B4K0c+27b7xh6n20yz1yqC7hHjWWyWSc6jgDAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhxwWbBnRw8oqHALXcqbIjhKsx3zzOSpJJEwrk2HLZlWeVybnlJkmSNggvnue/avpP9pt4DQ7bF9Ltvpv69vc3UOxrLd64tKikz9e7ucc8YnGrb9QoFtv8Qy3P/XTEocL9NJGkoa8ilC6yZhO7bmR1yzzyTpFw25FybXzzJ1Ltgcr2pvuvIYefagSFbbuCkyZXOtT3GB4ps0r2+qMi9b9pxV3IGBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADw4oKN4glCA8qFHDNcwm6RPZKUF7dtcijsHvcxNGTInJGUCUeca/PCxnWH3CNQ3ut0jxGRpH3vHjLVv3vIvf9g2hYlkht0jxHa83arqffhI8eca7M5Q5yNpCA7ZKqXoT4atf1eGTLU9/f3mnoXlRUaqm3xREHOvT4Std1/wsVTTPWHu9wju3KB+2OKJBUVFzjX1hm3s3aKe0RRLOselZRMutVyBgQA8IIBBADwwjyAXnvtNd14442qra1VKBTSs88+O+L622+/XaFQaMRl+fLlo7VeAMAEYR5A/f39mj9/vtatW3famuXLl6ujo2P48tRTT53TIgEAE4/5RQgrVqzQihUrPrImHo+rurr6rBcFAJj4xuQ5oK1bt6qyslKzZs3SPffco2PHTv9qolQqpd7e3hEXAMDEN+oDaPny5frhD3+oLVu26G/+5m/U0tKiFStWKHuaT11sbm5WIpEYvtTV1Y32kgAAF6BRfx/QbbfdNvzvuXPnat68eZoxY4a2bt2qJUuWfKh+7dq1WrNmzfDXvb29DCEA+BgY85dhT58+XRUVFdq3b98pr4/H4yotLR1xAQBMfGM+gA4ePKhjx46ppqZmrH8UAGAcMf8J7uTJkyPOZtra2rR7926Vl5ervLxcDz30kFauXKnq6mrt379fX/nKVzRz5kwtW7ZsVBcOABjfzANo586duu6664a//uD5m1WrVmn9+vXas2eP/v7v/17d3d2qra3VDTfcoL/8y79UPB43riz3/sVBJOJ+IpeVLbMrmU461/YP9Jl6h3Lu+V75BSWm3r29J5xrO7q6TL1P9J401WcM8W6RqO04yQ6578+hnC2DS5Goc2kymTK1zo1hFtyQLVJNg4Y8ve7DtmMlHHe/bxaVFJt65wL3h6/MkC1jMIhYMuyk3lyRc+3xox2m3rnA/XElabmzScpm3B/fQkPutem02/FqHkCLFy9WEJz+CH/ppZesLQEAH0NkwQEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvBj1zwMaLel0oFDYLdRqKDBkFGVtOWbdfceda2P57nlQkhRJTHKuLQhHTL0PHzzkXPtO235T78svu8y2liNHnWsPHuo09a6prnKuXXztNabeRSXuHw1y4oR79p4kFRbYMu8GB9zz2oYitrv1UDbjXJsLbBl2hzoOOtdOHppi6l1QUOZenLX9rl0Qj9nqi93vy33taVPvkNwf34KcLQsuN+S+72U4TrKO2YWcAQEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvLhgo3g6u3oUi7ktbzDjHm2RXzBgWkc25x6ZEovZonjiEfd4nVDGEJkh6Z13futc+97BdlPvP/jvf2iqr6iY7Fz7/17cbOr9mWsXO9f+j//xR6beu3b90r34oHvkjCRVVpab6g91djjXllZVm3qnB91jfvLzbRFCyeSgc+2xE+6xV5JUHoo61+ZHC0y947bkK+VH3dcSOEaMDdfn3O/7oVzW1DscuK8lCLmfr4QcazkDAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhxwWbB/fIX+xSJuM3HwfRJ5775BfmmdcyY2edcO5TJmXqn+nqda8sKik293zvwjnNtOBQy9Z528QxT/SWzLneuTUxyz42TpFmz3XvX1Naaeg+0uO/7Q+/uNfXurbXltXUeO+Jce1mp7VjpP9njXFucb7v/5IXdH2LSg7acxqGUe85ctMCW05hnzI4rKCx0X0ssZuqdSbnXDhmz4IKcIQtO7o8TGceMOc6AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeXLBRPAcPHFHIMSKmqDjq3NcSDSJJXR0HnWsHB90jgSTpaHWdc21hyBaB0r7vXefa2qkzTb0T5VWm+uJi92iYaxddZ+odyXPfn9msLaakqMA9MqXlF9tNvQ9OqTDVV9XVO9cmT7pHPElSOu0eaZPOi5h658m9PhzY9k8kyDjXxqLujxGSFI7b7m+Jye77s6jQFgvUnTzhXJsNbLFa6az7bRh2jEaTpIzc9iVnQAAAL0wDqLm5WVdeeaVKSkpUWVmpm2++Wa2trSNqksmkmpqaNHnyZBUXF2vlypXq6uoa1UUDAMY/0wBqaWlRU1OTtm/frpdfflmZTEY33HCD+vv7h2vuv/9+Pf/883rmmWfU0tKiQ4cO6ZZbbhn1hQMAxjfTEyKbN28e8fWGDRtUWVmpXbt2adGiRerp6dETTzyhjRs36vrrr5ckPfnkk7rsssu0fft2XX311aO3cgDAuHZOzwH19Lz/OSLl5eWSpF27dimTyWjp0qXDNbNnz1Z9fb22bdt2yh6pVEq9vb0jLgCAie+sB1Aul9N9992na665RnPmzJEkdXZ2KhaLqaysbERtVVWVOjs7T9mnublZiURi+FJX5/7KMADA+HXWA6ipqUlvvvmmnn766XNawNq1a9XT0zN8aW9vP6d+AIDx4azeB7R69Wq98MILeu211zR16tTh71dXVyudTqu7u3vEWVBXV5eqq0/9EcTxeFzxePxslgEAGMdMZ0BBEGj16tXatGmTXn31VTU0NIy4fsGCBYpGo9qyZcvw91pbW3XgwAE1NjaOzooBABOC6QyoqalJGzdu1HPPPaeSkpLh53USiYQKCgqUSCR0xx13aM2aNSovL1dpaanuvfdeNTY28go4AMAIpgG0fv16SdLixYtHfP/JJ5/U7bffLkn6zne+o3A4rJUrVyqVSmnZsmX6wQ9+MCqLBQBMHKYBFATBGWvy8/O1bt06rVu37qwXJUmzL69TxDF3qq7+1M8vncqkclsOU9gQfTWQTJl6Dw70ONe+9dabpt5H33PPjyopn3rmov8ikxsy1Svink9VXOqeGydJ/f0DzrUDg/1nLvovyhKlzrWHOt4z9T7R7b5/JGnmZZc71w4MuGe7SVIszz3zLjlo6x2Puj+/W1Jky1+LG/Ld4jHb88yBIWNQksKOuZWSFDX2zmTc72+hsPF1ZYZ1jwWy4AAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXpzVxzGcD59cMEOxuFvURsSwFZHImeOERgi71xeXlZha9x51j+7pG7DFyAyk3dcdWG5AST0n3SOEJCma7x6ZEjJGg4Sj7vWZdNrUOxp1z2EqLrZFPLnEWo1ci/s+KipyjxCSpKG0+3F4ovuoqXftaT6G5VRiMdtxmDVE1GRStpisaJ77MStJuWzOuTY7lDX1zs93jxFKpzOm3pbjMJNxX/eQ477hDAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxQWbBReKpBWKuOUrWWK1hgyZTZKknHvziGwZT5E89/lfdZF7ppYkRcLu2VfxokJT7yPHj5jqLVlwEWMuXS7rfpv399gy7AYGTzrXXnxxnal32pBjJkmTJk1yrq2cUmXq3XHoPefawWTS1Dubc88mGxxwv70lKT/PPSPNcpxIUjZjy1QLWR6EjDmAki0fcaxYYhpdazkDAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4ccFG8SSTKeUCt/iMvIh71Es05l4rSUMZ90ibgf5eU++C/Arn2ovqa029A7mv5WSyz9T77da3TfV9A+79CwtssUDxeMy5dqDHtn+OHz/qXHvR1BpT73A4Yqqvrq50ri0pSZh6dxeccK7NDtkihHp73XsPRd33pSSFs+63YWKS7f6TC7nf7yUpm3a/XSIR274fGnKPBcoaI4fCIfdzkFDEvTbnmHjGGRAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAiws2Cy6XCyuXdZuP2SDk3Dcvz5YFd7LvpHtxyDEA6T8kSuPOtaWTbDlZ+ccHnWuHAvesKUnq7esx1e/d676W0tJSU+8pU9zz9IYGkqbe8Xz3/TN16lRT77AxD6xsUrlzbTxmy9MrLS1zrg1MnaXePvf8vbziYlPvA+++61wbLygz9S4sm2Sqzxky2AoLbfsnm3V/XMlkbPflbM593SG5P87mHMPgOAMCAHhhGkDNzc268sorVVJSosrKSt18881qbW0dUbN48WKFQqERl7vvvntUFw0AGP9MA6ilpUVNTU3avn27Xn75ZWUyGd1www3q7+8fUXfnnXeqo6Nj+PLoo4+O6qIBAOOf6TmgzZs3j/h6w4YNqqys1K5du7Ro0aLh7xcWFqq6unp0VggAmJDO6Tmgnp73n4wuLx/5BOmPfvQjVVRUaM6cOVq7dq0GBgZO2yOVSqm3t3fEBQAw8Z31q+ByuZzuu+8+XXPNNZozZ87w9z//+c9r2rRpqq2t1Z49e/TVr35Vra2t+ulPf3rKPs3NzXrooYfOdhkAgHHqrAdQU1OT3nzzTf385z8f8f277rpr+N9z585VTU2NlixZov3792vGjBkf6rN27VqtWbNm+Ove3l7V1dWd7bIAAOPEWQ2g1atX64UXXtBrr712xvc/LFy4UJK0b9++Uw6geDyueNz9/RYAgInBNICCINC9996rTZs2aevWrWpoaDjj/9m9e7ckqaam5qwWCACYmEwDqKmpSRs3btRzzz2nkpISdXZ2SpISiYQKCgq0f/9+bdy4UX/wB3+gyZMna8+ePbr//vu1aNEizZs3b0w2AAAwPpkG0Pr16yW9/2bT/+rJJ5/U7bffrlgspldeeUWPPfaY+vv7VVdXp5UrV+rrX//6qC0YADAxmP8E91Hq6urU0tJyTgv6QCQUUiTslj0UibhnFIUCW15bNOqe2RWKuq9DktJZ99ymohL3LDBJKizuP3PRf4jn2XLmKow5WbGoob/tJlTIkJNVGLc95RkrqHSuHUrZbpOCwoStvth9LQryTb3z88uca8smTTH1TqbccwOHjPu+u/+Yc23n0QOm3oXJblN9QbF7vltuaMjUO51OOdemUu610pkf00fWGjLp0m4Zc2TBAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8OOvPAxpr+flRxRyjU4aG3GIfJCmdOf2ns55KLO4+o4OobZ6nMpaIjW5T72g06lwbz7MdBkc7O0z106ZNc64NR9yjjyQpHLjv++Ii99tEktKptHNtrKjE1Luipt5Ur4h7vE4Q2I5D9zAWKS9mi23qPub+CcfJlC0m60Rfl3NtuNPUWolSW/RV4L4U7d/376be4bD7fSIctu37IWMs0GjjDAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxQWbBRcOh5xzjXK5jKGvbeaGQpZiW+9c4J7CdeL4YVPvvEipc21RUbGp94GD+0z1g8ke59pJ5bYMrkSpewZb8qTtcI8Zcs8qphSZemdzJ031A8mkc20m456PJ0kdXe86177T/papd+fhA8615YlCU+9s4H6btB/ab+rdcfigqd5ym59MuefjSVJhiXsOoOWYlaSQ4QHO8tgZDrllzHEGBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADw4oKN4untO6lYym15uVzOuW88FrctxDCiQ3KP1pGkaMT95p88yT1yRpIiYff4jtIS22GQStl+bzl6vN25NpPrM/U+ctT9No+HLblK0mRDLFAkZuvddew9U30y7R43lUq5R9RI0uEjh5xrT3S770tJKklEnGvzYm7xLR+IuLdWMj1o6q3A/TFFkgqKC5xr4yWTbGsx3N3S6bSpteWxM7A8vjneHTgDAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhxwWbBhcMhhR2zuwJDRNFgypYJFXINNZJUWFRk6h3Nc5//eTFTa+Xnu687HLHdJmXltjy9vJh7jlkobFtLOpVyr824r0OSgmDAvXeu39R7MGXL7MoaDvJIniEkTdLgoPvaC4psmXfhSNa5NpWxZdiFDPf7cNTUWgrZsuCygXuOnfU4DIXdHydShvuDZMuOsyRdZtJu+50zIACAF6YBtH79es2bN0+lpaUqLS1VY2OjXnzxxeHrk8mkmpqaNHnyZBUXF2vlypXq6uoa9UUDAMY/0wCaOnWqHnnkEe3atUs7d+7U9ddfr5tuuklvvfWWJOn+++/X888/r2eeeUYtLS06dOiQbrnlljFZOABgfDM9B3TjjTeO+Pqv//qvtX79em3fvl1Tp07VE088oY0bN+r666+XJD355JO67LLLtH37dl199dWjt2oAwLh31s8BZbNZPf300+rv71djY6N27dqlTCajpUuXDtfMnj1b9fX12rZt22n7pFIp9fb2jrgAACY+8wB64403VFxcrHg8rrvvvlubNm3S5Zdfrs7OTsViMZWVlY2or6qqUmdn52n7NTc3K5FIDF/q6urMGwEAGH/MA2jWrFnavXu3duzYoXvuuUerVq3S22+/fdYLWLt2rXp6eoYv7e22j/wFAIxP5vcBxWIxzZw5U5K0YMEC/fKXv9R3v/td3XrrrUqn0+ru7h5xFtTV1aXq6urT9ovH44rHbe8rAQCMf+f8PqBcLqdUKqUFCxYoGo1qy5Ytw9e1trbqwIEDamxsPNcfAwCYYExnQGvXrtWKFStUX1+vvr4+bdy4UVu3btVLL72kRCKhO+64Q2vWrFF5eblKS0t17733qrGxkVfAAQA+xDSADh8+rC9+8Yvq6OhQIpHQvHnz9NJLL+n3f//3JUnf+c53FA6HtXLlSqVSKS1btkw/+MEPzmphkUieInluyxsaco/7iIRtMSWxqHsGTsT6F82cIV4l7L6N79e7x32Ew7bYkfx8U7lChhwUa5RINOZ+m4eHbCf8Q4ZomJ6+w6becoyZ+kBgKA+ytj9ph0KWqCTbsZJKu9+G2SH3OBtJSqcs9cY/9gS27RxMut+G6YwthikccX/Mco0v+0Am434bWtaRc3xsMz1iPvHEEx95fX5+vtatW6d169ZZ2gIAPobIggMAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhhTsMea0HwfoRDOu0eEWGpDYVsURXKuc/oIGuL+cll3eM+QsZfFUIh97Vk82yxIx/sI1epjCGmxBSvYtufoSHbdmYtMSWGWKX3/8PYRfGEI7aDxbKducAYl2Ponc3aemfSlngq4/4xHuMK3G/zTMYWqxWOuK/FHsXjvhZLGtgHfc/0WBEKrI8mY+zgwYN8KB0ATADt7e2aOnXqaa+/4AZQLpfToUOHVFJSMuK3297eXtXV1am9vV2lpaUeVzi22M6J4+OwjRLbOdGMxnYGQaC+vj7V1tYqHD792eEF9ye4cDj8kROztLR0Qu/8D7CdE8fHYRsltnOiOdftTCQSZ6zhRQgAAC8YQAAAL8bNAIrH43rwwQcVj9s+bGu8YTsnjo/DNkps50RzPrfzgnsRAgDg42HcnAEBACYWBhAAwAsGEADACwYQAMCLcTOA1q1bp4svvlj5+flauHChfvGLX/he0qj65je/qVAoNOIye/Zs38s6J6+99ppuvPFG1dbWKhQK6dlnnx1xfRAEeuCBB1RTU6OCggItXbpUe/fu9bPYc3Cm7bz99ts/tG+XL1/uZ7Fnqbm5WVdeeaVKSkpUWVmpm2++Wa2trSNqksmkmpqaNHnyZBUXF2vlypXq6urytOKz47Kdixcv/tD+vPvuuz2t+OysX79e8+bNG36zaWNjo1588cXh68/XvhwXA+jHP/6x1qxZowcffFD/9m//pvnz52vZsmU6fPiw76WNqiuuuEIdHR3Dl5///Oe+l3RO+vv7NX/+fK1bt+6U1z/66KP63ve+p8cff1w7duxQUVGRli1bpmQyeZ5Xem7OtJ2StHz58hH79qmnnjqPKzx3LS0tampq0vbt2/Xyyy8rk8nohhtuUH9//3DN/fffr+eff17PPPOMWlpadOjQId1yyy0eV23nsp2SdOedd47Yn48++qinFZ+dqVOn6pFHHtGuXbu0c+dOXX/99brpppv01ltvSTqP+zIYB6666qqgqalp+OtsNhvU1tYGzc3NHlc1uh588MFg/vz5vpcxZiQFmzZtGv46l8sF1dXVwbe+9a3h73V3dwfxeDx46qmnPKxwdPzudgZBEKxatSq46aabvKxnrBw+fDiQFLS0tARB8P6+i0ajwTPPPDNc8+tf/zqQFGzbts3XMs/Z725nEATB7/3e7wV/+qd/6m9RY2TSpEnB3/7t357XfXnBnwGl02nt2rVLS5cuHf5eOBzW0qVLtW3bNo8rG3179+5VbW2tpk+fri984Qs6cOCA7yWNmba2NnV2do7Yr4lEQgsXLpxw+1WStm7dqsrKSs2aNUv33HOPjh075ntJ56Snp0eSVF5eLknatWuXMpnMiP05e/Zs1dfXj+v9+bvb+YEf/ehHqqio0Jw5c7R27VoNDAz4WN6oyGazevrpp9Xf36/Gxsbzui8vuDDS33X06FFls1lVVVWN+H5VVZV+85vfeFrV6Fu4cKE2bNigWbNmqaOjQw899JCuvfZavfnmmyopKfG9vFHX2dkpSafcrx9cN1EsX75ct9xyixoaGrR//379xV/8hVasWKFt27YpErF9htSFIJfL6b777tM111yjOXPmSHp/f8ZiMZWVlY2oHc/781TbKUmf//znNW3aNNXW1mrPnj366le/qtbWVv30pz/1uFq7N954Q42NjUomkyouLtamTZt0+eWXa/fu3edtX17wA+jjYsWKFcP/njdvnhYuXKhp06bpJz/5ie644w6PK8O5uu2224b/PXfuXM2bN08zZszQ1q1btWTJEo8rOztNTU168803x/1zlGdyuu286667hv89d+5c1dTUaMmSJdq/f79mzJhxvpd51mbNmqXdu3erp6dH//AP/6BVq1appaXlvK7hgv8TXEVFhSKRyIdegdHV1aXq6mpPqxp7ZWVluvTSS7Vv3z7fSxkTH+y7j9t+laTp06eroqJiXO7b1atX64UXXtDPfvazER+bUl1drXQ6re7u7hH143V/nm47T2XhwoWSNO72ZywW08yZM7VgwQI1Nzdr/vz5+u53v3te9+UFP4BisZgWLFigLVu2DH8vl8tpy5Ytamxs9LiysXXy5Ent379fNTU1vpcyJhoaGlRdXT1iv/b29mrHjh0Ter9K73/q77Fjx8bVvg2CQKtXr9amTZv06quvqqGhYcT1CxYsUDQaHbE/W1tbdeDAgXG1P8+0naeye/duSRpX+/NUcrmcUqnU+d2Xo/qShjHy9NNPB/F4PNiwYUPw9ttvB3fddVdQVlYWdHZ2+l7aqPmzP/uzYOvWrUFbW1vwL//yL8HSpUuDioqK4PDhw76Xdtb6+vqC119/PXj99dcDScG3v/3t4PXXXw/efffdIAiC4JFHHgnKysqC5557LtizZ09w0003BQ0NDcHg4KDnldt81Hb29fUFX/7yl4Nt27YFbW1twSuvvBJ86lOfCi655JIgmUz6Xrqze+65J0gkEsHWrVuDjo6O4cvAwMBwzd133x3U19cHr776arBz586gsbExaGxs9LhquzNt5759+4KHH3442LlzZ9DW1hY899xzwfTp04NFixZ5XrnN1772taClpSVoa2sL9uzZE3zta18LQqFQ8E//9E9BEJy/fTkuBlAQBMH3v//9oL6+PojFYsFVV10VbN++3feSRtWtt94a1NTUBLFYLLjooouCW2+9Ndi3b5/vZZ2Tn/3sZ4GkD11WrVoVBMH7L8X+xje+EVRVVQXxeDxYsmRJ0Nra6nfRZ+GjtnNgYCC44YYbgilTpgTRaDSYNm1acOedd467X55OtX2SgieffHK4ZnBwMPiTP/mTYNKkSUFhYWHw2c9+Nujo6PC36LNwpu08cOBAsGjRoqC8vDyIx+PBzJkzgz//8z8Penp6/C7c6I//+I+DadOmBbFYLJgyZUqwZMmS4eETBOdvX/JxDAAALy7454AAABMTAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxf8Hn/HdX3IwC2EAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image tensor shape: (32, 32, 3)\n",
            "Image tensor data type: float64\n",
            "image_tensor type <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(image_array)"
      ],
      "metadata": {
        "id": "s413yxFQYA63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0a9d15-043d-4e49-c4c3-af041af86732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9215686274509803"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kM1grL2YAwO",
        "outputId": "8867dc0d-dabb-4fa6-b3c7-56081e3a2df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.011764705882352941"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(X_train[5036,:,:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPvFKDNCYAin",
        "outputId": "36dc1810-b9b0-4524-f135-8a6b3749cb19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9215686274509803"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(X_train[5036,:,:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3c6PsMlYAU3",
        "outputId": "d1e2aef7-7a74-48ab-84a0-3acbdcfacfac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.011764705882352941"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[5036]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApzRlKWL_fRz",
        "outputId": "95593465-0d2f-46bc-e1d1-fcd260f10ecb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(\"Max X_test =\", np.max(X_test))\n",
        "print(\"Min X_test =\", np.min(X_test))\n",
        "print(\"Max X_train =\", np.max(X_train))\n",
        "print(\"Min X_train =\", np.min(X_train))\n",
        "\n",
        "print(\"y_test dtype =\", y_test.dtype)\n",
        "print(\"y_train dtype =\", y_train.dtype)\n",
        "print(\"x_test dtype =\", X_test.dtype)\n",
        "print(\"x_train dtype =\", X_train.dtype)\n",
        "\n",
        "print(y_train.ndim)\n",
        "print(y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J6nYVZJYGoH",
        "outputId": "0c209ca7-4a5e-4a39-ba74-a13838fcc85f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max X_test = 1.0\n",
            "Min X_test = 0.0\n",
            "Max X_train = 1.0\n",
            "Min X_train = 0.0\n",
            "y_test dtype = float32\n",
            "y_train dtype = float32\n",
            "x_test dtype = float64\n",
            "x_train dtype = float64\n",
            "2\n",
            "(50000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[5036]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkEDcVizmepp",
        "outputId": "425c7e8d-3dd8-4de7-a4c2-365dec729af7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WITH 15% SPLIT\n",
        "\n",
        "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train, y_train, test_size=0.15, random_state=42, shuffle=True)\n",
        "\n",
        "print(y_train2.ndim)  # should output 2\n",
        "print(y_train2.shape)\n",
        "\n",
        "print(X_train2.ndim)  # should output 2\n",
        "print(X_train2.shape)\n",
        "len(X_train2)"
      ],
      "metadata": {
        "id": "TfWyxTXdkVtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5558f79b-5787-4c7d-b1a1-0cacf2cc2432"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "(42500, 10)\n",
            "4\n",
            "(42500, 32, 32, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42500"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WITH 10% SPLIT\n",
        "\n",
        "X_train3, X_val3, y_train3, y_val3 = train_test_split(X_train, y_train, test_size=0.1, random_state=42, shuffle=True)\n",
        "\n",
        "print(y_train3.ndim)  # should output 2\n",
        "print(y_train3.shape)\n",
        "\n",
        "print(X_train3.ndim)  # should output 2\n",
        "print(X_train3.shape)\n",
        "len(X_train3)"
      ],
      "metadata": {
        "id": "lFR5wJUgkVNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a86f711-1c65-48f4-a150-469b81baa69a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "(45000, 10)\n",
            "4\n",
            "(45000, 32, 32, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(X_train3[44999,:,:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wvFN3EIGQ9F",
        "outputId": "ae3f3cdb-5220-40e0-c829-9012b4e0ae51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9921568627450981"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(X_train3[-1,:,:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lclg9IrKGkDN",
        "outputId": "81cf682d-9700-4cf1-8d31-1cc07d7fd516"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9921568627450981"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple CNN\n",
        "################################################################################\n",
        "################################################################################\n",
        "############################### CNN_model1 #####################################\n",
        "################################################################################\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "YZKE2MR8APNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "z1LwFIXiYOPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24u8eW58YPnG",
        "outputId": "4c24de38-a24d-4f58-98c8-9b3700c40f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "704/704 [==============================] - 14s 5ms/step - loss: 1.6461 - accuracy: 0.4133 - val_loss: 1.4201 - val_accuracy: 0.4756\n",
            "Epoch 2/10\n",
            "704/704 [==============================] - 4s 6ms/step - loss: 1.2433 - accuracy: 0.5636 - val_loss: 1.2521 - val_accuracy: 0.5484\n",
            "Epoch 3/10\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 1.0571 - accuracy: 0.6311 - val_loss: 1.0457 - val_accuracy: 0.6336\n",
            "Epoch 4/10\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.9302 - accuracy: 0.6785 - val_loss: 1.1987 - val_accuracy: 0.6018\n",
            "Epoch 5/10\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.8406 - accuracy: 0.7086 - val_loss: 0.8572 - val_accuracy: 0.7058\n",
            "Epoch 6/10\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.7622 - accuracy: 0.7366 - val_loss: 1.1497 - val_accuracy: 0.6298\n",
            "Epoch 7/10\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.6991 - accuracy: 0.7586 - val_loss: 0.9676 - val_accuracy: 0.6770\n",
            "Epoch 8/10\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.6400 - accuracy: 0.7804 - val_loss: 0.9225 - val_accuracy: 0.7002\n",
            "Epoch 9/10\n",
            "704/704 [==============================] - 4s 6ms/step - loss: 0.5882 - accuracy: 0.7960 - val_loss: 0.8980 - val_accuracy: 0.7130\n",
            "Epoch 10/10\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.5405 - accuracy: 0.8138 - val_loss: 0.9117 - val_accuracy: 0.6962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad240a5f60>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnCUePOlL8WM",
        "outputId": "235dd601-60c3-494c-80e0-fb33acae0c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.9557 - accuracy: 0.6855\n",
            "Test accuracy: 0.6855000257492065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple CNN with more layers\n",
        "################################################################################\n",
        "################################################################################\n",
        "############################### CNN_model2 #####################################\n",
        "################################################################################\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "tw6Qf_d__90r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_model2 = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "CNN_model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "1oqjeG60LTkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_model2.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBc-mgUIL6-l",
        "outputId": "3b3104f9-3053-4f46-d1a9-083de753e119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "704/704 [==============================] - 10s 9ms/step - loss: 1.7159 - accuracy: 0.3572 - val_loss: 1.3060 - val_accuracy: 0.5160\n",
            "Epoch 2/20\n",
            "704/704 [==============================] - 5s 7ms/step - loss: 1.2645 - accuracy: 0.5415 - val_loss: 1.0911 - val_accuracy: 0.6212\n",
            "Epoch 3/20\n",
            "704/704 [==============================] - 5s 8ms/step - loss: 1.0673 - accuracy: 0.6203 - val_loss: 0.9250 - val_accuracy: 0.6688\n",
            "Epoch 4/20\n",
            "704/704 [==============================] - 6s 9ms/step - loss: 0.9409 - accuracy: 0.6687 - val_loss: 0.8472 - val_accuracy: 0.7040\n",
            "Epoch 5/20\n",
            "704/704 [==============================] - 7s 10ms/step - loss: 0.8575 - accuracy: 0.6987 - val_loss: 0.7267 - val_accuracy: 0.7484\n",
            "Epoch 6/20\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 0.7879 - accuracy: 0.7238 - val_loss: 0.7042 - val_accuracy: 0.7534\n",
            "Epoch 7/20\n",
            "704/704 [==============================] - 8s 11ms/step - loss: 0.7435 - accuracy: 0.7409 - val_loss: 0.6848 - val_accuracy: 0.7672\n",
            "Epoch 8/20\n",
            "704/704 [==============================] - 5s 8ms/step - loss: 0.7060 - accuracy: 0.7533 - val_loss: 0.6263 - val_accuracy: 0.7810\n",
            "Epoch 9/20\n",
            "704/704 [==============================] - 8s 11ms/step - loss: 0.6782 - accuracy: 0.7637 - val_loss: 0.6099 - val_accuracy: 0.7910\n",
            "Epoch 10/20\n",
            "704/704 [==============================] - 6s 8ms/step - loss: 0.6462 - accuracy: 0.7705 - val_loss: 0.6362 - val_accuracy: 0.7794\n",
            "Epoch 11/20\n",
            "704/704 [==============================] - 6s 8ms/step - loss: 0.6249 - accuracy: 0.7819 - val_loss: 0.6010 - val_accuracy: 0.7950\n",
            "Epoch 12/20\n",
            "704/704 [==============================] - 5s 7ms/step - loss: 0.5982 - accuracy: 0.7879 - val_loss: 0.5998 - val_accuracy: 0.7974\n",
            "Epoch 13/20\n",
            "704/704 [==============================] - 7s 9ms/step - loss: 0.5816 - accuracy: 0.7968 - val_loss: 0.6470 - val_accuracy: 0.7830\n",
            "Epoch 14/20\n",
            "704/704 [==============================] - 5s 7ms/step - loss: 0.5654 - accuracy: 0.8019 - val_loss: 0.6274 - val_accuracy: 0.7946\n",
            "Epoch 15/20\n",
            "704/704 [==============================] - 5s 7ms/step - loss: 0.5505 - accuracy: 0.8074 - val_loss: 0.5903 - val_accuracy: 0.8034\n",
            "Epoch 16/20\n",
            "704/704 [==============================] - 8s 11ms/step - loss: 0.5477 - accuracy: 0.8074 - val_loss: 0.6130 - val_accuracy: 0.7960\n",
            "Epoch 17/20\n",
            "704/704 [==============================] - 5s 8ms/step - loss: 0.5305 - accuracy: 0.8126 - val_loss: 0.6114 - val_accuracy: 0.7954\n",
            "Epoch 18/20\n",
            "704/704 [==============================] - 6s 8ms/step - loss: 0.5166 - accuracy: 0.8163 - val_loss: 0.5756 - val_accuracy: 0.8104\n",
            "Epoch 19/20\n",
            "704/704 [==============================] - 5s 7ms/step - loss: 0.5081 - accuracy: 0.8207 - val_loss: 0.6117 - val_accuracy: 0.8020\n",
            "Epoch 20/20\n",
            "704/704 [==============================] - 6s 8ms/step - loss: 0.5003 - accuracy: 0.8226 - val_loss: 0.5703 - val_accuracy: 0.8114\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac7c4ea140>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = CNN_model2.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGlwy2aZNr1_",
        "outputId": "7d0e27d4-9916-483f-bd4b-9f630cce3ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.6203 - accuracy: 0.8002\n",
            "Test accuracy: 0.8001999855041504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN with data more layer, global optimizer\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################# CNN_model3 ########################################\n",
        "################################################################################\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "zSSGk8aBJJgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define and compile your Keras model\n",
        "with strategy.scope():\n",
        "  CNN_model3 = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "opt = SGD(learning_rate=0.001)\n",
        "CNN_model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "CNN_model3_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3.h5'\n",
        "CNN_model3_path = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3_weights'\n",
        "checkpoint_path = os.path.join(CNN_model3_path)\n",
        "checkpoint_Ped = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                                 patience=20, min_lr=0.00000000001)\n",
        "\n",
        "\n",
        "\n",
        "callbacks_Ped = [checkpoint_Ped, reduce_lr, EarlyStopping(monitor='val_loss', patience=40, verbose=1)]\n",
        "\n",
        "CNN_model3.summary()"
      ],
      "metadata": {
        "id": "-lbSDpjPisYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea171c9-34b2-49f5-ab7f-44dab83fb3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 4, 4, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,493,834\n",
            "Trainable params: 2,489,930\n",
            "Non-trainable params: 3,904\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_CNN_model3= CNN_model3.fit(X_train3, y_train3, batch_size=200, epochs=500, callbacks = callbacks_Ped, validation_data=(X_val3, y_val3))\n",
        "\n",
        "\n",
        "CNN_model3.save(CNN_model3_path_T)\n",
        "\n",
        "test_loss, test_acc = CNN_model3.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc) # epock 215 ==== 0.592199981212616"
      ],
      "metadata": {
        "id": "yjQTR7Tej1bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc241fe-8b0b-43f8-e7ae-71212608d21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "225/225 [==============================] - 9s 31ms/step - loss: 3.2651 - accuracy: 0.1476 - val_loss: 3.0012 - val_accuracy: 0.0972 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 2.7856 - accuracy: 0.2108 - val_loss: 2.8374 - val_accuracy: 0.1490 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 2.5016 - accuracy: 0.2547 - val_loss: 2.2147 - val_accuracy: 0.2412 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 2.3334 - accuracy: 0.2770 - val_loss: 2.3297 - val_accuracy: 0.2330 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 2.2039 - accuracy: 0.2978 - val_loss: 1.8397 - val_accuracy: 0.3404 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 2.0858 - accuracy: 0.3181 - val_loss: 1.6711 - val_accuracy: 0.3876 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 1.9871 - accuracy: 0.3384 - val_loss: 1.8033 - val_accuracy: 0.3550 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.9063 - accuracy: 0.3581 - val_loss: 1.6959 - val_accuracy: 0.3912 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.8607 - accuracy: 0.3726 - val_loss: 1.6044 - val_accuracy: 0.4104 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.8042 - accuracy: 0.3858 - val_loss: 1.6861 - val_accuracy: 0.4044 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.7625 - accuracy: 0.3969 - val_loss: 1.6085 - val_accuracy: 0.4300 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.7182 - accuracy: 0.4074 - val_loss: 1.6785 - val_accuracy: 0.4096 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.6845 - accuracy: 0.4158 - val_loss: 1.6307 - val_accuracy: 0.4188 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.6575 - accuracy: 0.4234 - val_loss: 1.5297 - val_accuracy: 0.4442 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.6278 - accuracy: 0.4336 - val_loss: 1.5818 - val_accuracy: 0.4434 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.6088 - accuracy: 0.4441 - val_loss: 1.9349 - val_accuracy: 0.3526 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.5763 - accuracy: 0.4517 - val_loss: 1.4644 - val_accuracy: 0.4672 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "225/225 [==============================] - 6s 28ms/step - loss: 1.5579 - accuracy: 0.4573 - val_loss: 1.4686 - val_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.5402 - accuracy: 0.4645 - val_loss: 1.5268 - val_accuracy: 0.4602 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.5196 - accuracy: 0.4710 - val_loss: 1.5153 - val_accuracy: 0.4672 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 1.4971 - accuracy: 0.4767 - val_loss: 1.4335 - val_accuracy: 0.4866 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.4783 - accuracy: 0.4832 - val_loss: 1.3907 - val_accuracy: 0.5006 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.4590 - accuracy: 0.4904 - val_loss: 1.4657 - val_accuracy: 0.4734 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.4477 - accuracy: 0.4944 - val_loss: 1.4801 - val_accuracy: 0.4810 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.4234 - accuracy: 0.5007 - val_loss: 1.3408 - val_accuracy: 0.5178 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.4154 - accuracy: 0.5055 - val_loss: 1.3854 - val_accuracy: 0.5058 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.3984 - accuracy: 0.5085 - val_loss: 1.3791 - val_accuracy: 0.5102 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.3875 - accuracy: 0.5145 - val_loss: 1.4388 - val_accuracy: 0.4910 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 1.3705 - accuracy: 0.5189 - val_loss: 1.4242 - val_accuracy: 0.4964 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.3525 - accuracy: 0.5248 - val_loss: 1.3508 - val_accuracy: 0.5244 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.3306 - accuracy: 0.5292 - val_loss: 1.3133 - val_accuracy: 0.5298 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 1.3258 - accuracy: 0.5344 - val_loss: 1.3475 - val_accuracy: 0.5236 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.3115 - accuracy: 0.5391 - val_loss: 1.3391 - val_accuracy: 0.5216 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.3069 - accuracy: 0.5430 - val_loss: 1.3880 - val_accuracy: 0.5118 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 1.2907 - accuracy: 0.5482 - val_loss: 1.3137 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.2764 - accuracy: 0.5492 - val_loss: 1.2587 - val_accuracy: 0.5534 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.2732 - accuracy: 0.5554 - val_loss: 1.3142 - val_accuracy: 0.5296 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "225/225 [==============================] - 6s 27ms/step - loss: 1.2533 - accuracy: 0.5608 - val_loss: 1.4586 - val_accuracy: 0.4948 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.2489 - accuracy: 0.5627 - val_loss: 1.3086 - val_accuracy: 0.5376 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.2330 - accuracy: 0.5640 - val_loss: 1.3495 - val_accuracy: 0.5232 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.2230 - accuracy: 0.5730 - val_loss: 1.3692 - val_accuracy: 0.5218 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.2135 - accuracy: 0.5732 - val_loss: 1.2808 - val_accuracy: 0.5504 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.2065 - accuracy: 0.5761 - val_loss: 1.3512 - val_accuracy: 0.5270 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.1943 - accuracy: 0.5804 - val_loss: 1.1742 - val_accuracy: 0.5828 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.1884 - accuracy: 0.5807 - val_loss: 1.3128 - val_accuracy: 0.5328 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 1.1748 - accuracy: 0.5878 - val_loss: 1.2248 - val_accuracy: 0.5686 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.1687 - accuracy: 0.5892 - val_loss: 1.2153 - val_accuracy: 0.5692 - lr: 0.0010\n",
            "Epoch 48/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.1616 - accuracy: 0.5938 - val_loss: 1.2706 - val_accuracy: 0.5530 - lr: 0.0010\n",
            "Epoch 49/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.1530 - accuracy: 0.5953 - val_loss: 1.3357 - val_accuracy: 0.5318 - lr: 0.0010\n",
            "Epoch 50/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.1434 - accuracy: 0.5973 - val_loss: 1.1616 - val_accuracy: 0.5860 - lr: 0.0010\n",
            "Epoch 51/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.1390 - accuracy: 0.6008 - val_loss: 1.3041 - val_accuracy: 0.5444 - lr: 0.0010\n",
            "Epoch 52/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.1301 - accuracy: 0.6034 - val_loss: 1.3834 - val_accuracy: 0.5270 - lr: 0.0010\n",
            "Epoch 53/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.1163 - accuracy: 0.6061 - val_loss: 1.1986 - val_accuracy: 0.5796 - lr: 0.0010\n",
            "Epoch 54/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.1137 - accuracy: 0.6080 - val_loss: 1.2705 - val_accuracy: 0.5560 - lr: 0.0010\n",
            "Epoch 55/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.1008 - accuracy: 0.6123 - val_loss: 1.2109 - val_accuracy: 0.5760 - lr: 0.0010\n",
            "Epoch 56/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.0930 - accuracy: 0.6143 - val_loss: 1.2392 - val_accuracy: 0.5664 - lr: 0.0010\n",
            "Epoch 57/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.0836 - accuracy: 0.6210 - val_loss: 1.2582 - val_accuracy: 0.5620 - lr: 0.0010\n",
            "Epoch 58/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.0806 - accuracy: 0.6202 - val_loss: 1.1966 - val_accuracy: 0.5794 - lr: 0.0010\n",
            "Epoch 59/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.0771 - accuracy: 0.6198 - val_loss: 1.1582 - val_accuracy: 0.5906 - lr: 0.0010\n",
            "Epoch 60/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.0674 - accuracy: 0.6242 - val_loss: 1.1715 - val_accuracy: 0.5830 - lr: 0.0010\n",
            "Epoch 61/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.0604 - accuracy: 0.6260 - val_loss: 1.1732 - val_accuracy: 0.5890 - lr: 0.0010\n",
            "Epoch 62/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.0576 - accuracy: 0.6252 - val_loss: 1.4124 - val_accuracy: 0.5164 - lr: 0.0010\n",
            "Epoch 63/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.0487 - accuracy: 0.6300 - val_loss: 1.1944 - val_accuracy: 0.5828 - lr: 0.0010\n",
            "Epoch 64/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.0500 - accuracy: 0.6312 - val_loss: 1.2082 - val_accuracy: 0.5770 - lr: 0.0010\n",
            "Epoch 65/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 1.0391 - accuracy: 0.6318 - val_loss: 1.0873 - val_accuracy: 0.6184 - lr: 0.0010\n",
            "Epoch 66/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 1.0394 - accuracy: 0.6344 - val_loss: 1.1873 - val_accuracy: 0.5828 - lr: 0.0010\n",
            "Epoch 67/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.0255 - accuracy: 0.6411 - val_loss: 1.2356 - val_accuracy: 0.5712 - lr: 0.0010\n",
            "Epoch 68/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.0217 - accuracy: 0.6412 - val_loss: 1.1109 - val_accuracy: 0.6142 - lr: 0.0010\n",
            "Epoch 69/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 1.0170 - accuracy: 0.6391 - val_loss: 1.1084 - val_accuracy: 0.6112 - lr: 0.0010\n",
            "Epoch 70/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 1.0139 - accuracy: 0.6411 - val_loss: 1.0962 - val_accuracy: 0.6138 - lr: 0.0010\n",
            "Epoch 71/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 1.0061 - accuracy: 0.6442 - val_loss: 1.2309 - val_accuracy: 0.5738 - lr: 0.0010\n",
            "Epoch 72/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.9998 - accuracy: 0.6444 - val_loss: 1.1369 - val_accuracy: 0.6020 - lr: 0.0010\n",
            "Epoch 73/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.9940 - accuracy: 0.6497 - val_loss: 1.0477 - val_accuracy: 0.6288 - lr: 0.0010\n",
            "Epoch 74/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.9929 - accuracy: 0.6492 - val_loss: 1.0339 - val_accuracy: 0.6338 - lr: 0.0010\n",
            "Epoch 75/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.9885 - accuracy: 0.6518 - val_loss: 1.1523 - val_accuracy: 0.6004 - lr: 0.0010\n",
            "Epoch 76/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.9817 - accuracy: 0.6521 - val_loss: 1.0986 - val_accuracy: 0.6156 - lr: 0.0010\n",
            "Epoch 77/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.9741 - accuracy: 0.6550 - val_loss: 1.0481 - val_accuracy: 0.6326 - lr: 0.0010\n",
            "Epoch 78/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.9705 - accuracy: 0.6562 - val_loss: 1.1004 - val_accuracy: 0.6102 - lr: 0.0010\n",
            "Epoch 79/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.9665 - accuracy: 0.6578 - val_loss: 1.0475 - val_accuracy: 0.6312 - lr: 0.0010\n",
            "Epoch 80/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.9631 - accuracy: 0.6599 - val_loss: 1.0344 - val_accuracy: 0.6328 - lr: 0.0010\n",
            "Epoch 81/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.9539 - accuracy: 0.6629 - val_loss: 1.0372 - val_accuracy: 0.6346 - lr: 0.0010\n",
            "Epoch 82/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.9519 - accuracy: 0.6641 - val_loss: 1.0597 - val_accuracy: 0.6266 - lr: 0.0010\n",
            "Epoch 83/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.9506 - accuracy: 0.6634 - val_loss: 0.9573 - val_accuracy: 0.6596 - lr: 0.0010\n",
            "Epoch 84/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.9460 - accuracy: 0.6632 - val_loss: 1.0450 - val_accuracy: 0.6382 - lr: 0.0010\n",
            "Epoch 85/500\n",
            "225/225 [==============================] - 6s 28ms/step - loss: 0.9383 - accuracy: 0.6686 - val_loss: 1.0336 - val_accuracy: 0.6396 - lr: 0.0010\n",
            "Epoch 86/500\n",
            "225/225 [==============================] - 8s 36ms/step - loss: 0.9377 - accuracy: 0.6681 - val_loss: 0.9894 - val_accuracy: 0.6490 - lr: 0.0010\n",
            "Epoch 87/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.9299 - accuracy: 0.6713 - val_loss: 0.9822 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 88/500\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 0.9236 - accuracy: 0.6716 - val_loss: 0.9366 - val_accuracy: 0.6714 - lr: 0.0010\n",
            "Epoch 89/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.9230 - accuracy: 0.6769 - val_loss: 0.9749 - val_accuracy: 0.6552 - lr: 0.0010\n",
            "Epoch 90/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.9183 - accuracy: 0.6774 - val_loss: 0.9962 - val_accuracy: 0.6498 - lr: 0.0010\n",
            "Epoch 91/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.9109 - accuracy: 0.6808 - val_loss: 0.9235 - val_accuracy: 0.6716 - lr: 0.0010\n",
            "Epoch 92/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.9094 - accuracy: 0.6791 - val_loss: 0.9422 - val_accuracy: 0.6666 - lr: 0.0010\n",
            "Epoch 93/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.9075 - accuracy: 0.6807 - val_loss: 0.9896 - val_accuracy: 0.6442 - lr: 0.0010\n",
            "Epoch 94/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.9081 - accuracy: 0.6789 - val_loss: 0.9642 - val_accuracy: 0.6566 - lr: 0.0010\n",
            "Epoch 95/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.8992 - accuracy: 0.6826 - val_loss: 1.0773 - val_accuracy: 0.6292 - lr: 0.0010\n",
            "Epoch 96/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.8933 - accuracy: 0.6837 - val_loss: 0.9749 - val_accuracy: 0.6558 - lr: 0.0010\n",
            "Epoch 97/500\n",
            "225/225 [==============================] - 6s 27ms/step - loss: 0.8923 - accuracy: 0.6856 - val_loss: 1.0520 - val_accuracy: 0.6334 - lr: 0.0010\n",
            "Epoch 98/500\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 0.8929 - accuracy: 0.6839 - val_loss: 0.8913 - val_accuracy: 0.6842 - lr: 0.0010\n",
            "Epoch 99/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.8825 - accuracy: 0.6893 - val_loss: 0.8827 - val_accuracy: 0.6892 - lr: 0.0010\n",
            "Epoch 100/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.8788 - accuracy: 0.6899 - val_loss: 0.9401 - val_accuracy: 0.6638 - lr: 0.0010\n",
            "Epoch 101/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.8765 - accuracy: 0.6880 - val_loss: 1.0059 - val_accuracy: 0.6484 - lr: 0.0010\n",
            "Epoch 102/500\n",
            "225/225 [==============================] - 8s 35ms/step - loss: 0.8715 - accuracy: 0.6918 - val_loss: 0.9547 - val_accuracy: 0.6642 - lr: 0.0010\n",
            "Epoch 103/500\n",
            "225/225 [==============================] - 7s 30ms/step - loss: 0.8703 - accuracy: 0.6923 - val_loss: 0.8917 - val_accuracy: 0.6850 - lr: 0.0010\n",
            "Epoch 104/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.8642 - accuracy: 0.6966 - val_loss: 0.9308 - val_accuracy: 0.6728 - lr: 0.0010\n",
            "Epoch 105/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.8625 - accuracy: 0.6966 - val_loss: 0.9058 - val_accuracy: 0.6828 - lr: 0.0010\n",
            "Epoch 106/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.8617 - accuracy: 0.6953 - val_loss: 0.9534 - val_accuracy: 0.6676 - lr: 0.0010\n",
            "Epoch 107/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.8556 - accuracy: 0.6999 - val_loss: 0.9117 - val_accuracy: 0.6774 - lr: 0.0010\n",
            "Epoch 108/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.8551 - accuracy: 0.6948 - val_loss: 0.9905 - val_accuracy: 0.6578 - lr: 0.0010\n",
            "Epoch 109/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.8474 - accuracy: 0.7016 - val_loss: 0.9881 - val_accuracy: 0.6572 - lr: 0.0010\n",
            "Epoch 110/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.8474 - accuracy: 0.7006 - val_loss: 0.8912 - val_accuracy: 0.6836 - lr: 0.0010\n",
            "Epoch 111/500\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 0.8401 - accuracy: 0.7042 - val_loss: 0.9628 - val_accuracy: 0.6638 - lr: 0.0010\n",
            "Epoch 112/500\n",
            "225/225 [==============================] - 7s 31ms/step - loss: 0.8375 - accuracy: 0.7023 - val_loss: 0.9101 - val_accuracy: 0.6764 - lr: 0.0010\n",
            "Epoch 113/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.8357 - accuracy: 0.7044 - val_loss: 0.9569 - val_accuracy: 0.6732 - lr: 0.0010\n",
            "Epoch 114/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.8328 - accuracy: 0.7062 - val_loss: 0.8673 - val_accuracy: 0.7020 - lr: 0.0010\n",
            "Epoch 115/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.8307 - accuracy: 0.7078 - val_loss: 0.8704 - val_accuracy: 0.6936 - lr: 0.0010\n",
            "Epoch 116/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.8224 - accuracy: 0.7072 - val_loss: 0.8811 - val_accuracy: 0.6896 - lr: 0.0010\n",
            "Epoch 117/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.8201 - accuracy: 0.7096 - val_loss: 0.9262 - val_accuracy: 0.6780 - lr: 0.0010\n",
            "Epoch 118/500\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 0.8207 - accuracy: 0.7114 - val_loss: 0.9091 - val_accuracy: 0.6824 - lr: 0.0010\n",
            "Epoch 119/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.8152 - accuracy: 0.7134 - val_loss: 1.1504 - val_accuracy: 0.6212 - lr: 0.0010\n",
            "Epoch 120/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.8164 - accuracy: 0.7111 - val_loss: 0.9396 - val_accuracy: 0.6774 - lr: 0.0010\n",
            "Epoch 121/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.8109 - accuracy: 0.7134 - val_loss: 0.9512 - val_accuracy: 0.6736 - lr: 0.0010\n",
            "Epoch 122/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.8086 - accuracy: 0.7150 - val_loss: 0.8563 - val_accuracy: 0.7004 - lr: 0.0010\n",
            "Epoch 123/500\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.8024 - accuracy: 0.7151 - val_loss: 0.9227 - val_accuracy: 0.6802 - lr: 0.0010\n",
            "Epoch 124/500\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 0.8029 - accuracy: 0.7172 - val_loss: 0.9030 - val_accuracy: 0.6916 - lr: 0.0010\n",
            "Epoch 125/500\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 0.7951 - accuracy: 0.7219 - val_loss: 0.8500 - val_accuracy: 0.7054 - lr: 0.0010\n",
            "Epoch 126/500\n",
            "225/225 [==============================] - 8s 34ms/step - loss: 0.7941 - accuracy: 0.7202 - val_loss: 0.8689 - val_accuracy: 0.7006 - lr: 0.0010\n",
            "Epoch 127/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7907 - accuracy: 0.7199 - val_loss: 0.9600 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 128/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7850 - accuracy: 0.7226 - val_loss: 0.8639 - val_accuracy: 0.6998 - lr: 0.0010\n",
            "Epoch 129/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7822 - accuracy: 0.7244 - val_loss: 0.9180 - val_accuracy: 0.6842 - lr: 0.0010\n",
            "Epoch 130/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.7818 - accuracy: 0.7257 - val_loss: 0.8467 - val_accuracy: 0.7074 - lr: 0.0010\n",
            "Epoch 131/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.7818 - accuracy: 0.7235 - val_loss: 0.8353 - val_accuracy: 0.7150 - lr: 0.0010\n",
            "Epoch 132/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7763 - accuracy: 0.7259 - val_loss: 0.8809 - val_accuracy: 0.6964 - lr: 0.0010\n",
            "Epoch 133/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7716 - accuracy: 0.7290 - val_loss: 0.8924 - val_accuracy: 0.6944 - lr: 0.0010\n",
            "Epoch 134/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7746 - accuracy: 0.7264 - val_loss: 0.8485 - val_accuracy: 0.7098 - lr: 0.0010\n",
            "Epoch 135/500\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.7722 - accuracy: 0.7270 - val_loss: 0.8359 - val_accuracy: 0.7116 - lr: 0.0010\n",
            "Epoch 136/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7667 - accuracy: 0.7290 - val_loss: 0.8157 - val_accuracy: 0.7166 - lr: 0.0010\n",
            "Epoch 137/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7664 - accuracy: 0.7294 - val_loss: 0.9736 - val_accuracy: 0.6712 - lr: 0.0010\n",
            "Epoch 138/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.7626 - accuracy: 0.7329 - val_loss: 0.8952 - val_accuracy: 0.6946 - lr: 0.0010\n",
            "Epoch 139/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.7537 - accuracy: 0.7329 - val_loss: 0.8195 - val_accuracy: 0.7194 - lr: 0.0010\n",
            "Epoch 140/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.7562 - accuracy: 0.7342 - val_loss: 0.8669 - val_accuracy: 0.7048 - lr: 0.0010\n",
            "Epoch 141/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.7521 - accuracy: 0.7352 - val_loss: 0.8052 - val_accuracy: 0.7224 - lr: 0.0010\n",
            "Epoch 142/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7478 - accuracy: 0.7351 - val_loss: 0.8287 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 143/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.7478 - accuracy: 0.7366 - val_loss: 0.8659 - val_accuracy: 0.7032 - lr: 0.0010\n",
            "Epoch 144/500\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 0.7447 - accuracy: 0.7369 - val_loss: 0.8591 - val_accuracy: 0.7074 - lr: 0.0010\n",
            "Epoch 145/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7469 - accuracy: 0.7379 - val_loss: 0.8554 - val_accuracy: 0.7116 - lr: 0.0010\n",
            "Epoch 146/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7376 - accuracy: 0.7378 - val_loss: 0.8634 - val_accuracy: 0.7090 - lr: 0.0010\n",
            "Epoch 147/500\n",
            "225/225 [==============================] - 7s 31ms/step - loss: 0.7412 - accuracy: 0.7380 - val_loss: 0.7891 - val_accuracy: 0.7276 - lr: 0.0010\n",
            "Epoch 148/500\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.7344 - accuracy: 0.7415 - val_loss: 0.8675 - val_accuracy: 0.7068 - lr: 0.0010\n",
            "Epoch 149/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7289 - accuracy: 0.7418 - val_loss: 0.8224 - val_accuracy: 0.7172 - lr: 0.0010\n",
            "Epoch 150/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.7287 - accuracy: 0.7422 - val_loss: 0.8199 - val_accuracy: 0.7180 - lr: 0.0010\n",
            "Epoch 151/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7328 - accuracy: 0.7434 - val_loss: 0.8868 - val_accuracy: 0.7010 - lr: 0.0010\n",
            "Epoch 152/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7246 - accuracy: 0.7478 - val_loss: 0.8412 - val_accuracy: 0.7134 - lr: 0.0010\n",
            "Epoch 153/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.7241 - accuracy: 0.7449 - val_loss: 0.9137 - val_accuracy: 0.6940 - lr: 0.0010\n",
            "Epoch 154/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7167 - accuracy: 0.7462 - val_loss: 0.7539 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 155/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7144 - accuracy: 0.7483 - val_loss: 0.8265 - val_accuracy: 0.7238 - lr: 0.0010\n",
            "Epoch 156/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7158 - accuracy: 0.7469 - val_loss: 0.7791 - val_accuracy: 0.7366 - lr: 0.0010\n",
            "Epoch 157/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.7128 - accuracy: 0.7484 - val_loss: 0.7946 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 158/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7116 - accuracy: 0.7486 - val_loss: 0.7872 - val_accuracy: 0.7342 - lr: 0.0010\n",
            "Epoch 159/500\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.7113 - accuracy: 0.7480 - val_loss: 0.8323 - val_accuracy: 0.7174 - lr: 0.0010\n",
            "Epoch 160/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7067 - accuracy: 0.7502 - val_loss: 0.7624 - val_accuracy: 0.7344 - lr: 0.0010\n",
            "Epoch 161/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.7081 - accuracy: 0.7506 - val_loss: 0.8065 - val_accuracy: 0.7274 - lr: 0.0010\n",
            "Epoch 162/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6962 - accuracy: 0.7552 - val_loss: 0.8781 - val_accuracy: 0.7036 - lr: 0.0010\n",
            "Epoch 163/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6960 - accuracy: 0.7538 - val_loss: 0.8021 - val_accuracy: 0.7280 - lr: 0.0010\n",
            "Epoch 164/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6980 - accuracy: 0.7554 - val_loss: 0.8269 - val_accuracy: 0.7230 - lr: 0.0010\n",
            "Epoch 165/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6963 - accuracy: 0.7536 - val_loss: 0.8018 - val_accuracy: 0.7292 - lr: 0.0010\n",
            "Epoch 166/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6930 - accuracy: 0.7556 - val_loss: 0.7589 - val_accuracy: 0.7366 - lr: 0.0010\n",
            "Epoch 167/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6915 - accuracy: 0.7580 - val_loss: 0.7291 - val_accuracy: 0.7504 - lr: 0.0010\n",
            "Epoch 168/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6873 - accuracy: 0.7593 - val_loss: 0.7917 - val_accuracy: 0.7304 - lr: 0.0010\n",
            "Epoch 169/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6803 - accuracy: 0.7602 - val_loss: 0.7664 - val_accuracy: 0.7416 - lr: 0.0010\n",
            "Epoch 170/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6850 - accuracy: 0.7582 - val_loss: 0.8259 - val_accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 171/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6789 - accuracy: 0.7610 - val_loss: 0.7551 - val_accuracy: 0.7422 - lr: 0.0010\n",
            "Epoch 172/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6797 - accuracy: 0.7593 - val_loss: 0.8169 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 173/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6778 - accuracy: 0.7604 - val_loss: 0.7888 - val_accuracy: 0.7346 - lr: 0.0010\n",
            "Epoch 174/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6760 - accuracy: 0.7618 - val_loss: 0.7530 - val_accuracy: 0.7452 - lr: 0.0010\n",
            "Epoch 175/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6739 - accuracy: 0.7631 - val_loss: 0.7890 - val_accuracy: 0.7278 - lr: 0.0010\n",
            "Epoch 176/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6731 - accuracy: 0.7614 - val_loss: 0.7951 - val_accuracy: 0.7282 - lr: 0.0010\n",
            "Epoch 177/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6696 - accuracy: 0.7617 - val_loss: 0.7501 - val_accuracy: 0.7422 - lr: 0.0010\n",
            "Epoch 178/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6659 - accuracy: 0.7666 - val_loss: 0.7080 - val_accuracy: 0.7568 - lr: 0.0010\n",
            "Epoch 179/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6604 - accuracy: 0.7680 - val_loss: 0.7894 - val_accuracy: 0.7344 - lr: 0.0010\n",
            "Epoch 180/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6631 - accuracy: 0.7668 - val_loss: 0.7808 - val_accuracy: 0.7328 - lr: 0.0010\n",
            "Epoch 181/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6614 - accuracy: 0.7660 - val_loss: 0.7461 - val_accuracy: 0.7466 - lr: 0.0010\n",
            "Epoch 182/500\n",
            "225/225 [==============================] - 10s 45ms/step - loss: 0.6563 - accuracy: 0.7660 - val_loss: 0.8158 - val_accuracy: 0.7230 - lr: 0.0010\n",
            "Epoch 183/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6511 - accuracy: 0.7698 - val_loss: 0.7629 - val_accuracy: 0.7398 - lr: 0.0010\n",
            "Epoch 184/500\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.6545 - accuracy: 0.7699 - val_loss: 0.7577 - val_accuracy: 0.7388 - lr: 0.0010\n",
            "Epoch 185/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6549 - accuracy: 0.7688 - val_loss: 0.7297 - val_accuracy: 0.7522 - lr: 0.0010\n",
            "Epoch 186/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6481 - accuracy: 0.7704 - val_loss: 0.7263 - val_accuracy: 0.7510 - lr: 0.0010\n",
            "Epoch 187/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6478 - accuracy: 0.7719 - val_loss: 0.7660 - val_accuracy: 0.7404 - lr: 0.0010\n",
            "Epoch 188/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6415 - accuracy: 0.7743 - val_loss: 0.7214 - val_accuracy: 0.7568 - lr: 0.0010\n",
            "Epoch 189/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6481 - accuracy: 0.7726 - val_loss: 0.7799 - val_accuracy: 0.7338 - lr: 0.0010\n",
            "Epoch 190/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6416 - accuracy: 0.7738 - val_loss: 0.7717 - val_accuracy: 0.7380 - lr: 0.0010\n",
            "Epoch 191/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6420 - accuracy: 0.7740 - val_loss: 0.8051 - val_accuracy: 0.7308 - lr: 0.0010\n",
            "Epoch 192/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6346 - accuracy: 0.7771 - val_loss: 0.7880 - val_accuracy: 0.7344 - lr: 0.0010\n",
            "Epoch 193/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6374 - accuracy: 0.7755 - val_loss: 0.7463 - val_accuracy: 0.7480 - lr: 0.0010\n",
            "Epoch 194/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6351 - accuracy: 0.7753 - val_loss: 0.7603 - val_accuracy: 0.7430 - lr: 0.0010\n",
            "Epoch 195/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6351 - accuracy: 0.7738 - val_loss: 0.7092 - val_accuracy: 0.7546 - lr: 0.0010\n",
            "Epoch 196/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6297 - accuracy: 0.7792 - val_loss: 0.7593 - val_accuracy: 0.7422 - lr: 0.0010\n",
            "Epoch 197/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6272 - accuracy: 0.7800 - val_loss: 0.7403 - val_accuracy: 0.7498 - lr: 0.0010\n",
            "Epoch 198/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6254 - accuracy: 0.7791 - val_loss: 0.7693 - val_accuracy: 0.7410 - lr: 0.0010\n",
            "Epoch 199/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6216 - accuracy: 0.7802 - val_loss: 0.7325 - val_accuracy: 0.7522 - lr: 1.0000e-04\n",
            "Epoch 200/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6212 - accuracy: 0.7814 - val_loss: 0.7205 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
            "Epoch 201/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6191 - accuracy: 0.7808 - val_loss: 0.7247 - val_accuracy: 0.7548 - lr: 1.0000e-04\n",
            "Epoch 202/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6184 - accuracy: 0.7820 - val_loss: 0.7258 - val_accuracy: 0.7558 - lr: 1.0000e-04\n",
            "Epoch 203/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6211 - accuracy: 0.7828 - val_loss: 0.7115 - val_accuracy: 0.7590 - lr: 1.0000e-04\n",
            "Epoch 204/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6157 - accuracy: 0.7833 - val_loss: 0.7233 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 205/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6225 - accuracy: 0.7819 - val_loss: 0.7260 - val_accuracy: 0.7540 - lr: 1.0000e-04\n",
            "Epoch 206/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6175 - accuracy: 0.7818 - val_loss: 0.7253 - val_accuracy: 0.7566 - lr: 1.0000e-04\n",
            "Epoch 207/500\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6173 - accuracy: 0.7812 - val_loss: 0.7255 - val_accuracy: 0.7548 - lr: 1.0000e-04\n",
            "Epoch 208/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6149 - accuracy: 0.7835 - val_loss: 0.7192 - val_accuracy: 0.7576 - lr: 1.0000e-04\n",
            "Epoch 209/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6171 - accuracy: 0.7832 - val_loss: 0.7291 - val_accuracy: 0.7536 - lr: 1.0000e-04\n",
            "Epoch 210/500\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.6186 - accuracy: 0.7818 - val_loss: 0.7225 - val_accuracy: 0.7554 - lr: 1.0000e-04\n",
            "Epoch 211/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6152 - accuracy: 0.7834 - val_loss: 0.7159 - val_accuracy: 0.7570 - lr: 1.0000e-04\n",
            "Epoch 212/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6161 - accuracy: 0.7829 - val_loss: 0.7155 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
            "Epoch 213/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6144 - accuracy: 0.7847 - val_loss: 0.7237 - val_accuracy: 0.7548 - lr: 1.0000e-04\n",
            "Epoch 214/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6122 - accuracy: 0.7844 - val_loss: 0.7267 - val_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 215/500\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6154 - accuracy: 0.7816 - val_loss: 0.7155 - val_accuracy: 0.7572 - lr: 1.0000e-04\n",
            "Epoch 216/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6162 - accuracy: 0.7836 - val_loss: 0.7253 - val_accuracy: 0.7538 - lr: 1.0000e-04\n",
            "Epoch 217/500\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6158 - accuracy: 0.7840 - val_loss: 0.7318 - val_accuracy: 0.7532 - lr: 1.0000e-04\n",
            "Epoch 218/500\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.6167 - accuracy: 0.7836 - val_loss: 0.7304 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 218: early stopping\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.7493 - accuracy: 0.7542\n",
            "Test accuracy: 0.7541999816894531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = CNN_model3.layers[-1].get_weights()\n",
        "print(\"Weights shape:\", weights.shape)\n",
        "print(\"Biases shape:\", biases.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO8SKOeBFRJw",
        "outputId": "bb986959-fc2c-4eff-8c8f-c0e84b60b622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights shape: (512, 10)\n",
            "Biases shape: (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# at this stage since there is no sign of overfitting we can train for more epochs\n",
        "# before 1. lowering learning rate or 2. adding more layers in case the model is\n",
        "# not able to get higher accuray\n",
        "\n",
        "\n",
        "opt = SGD(learning_rate=0.001)\n",
        "CNN_model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "CNN_model3_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3.h5'\n",
        "CNN_model3_path = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3_weights'\n",
        "checkpoint_path = os.path.join(CNN_model3_path)\n",
        "checkpoint_Ped = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                                 patience=20, min_lr=0.00000000001)\n",
        "\n",
        "\n",
        "\n",
        "callbacks_Ped = [checkpoint_Ped, reduce_lr, EarlyStopping(monitor='val_loss', patience=30, verbose=1)]"
      ],
      "metadata": {
        "id": "BxCb7qekj1Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for another 500 epochs and append the new history\n",
        "new_history = CNN_model3.fit(X_train3, y_train3, batch_size=200, epochs=400,\n",
        "                             callbacks=callbacks_Ped, validation_data=(X_val3, y_val3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for key in new_history.history.keys():\n",
        "    history_CNN_model3.history[key].extend(new_history.history[key])\n",
        "\n",
        "# # Save the model\n",
        "CNN_model3.save(CNN_model3_path_T)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = CNN_model3.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc) # Epoch 162: early stopping === 0.6765000224113464"
      ],
      "metadata": {
        "id": "WW0ewrmpj1Vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f627010a-7be4-4dfd-a533-a83afd57358e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "225/225 [==============================] - 8s 25ms/step - loss: 0.6183 - accuracy: 0.7822 - val_loss: 0.7217 - val_accuracy: 0.7570 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6177 - accuracy: 0.7833 - val_loss: 0.7114 - val_accuracy: 0.7594 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6150 - accuracy: 0.7849 - val_loss: 0.7417 - val_accuracy: 0.7532 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6141 - accuracy: 0.7846 - val_loss: 0.6965 - val_accuracy: 0.7626 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.6165 - accuracy: 0.7839 - val_loss: 0.7667 - val_accuracy: 0.7364 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6139 - accuracy: 0.7842 - val_loss: 0.6935 - val_accuracy: 0.7620 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6057 - accuracy: 0.7844 - val_loss: 0.7419 - val_accuracy: 0.7484 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6112 - accuracy: 0.7852 - val_loss: 0.7081 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6055 - accuracy: 0.7874 - val_loss: 0.7450 - val_accuracy: 0.7488 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.6009 - accuracy: 0.7891 - val_loss: 0.6836 - val_accuracy: 0.7656 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.6037 - accuracy: 0.7863 - val_loss: 0.7532 - val_accuracy: 0.7422 - lr: 0.0010\n",
            "Epoch 12/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.6025 - accuracy: 0.7879 - val_loss: 0.7117 - val_accuracy: 0.7584 - lr: 0.0010\n",
            "Epoch 13/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5946 - accuracy: 0.7898 - val_loss: 0.7298 - val_accuracy: 0.7520 - lr: 0.0010\n",
            "Epoch 14/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5991 - accuracy: 0.7894 - val_loss: 0.6787 - val_accuracy: 0.7694 - lr: 0.0010\n",
            "Epoch 15/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5988 - accuracy: 0.7890 - val_loss: 0.6834 - val_accuracy: 0.7678 - lr: 0.0010\n",
            "Epoch 16/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5942 - accuracy: 0.7884 - val_loss: 0.7157 - val_accuracy: 0.7552 - lr: 0.0010\n",
            "Epoch 17/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5963 - accuracy: 0.7899 - val_loss: 0.7767 - val_accuracy: 0.7368 - lr: 0.0010\n",
            "Epoch 18/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.5920 - accuracy: 0.7920 - val_loss: 0.6817 - val_accuracy: 0.7724 - lr: 0.0010\n",
            "Epoch 19/400\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.5936 - accuracy: 0.7915 - val_loss: 0.7269 - val_accuracy: 0.7584 - lr: 0.0010\n",
            "Epoch 20/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5881 - accuracy: 0.7913 - val_loss: 0.6869 - val_accuracy: 0.7684 - lr: 0.0010\n",
            "Epoch 21/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5862 - accuracy: 0.7940 - val_loss: 0.6888 - val_accuracy: 0.7660 - lr: 0.0010\n",
            "Epoch 22/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5871 - accuracy: 0.7912 - val_loss: 0.7399 - val_accuracy: 0.7482 - lr: 0.0010\n",
            "Epoch 23/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5828 - accuracy: 0.7953 - val_loss: 0.7162 - val_accuracy: 0.7548 - lr: 0.0010\n",
            "Epoch 24/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5782 - accuracy: 0.7962 - val_loss: 0.7086 - val_accuracy: 0.7574 - lr: 0.0010\n",
            "Epoch 25/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5785 - accuracy: 0.7974 - val_loss: 0.7039 - val_accuracy: 0.7606 - lr: 0.0010\n",
            "Epoch 26/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5780 - accuracy: 0.7960 - val_loss: 0.7268 - val_accuracy: 0.7514 - lr: 0.0010\n",
            "Epoch 27/400\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.5760 - accuracy: 0.7979 - val_loss: 0.6727 - val_accuracy: 0.7734 - lr: 0.0010\n",
            "Epoch 28/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5733 - accuracy: 0.7997 - val_loss: 0.6777 - val_accuracy: 0.7748 - lr: 0.0010\n",
            "Epoch 29/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5726 - accuracy: 0.7984 - val_loss: 0.6968 - val_accuracy: 0.7642 - lr: 0.0010\n",
            "Epoch 30/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.5770 - accuracy: 0.7966 - val_loss: 0.6663 - val_accuracy: 0.7736 - lr: 0.0010\n",
            "Epoch 31/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5727 - accuracy: 0.7992 - val_loss: 0.6845 - val_accuracy: 0.7684 - lr: 0.0010\n",
            "Epoch 32/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5713 - accuracy: 0.7971 - val_loss: 0.7216 - val_accuracy: 0.7560 - lr: 0.0010\n",
            "Epoch 33/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5663 - accuracy: 0.8023 - val_loss: 0.6797 - val_accuracy: 0.7706 - lr: 0.0010\n",
            "Epoch 34/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5672 - accuracy: 0.7997 - val_loss: 0.7007 - val_accuracy: 0.7672 - lr: 0.0010\n",
            "Epoch 35/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5669 - accuracy: 0.8012 - val_loss: 0.6760 - val_accuracy: 0.7714 - lr: 0.0010\n",
            "Epoch 36/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5649 - accuracy: 0.8014 - val_loss: 0.7170 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Epoch 37/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5586 - accuracy: 0.8035 - val_loss: 0.6709 - val_accuracy: 0.7728 - lr: 0.0010\n",
            "Epoch 38/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5591 - accuracy: 0.8038 - val_loss: 0.6802 - val_accuracy: 0.7674 - lr: 0.0010\n",
            "Epoch 39/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5565 - accuracy: 0.8029 - val_loss: 0.7281 - val_accuracy: 0.7568 - lr: 0.0010\n",
            "Epoch 40/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5556 - accuracy: 0.8037 - val_loss: 0.6885 - val_accuracy: 0.7672 - lr: 0.0010\n",
            "Epoch 41/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5560 - accuracy: 0.8038 - val_loss: 0.7199 - val_accuracy: 0.7552 - lr: 0.0010\n",
            "Epoch 42/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5560 - accuracy: 0.8041 - val_loss: 0.7105 - val_accuracy: 0.7654 - lr: 0.0010\n",
            "Epoch 43/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5535 - accuracy: 0.8043 - val_loss: 0.6948 - val_accuracy: 0.7648 - lr: 0.0010\n",
            "Epoch 44/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5493 - accuracy: 0.8056 - val_loss: 0.6672 - val_accuracy: 0.7746 - lr: 0.0010\n",
            "Epoch 45/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5482 - accuracy: 0.8061 - val_loss: 0.6768 - val_accuracy: 0.7696 - lr: 0.0010\n",
            "Epoch 46/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5515 - accuracy: 0.8052 - val_loss: 0.7190 - val_accuracy: 0.7592 - lr: 0.0010\n",
            "Epoch 47/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.5465 - accuracy: 0.8077 - val_loss: 0.6304 - val_accuracy: 0.7866 - lr: 0.0010\n",
            "Epoch 48/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5431 - accuracy: 0.8100 - val_loss: 0.6628 - val_accuracy: 0.7742 - lr: 0.0010\n",
            "Epoch 49/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5404 - accuracy: 0.8104 - val_loss: 0.6224 - val_accuracy: 0.7870 - lr: 0.0010\n",
            "Epoch 50/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5392 - accuracy: 0.8101 - val_loss: 0.6625 - val_accuracy: 0.7764 - lr: 0.0010\n",
            "Epoch 51/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5435 - accuracy: 0.8084 - val_loss: 0.6947 - val_accuracy: 0.7628 - lr: 0.0010\n",
            "Epoch 52/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5387 - accuracy: 0.8119 - val_loss: 0.6750 - val_accuracy: 0.7758 - lr: 0.0010\n",
            "Epoch 53/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5349 - accuracy: 0.8122 - val_loss: 0.6495 - val_accuracy: 0.7802 - lr: 0.0010\n",
            "Epoch 54/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5364 - accuracy: 0.8127 - val_loss: 0.6532 - val_accuracy: 0.7824 - lr: 0.0010\n",
            "Epoch 55/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5329 - accuracy: 0.8116 - val_loss: 0.6771 - val_accuracy: 0.7728 - lr: 0.0010\n",
            "Epoch 56/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5301 - accuracy: 0.8122 - val_loss: 0.7146 - val_accuracy: 0.7602 - lr: 0.0010\n",
            "Epoch 57/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5303 - accuracy: 0.8122 - val_loss: 0.6651 - val_accuracy: 0.7754 - lr: 0.0010\n",
            "Epoch 58/400\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.5312 - accuracy: 0.8119 - val_loss: 0.6403 - val_accuracy: 0.7840 - lr: 0.0010\n",
            "Epoch 59/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.5283 - accuracy: 0.8145 - val_loss: 0.6567 - val_accuracy: 0.7804 - lr: 0.0010\n",
            "Epoch 60/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5281 - accuracy: 0.8149 - val_loss: 0.6498 - val_accuracy: 0.7816 - lr: 0.0010\n",
            "Epoch 61/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5253 - accuracy: 0.8151 - val_loss: 0.6959 - val_accuracy: 0.7670 - lr: 0.0010\n",
            "Epoch 62/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5237 - accuracy: 0.8159 - val_loss: 0.6659 - val_accuracy: 0.7774 - lr: 0.0010\n",
            "Epoch 63/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5260 - accuracy: 0.8143 - val_loss: 0.6257 - val_accuracy: 0.7876 - lr: 0.0010\n",
            "Epoch 64/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5233 - accuracy: 0.8164 - val_loss: 0.6896 - val_accuracy: 0.7680 - lr: 0.0010\n",
            "Epoch 65/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5230 - accuracy: 0.8155 - val_loss: 0.6366 - val_accuracy: 0.7872 - lr: 0.0010\n",
            "Epoch 66/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5195 - accuracy: 0.8188 - val_loss: 0.6566 - val_accuracy: 0.7758 - lr: 0.0010\n",
            "Epoch 67/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5204 - accuracy: 0.8181 - val_loss: 0.6478 - val_accuracy: 0.7796 - lr: 0.0010\n",
            "Epoch 68/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5159 - accuracy: 0.8181 - val_loss: 0.6791 - val_accuracy: 0.7726 - lr: 0.0010\n",
            "Epoch 69/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5159 - accuracy: 0.8182 - val_loss: 0.7153 - val_accuracy: 0.7652 - lr: 0.0010\n",
            "Epoch 70/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5124 - accuracy: 0.8198 - val_loss: 0.6425 - val_accuracy: 0.7822 - lr: 1.0000e-04\n",
            "Epoch 71/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5077 - accuracy: 0.8212 - val_loss: 0.6544 - val_accuracy: 0.7820 - lr: 1.0000e-04\n",
            "Epoch 72/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5033 - accuracy: 0.8235 - val_loss: 0.6420 - val_accuracy: 0.7872 - lr: 1.0000e-04\n",
            "Epoch 73/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5060 - accuracy: 0.8214 - val_loss: 0.6577 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 74/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5104 - accuracy: 0.8207 - val_loss: 0.6431 - val_accuracy: 0.7858 - lr: 1.0000e-04\n",
            "Epoch 75/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5087 - accuracy: 0.8204 - val_loss: 0.6611 - val_accuracy: 0.7788 - lr: 1.0000e-04\n",
            "Epoch 76/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5059 - accuracy: 0.8210 - val_loss: 0.6528 - val_accuracy: 0.7832 - lr: 1.0000e-04\n",
            "Epoch 77/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5038 - accuracy: 0.8238 - val_loss: 0.6467 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
            "Epoch 78/400\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.5095 - accuracy: 0.8204 - val_loss: 0.6437 - val_accuracy: 0.7848 - lr: 1.0000e-04\n",
            "Epoch 79/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5038 - accuracy: 0.8236 - val_loss: 0.6571 - val_accuracy: 0.7798 - lr: 1.0000e-04\n",
            "Epoch 79: early stopping\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6838 - accuracy: 0.7797\n",
            "Test accuracy: 0.779699981212616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# at this stage since there is no sign of overfitting we can train for more epochs\n",
        "# before 1. lowering learning rate or 2. adding more layers in case the model is\n",
        "# not able to get higher accuray\n",
        "\n",
        "\n",
        "opt = SGD(learning_rate=0.00001)\n",
        "CNN_model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "CNN_model3_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3.h5'\n",
        "CNN_model3_path = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3_weights'\n",
        "checkpoint_path = os.path.join(CNN_model3_path)\n",
        "checkpoint_Ped = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                                 patience=15, min_lr=0.00000000001)\n",
        "\n",
        "\n",
        "\n",
        "callbacks_Ped = [checkpoint_Ped, reduce_lr, EarlyStopping(monitor='val_loss', patience=20, verbose=1)]\n",
        "\n",
        "# Train the model for another 500 epochs and append the new history\n",
        "new_history = CNN_model3.fit(X_train3, y_train3, batch_size=200, epochs=400,\n",
        "                             callbacks=callbacks_Ped, validation_data=(X_val3, y_val3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for key in new_history.history.keys():\n",
        "    history_CNN_model3.history[key].extend(new_history.history[key])\n",
        "\n",
        "# # Save the model\n",
        "CNN_model3.save(CNN_model3_path_T)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = CNN_model3.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc) # Epoch 162: early stopping === 0.6765000224113464"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmciy4eLJ0AZ",
        "outputId": "1088922f-200f-4c53-f8d9-b4ff13296763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "225/225 [==============================] - 7s 24ms/step - loss: 0.5023 - accuracy: 0.8233 - val_loss: 0.6487 - val_accuracy: 0.7840 - lr: 1.0000e-05\n",
            "Epoch 2/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5058 - accuracy: 0.8225 - val_loss: 0.6500 - val_accuracy: 0.7826 - lr: 1.0000e-05\n",
            "Epoch 3/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5008 - accuracy: 0.8248 - val_loss: 0.6465 - val_accuracy: 0.7830 - lr: 1.0000e-05\n",
            "Epoch 4/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5000 - accuracy: 0.8244 - val_loss: 0.6473 - val_accuracy: 0.7832 - lr: 1.0000e-05\n",
            "Epoch 5/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5018 - accuracy: 0.8243 - val_loss: 0.6480 - val_accuracy: 0.7830 - lr: 1.0000e-05\n",
            "Epoch 6/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5035 - accuracy: 0.8238 - val_loss: 0.6503 - val_accuracy: 0.7830 - lr: 1.0000e-05\n",
            "Epoch 7/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5049 - accuracy: 0.8210 - val_loss: 0.6486 - val_accuracy: 0.7828 - lr: 1.0000e-05\n",
            "Epoch 8/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5070 - accuracy: 0.8224 - val_loss: 0.6483 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 9/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5011 - accuracy: 0.8231 - val_loss: 0.6467 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 10/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5045 - accuracy: 0.8218 - val_loss: 0.6475 - val_accuracy: 0.7832 - lr: 1.0000e-05\n",
            "Epoch 11/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5014 - accuracy: 0.8238 - val_loss: 0.6491 - val_accuracy: 0.7838 - lr: 1.0000e-05\n",
            "Epoch 12/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5005 - accuracy: 0.8252 - val_loss: 0.6486 - val_accuracy: 0.7834 - lr: 1.0000e-05\n",
            "Epoch 13/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5131 - accuracy: 0.8182 - val_loss: 0.6486 - val_accuracy: 0.7836 - lr: 1.0000e-05\n",
            "Epoch 14/400\n",
            "225/225 [==============================] - 6s 27ms/step - loss: 0.5024 - accuracy: 0.8224 - val_loss: 0.6501 - val_accuracy: 0.7832 - lr: 1.0000e-05\n",
            "Epoch 15/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5009 - accuracy: 0.8224 - val_loss: 0.6507 - val_accuracy: 0.7834 - lr: 1.0000e-05\n",
            "Epoch 16/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.5022 - accuracy: 0.8225 - val_loss: 0.6493 - val_accuracy: 0.7832 - lr: 1.0000e-05\n",
            "Epoch 17/400\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.5048 - accuracy: 0.8257 - val_loss: 0.6486 - val_accuracy: 0.7842 - lr: 1.0000e-05\n",
            "Epoch 18/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5045 - accuracy: 0.8198 - val_loss: 0.6474 - val_accuracy: 0.7850 - lr: 1.0000e-05\n",
            "Epoch 19/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5021 - accuracy: 0.8244 - val_loss: 0.6498 - val_accuracy: 0.7840 - lr: 1.0000e-06\n",
            "Epoch 20/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5040 - accuracy: 0.8226 - val_loss: 0.6481 - val_accuracy: 0.7836 - lr: 1.0000e-06\n",
            "Epoch 21/400\n",
            "225/225 [==============================] - 5s 20ms/step - loss: 0.5021 - accuracy: 0.8204 - val_loss: 0.6491 - val_accuracy: 0.7834 - lr: 1.0000e-06\n",
            "Epoch 22/400\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.5052 - accuracy: 0.8217 - val_loss: 0.6481 - val_accuracy: 0.7836 - lr: 1.0000e-06\n",
            "Epoch 23/400\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.5085 - accuracy: 0.8202 - val_loss: 0.6489 - val_accuracy: 0.7826 - lr: 1.0000e-06\n",
            "Epoch 23: early stopping\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6749 - accuracy: 0.7820\n",
            "Test accuracy: 0.7820000052452087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# at this stage since there is no sign of overfitting we can train for more epochs\n",
        "# before 1. lowering learning rate or 2. adding more layers in case the model is\n",
        "# not able to get higher accuray\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "CNN_model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "CNN_model3_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3.h5'\n",
        "CNN_model3_path = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3_weights'\n",
        "checkpoint_path = os.path.join(CNN_model3_path)\n",
        "checkpoint_Ped = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                                 patience=10, min_lr=0.000000001)\n",
        "\n",
        "\n",
        "\n",
        "callbacks_Ped = [checkpoint_Ped, reduce_lr, EarlyStopping(monitor='val_loss', patience=15, verbose=1)]\n",
        "\n",
        "# Train the model for another 500 epochs and append the new history\n",
        "new_history = CNN_model3.fit(X_train3, y_train3, batch_size=200, epochs=50,\n",
        "                             callbacks=callbacks_Ped, validation_data=(X_val3, y_val3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = CNN_model3.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc) # Epoch 162: early stopping === 0.6765000224113464"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dObx0WZDKkyV",
        "outputId": "aecb061c-96d5-4f0e-e1f2-81ba9cf8a3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "225/225 [==============================] - 16s 30ms/step - loss: 0.8969 - accuracy: 0.6906 - val_loss: 1.3916 - val_accuracy: 0.6578 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.7139 - accuracy: 0.7552 - val_loss: 0.8054 - val_accuracy: 0.7370 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.6167 - accuracy: 0.7897 - val_loss: 0.8719 - val_accuracy: 0.7274 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.5519 - accuracy: 0.8102 - val_loss: 0.6408 - val_accuracy: 0.7910 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.4983 - accuracy: 0.8304 - val_loss: 0.5564 - val_accuracy: 0.8150 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.4533 - accuracy: 0.8457 - val_loss: 0.5572 - val_accuracy: 0.8134 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.4142 - accuracy: 0.8588 - val_loss: 0.5436 - val_accuracy: 0.8216 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "225/225 [==============================] - 6s 26ms/step - loss: 0.3796 - accuracy: 0.8699 - val_loss: 0.5485 - val_accuracy: 0.8246 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.3375 - accuracy: 0.8845 - val_loss: 0.5551 - val_accuracy: 0.8286 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.3153 - accuracy: 0.8925 - val_loss: 0.5838 - val_accuracy: 0.8178 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.2930 - accuracy: 0.8979 - val_loss: 0.5734 - val_accuracy: 0.8254 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.2632 - accuracy: 0.9090 - val_loss: 0.5245 - val_accuracy: 0.8444 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.2362 - accuracy: 0.9177 - val_loss: 0.5671 - val_accuracy: 0.8258 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.2176 - accuracy: 0.9240 - val_loss: 0.4911 - val_accuracy: 0.8576 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "225/225 [==============================] - 8s 36ms/step - loss: 0.1994 - accuracy: 0.9299 - val_loss: 0.5320 - val_accuracy: 0.8498 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "225/225 [==============================] - 6s 27ms/step - loss: 0.1841 - accuracy: 0.9372 - val_loss: 0.5251 - val_accuracy: 0.8440 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.1679 - accuracy: 0.9423 - val_loss: 0.5232 - val_accuracy: 0.8542 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "225/225 [==============================] - 7s 32ms/step - loss: 0.1578 - accuracy: 0.9452 - val_loss: 0.5787 - val_accuracy: 0.8434 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.1433 - accuracy: 0.9506 - val_loss: 0.6257 - val_accuracy: 0.8392 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "225/225 [==============================] - 5s 21ms/step - loss: 0.1382 - accuracy: 0.9522 - val_loss: 0.5731 - val_accuracy: 0.8488 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "225/225 [==============================] - 6s 25ms/step - loss: 0.1281 - accuracy: 0.9555 - val_loss: 0.5694 - val_accuracy: 0.8526 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "225/225 [==============================] - 5s 22ms/step - loss: 0.1213 - accuracy: 0.9571 - val_loss: 0.5540 - val_accuracy: 0.8562 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "225/225 [==============================] - 5s 23ms/step - loss: 0.1156 - accuracy: 0.9602 - val_loss: 0.5746 - val_accuracy: 0.8488 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.1018 - accuracy: 0.9648 - val_loss: 0.6476 - val_accuracy: 0.8478 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.0624 - accuracy: 0.9786 - val_loss: 0.5124 - val_accuracy: 0.8698 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "225/225 [==============================] - 6s 28ms/step - loss: 0.0409 - accuracy: 0.9871 - val_loss: 0.5153 - val_accuracy: 0.8726 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.5192 - val_accuracy: 0.8744 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "225/225 [==============================] - 5s 24ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 0.5405 - val_accuracy: 0.8742 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "225/225 [==============================] - 6s 27ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.5371 - val_accuracy: 0.8760 - lr: 1.0000e-04\n",
            "Epoch 29: early stopping\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5559 - accuracy: 0.8741\n",
            "Test accuracy: 0.8741000294685364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in new_history.history.keys():\n",
        "    history_CNN_model3.history[key].extend(new_history.history[key])\n",
        "\n",
        "# # Save the model\n",
        "CNN_model3.save(CNN_model3_path_T)"
      ],
      "metadata": {
        "id": "tp_502rUKsr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = X_train[5036,:,:,:]\n",
        "image = np.expand_dims(image, axis=0)\n",
        "prob_vector = CNN_model3.predict(image)\n",
        "\n",
        "print(prob_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REjwIPb1Mp7v",
        "outputId": "eacc1219-266c-47b5-8f0b-8096a6e326d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 250ms/step\n",
            "[[1.1982176e-09 1.6125456e-07 4.3310116e-08 2.3596838e-05 1.9784456e-07\n",
            "  9.9997532e-01 7.4573663e-09 5.7901173e-07 1.4727061e-09 1.0523736e-08]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_CNN_model3.history['accuracy'])\n",
        "plt.plot(history_CNN_model3.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history_CNN_model3.history['loss'])\n",
        "plt.plot(history_CNN_model3.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jqOnT3iMj1Ip",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "a993ef85-567c-41ed-f7b0-f7931b15360e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Load the saved model\n",
        "# CNN_model3_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3.h5'\n",
        "# CNN_model3 = tf.keras.models.load_model(CNN_model3_path_T)\n",
        "\n",
        "# Calculate the size of the model\n",
        "model_size = os.path.getsize(CNN_model3_path_T) / (1024 * 1024)\n",
        "\n",
        "# Calculate the top-1 and top-2 accuracies on the test data\n",
        "top1_accuracy = CNN_model3.evaluate(X_test, y_test)[1]\n",
        "\n",
        "\n",
        "# Define a function to calculate the top-2 accuracy\n",
        "y_pred = CNN_model3.predict(X_test)\n",
        "\n",
        "top2_acc = tf.keras.metrics.TopKCategoricalAccuracy(k=2)\n",
        "top2_acc.update_state(y_test, y_pred)\n",
        "top2_accuracy = top2_acc.result().numpy()\n",
        "# print('Top-5 accuracy:', top2_acc.result().numpy())\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the train and validation accuracies\n",
        "train_accuracy = CNN_model3.evaluate(X_train3, y_train3)[1]\n",
        "val_accuracy = CNN_model3.evaluate(X_val3, y_val3)[1]\n",
        "\n",
        "# Count the number of trainable and non-trainable parameters in the model\n",
        "num_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in CNN_model3.trainable_variables])\n",
        "num_non_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in CNN_model3.non_trainable_variables])\n",
        "num_params = num_trainable_params + num_non_trainable_params\n",
        "\n",
        "# Calculate the depth of the model\n",
        "depth = len(CNN_model3.layers)\n",
        "\n",
        "# Print the information in the required format\n",
        "print(\"| CNN_model3 | {:.2f} | {:.4f} | {:.4f} | {:.4f} | {:.4f} | {} | {} |\".format(\n",
        "    model_size, top1_accuracy, top2_accuracy, train_accuracy, val_accuracy, num_params, depth))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b39nTVCFDVqu",
        "outputId": "f725c34f-9fe9-4d5c-8f7a-0d705cec14ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5559 - accuracy: 0.8741\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.5371 - accuracy: 0.8760\n",
            "| CNN_model3 | 28.73 | 0.8741 | 0.9533 | 1.0000 | 0.8760 | 2493834 | 37 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple ResNet50\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################## resnet_model1 ##################################\n",
        "################################################################################\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "hTCPFPfrrVfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define and compile your Keras model\n",
        "with strategy.scope():\n",
        "  # Define the input shape\n",
        "  input_shape = (32, 32, 3)\n",
        "  num_classes = 10\n",
        "  \n",
        "  # Load the ResNet50 model\n",
        "  # weights=None, include_top=True\n",
        "  resnet_model_base = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False, classes=num_classes) \n",
        "  # resnet_model = ResNet50(input_shape=input_shape, weights=None, classes=10)\n",
        "  for layer in resnet_model_base.layers:\n",
        "  # if layer.trainable:\n",
        "    layer.trainable = True\n",
        "  # Add the top layers\n",
        "  x = resnet_model_base.output\n",
        "  x = Flatten()(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  # Combine the base model and top layers\n",
        "  resnet50_model1 = Model(inputs=resnet_model_base.input, outputs=predictions)\n",
        "  # Compile the model\n",
        "  resnet50_model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  # Print the model summary\n",
        "  resnet50_model1.summary()"
      ],
      "metadata": {
        "id": "q8B8R8RWsLfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27cbaadd-3f20-426c-c37e-fbaf6c8d6fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 2048)         0           ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 10)           20490       ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_resnet50_model = resnet50_model1.fit(X_train2, y_train2, epochs=30, batch_size=64, validation_data=(X_val2, y_val2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olsQTynvjvhy",
        "outputId": "a9f1cc88-c892-4a54-a718-4739d5609230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "665/665 [==============================] - 93s 71ms/step - loss: 1.4402 - accuracy: 0.5529 - val_loss: 3.8492 - val_accuracy: 0.1967\n",
            "Epoch 2/30\n",
            "665/665 [==============================] - 37s 55ms/step - loss: 1.3353 - accuracy: 0.5864 - val_loss: 2.1260 - val_accuracy: 0.4603\n",
            "Epoch 3/30\n",
            "665/665 [==============================] - 39s 59ms/step - loss: 0.9772 - accuracy: 0.6797 - val_loss: 1.2379 - val_accuracy: 0.6243\n",
            "Epoch 4/30\n",
            "665/665 [==============================] - 41s 62ms/step - loss: 1.0040 - accuracy: 0.6798 - val_loss: 2.3613 - val_accuracy: 0.4337\n",
            "Epoch 5/30\n",
            "665/665 [==============================] - 38s 56ms/step - loss: 1.3863 - accuracy: 0.5632 - val_loss: 1.7001 - val_accuracy: 0.4604\n",
            "Epoch 6/30\n",
            "665/665 [==============================] - 40s 61ms/step - loss: 1.0088 - accuracy: 0.6689 - val_loss: 1.1074 - val_accuracy: 0.6372\n",
            "Epoch 7/30\n",
            "665/665 [==============================] - 36s 54ms/step - loss: 0.9555 - accuracy: 0.7030 - val_loss: 1.0343 - val_accuracy: 0.6645\n",
            "Epoch 8/30\n",
            "665/665 [==============================] - 37s 56ms/step - loss: 0.8258 - accuracy: 0.7328 - val_loss: 2.9777 - val_accuracy: 0.2999\n",
            "Epoch 9/30\n",
            "665/665 [==============================] - 37s 55ms/step - loss: 0.9155 - accuracy: 0.7141 - val_loss: 3.5010 - val_accuracy: 0.4844\n",
            "Epoch 10/30\n",
            "665/665 [==============================] - 36s 54ms/step - loss: 0.9720 - accuracy: 0.6871 - val_loss: 3.1865 - val_accuracy: 0.4515\n",
            "Epoch 11/30\n",
            "665/665 [==============================] - 37s 55ms/step - loss: 0.7453 - accuracy: 0.7514 - val_loss: 0.8084 - val_accuracy: 0.7309\n",
            "Epoch 12/30\n",
            "665/665 [==============================] - 39s 58ms/step - loss: 0.8301 - accuracy: 0.7366 - val_loss: 0.8461 - val_accuracy: 0.7144\n",
            "Epoch 13/30\n",
            "665/665 [==============================] - 35s 53ms/step - loss: 0.6422 - accuracy: 0.7871 - val_loss: 2.1127 - val_accuracy: 0.5197\n",
            "Epoch 14/30\n",
            "665/665 [==============================] - 37s 56ms/step - loss: 0.6098 - accuracy: 0.7963 - val_loss: 0.7577 - val_accuracy: 0.7443\n",
            "Epoch 15/30\n",
            "665/665 [==============================] - 38s 58ms/step - loss: 0.5012 - accuracy: 0.8346 - val_loss: 0.7068 - val_accuracy: 0.7752\n",
            "Epoch 16/30\n",
            "665/665 [==============================] - 46s 69ms/step - loss: 0.3685 - accuracy: 0.8749 - val_loss: 0.9564 - val_accuracy: 0.7177\n",
            "Epoch 17/30\n",
            "665/665 [==============================] - 57s 86ms/step - loss: 0.4141 - accuracy: 0.8648 - val_loss: 2.6920 - val_accuracy: 0.4481\n",
            "Epoch 18/30\n",
            "665/665 [==============================] - 48s 72ms/step - loss: 0.5969 - accuracy: 0.8140 - val_loss: 0.9168 - val_accuracy: 0.7117\n",
            "Epoch 19/30\n",
            "665/665 [==============================] - 53s 80ms/step - loss: 0.3544 - accuracy: 0.8835 - val_loss: 2.0395 - val_accuracy: 0.7243\n",
            "Epoch 20/30\n",
            "665/665 [==============================] - 37s 56ms/step - loss: 0.2920 - accuracy: 0.9026 - val_loss: 0.8641 - val_accuracy: 0.7543\n",
            "Epoch 21/30\n",
            "665/665 [==============================] - 43s 64ms/step - loss: 0.2207 - accuracy: 0.9283 - val_loss: 0.9445 - val_accuracy: 0.7453\n",
            "Epoch 22/30\n",
            "665/665 [==============================] - 48s 72ms/step - loss: 0.3286 - accuracy: 0.8928 - val_loss: 1.2406 - val_accuracy: 0.6891\n",
            "Epoch 23/30\n",
            "665/665 [==============================] - 38s 57ms/step - loss: 0.2520 - accuracy: 0.9200 - val_loss: 1.0218 - val_accuracy: 0.7575\n",
            "Epoch 24/30\n",
            "665/665 [==============================] - 40s 61ms/step - loss: 0.2943 - accuracy: 0.9056 - val_loss: 2.2321 - val_accuracy: 0.5139\n",
            "Epoch 25/30\n",
            "665/665 [==============================] - 38s 57ms/step - loss: 0.1838 - accuracy: 0.9399 - val_loss: 1.0542 - val_accuracy: 0.7412\n",
            "Epoch 26/30\n",
            "665/665 [==============================] - 35s 53ms/step - loss: 0.1939 - accuracy: 0.9372 - val_loss: 0.9911 - val_accuracy: 0.7687\n",
            "Epoch 27/30\n",
            "665/665 [==============================] - 41s 62ms/step - loss: 0.2934 - accuracy: 0.9100 - val_loss: 1.3408 - val_accuracy: 0.6747\n",
            "Epoch 28/30\n",
            "665/665 [==============================] - 37s 56ms/step - loss: 0.2170 - accuracy: 0.9289 - val_loss: 1.1246 - val_accuracy: 0.7320\n",
            "Epoch 29/30\n",
            "665/665 [==============================] - 35s 53ms/step - loss: 0.1013 - accuracy: 0.9677 - val_loss: 1.1498 - val_accuracy: 0.7553\n",
            "Epoch 30/30\n",
            "665/665 [==============================] - 37s 56ms/step - loss: 0.0914 - accuracy: 0.9692 - val_loss: 1.1825 - val_accuracy: 0.7541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = resnet50_model1.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc) # Test accuracy: 0.6413000226020813"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0Padj8Dr-5a",
        "outputId": "567eeeaf-aab1-4c94-d5e6-374d9a845a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 1.1996 - accuracy: 0.7545\n",
            "Test accuracy: 0.7544999718666077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the resnet50_model1 with adding more Dense top layers and data Augmentation\n",
        "################################################################################\n",
        "################################################################################\n",
        "############################## resnet50_model3 #################################\n",
        "################################################################################\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "NUi8m5S0bizz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "# Define and compile your Keras model\n",
        "with strategy.scope():\n",
        "    # Define the input shape\n",
        "    input_shape = (32, 32, 3)\n",
        "    num_classes = 10\n",
        "\n",
        "    # Load the ResNet50 model\n",
        "    # (weights='imagenet', include_top=False) OR (weights=None, include_top=True)\n",
        "    resnet50_model_base3 = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False, classes=num_classes)\n",
        "\n",
        "\n",
        "    # Freeze the layers in the base model\n",
        "    resnet50_model_base3.trainable = True\n",
        "    # Add the top layers\n",
        "    x = resnet50_model_base3.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(2048, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Combine the base model and top layers\n",
        "    resnet50_model3 = Model(inputs=resnet50_model_base3.input, outputs=predictions)\n",
        "\n",
        "    #  Define data augmentation pipelines\n",
        "    data_gen = ImageDataGenerator(\n",
        "         rotation_range=10,  # rotate images by up to 10 degrees\n",
        "         width_shift_range=0.05,  # shift images horizontally by up to 5% of the width\n",
        "         height_shift_range=0.05,  # shift images vertically by up to 5% of the height\n",
        "         zoom_range=0.05,  # zoom in on images by up to 5%\n",
        "         horizontal_flip=True,  # flip images horizontally\n",
        "         # brightness_range=[0.8, 1.2],  # adjust brightness randomly between 0.8 and 1.2\n",
        "         # shear_range=0.1,  # shear images by up to 10 degrees\n",
        "         fill_mode='nearest'  # fill any pixel that might be lost after rotation or shift with the nearest pixel value\n",
        "     )\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    resnet50_model3.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "resnet50_model3_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/resnet50_model3.h5'\n",
        "resnet50_model3_path = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/resnet50_model3_weights'\n",
        "checkpoint_path = os.path.join(resnet50_model3_path)\n",
        "checkpoint_Ped = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                                 patience=5, min_lr=0.0000001)\n",
        "\n",
        "\n",
        "callbacks_Ped = [checkpoint_Ped, reduce_lr, EarlyStopping(monitor='val_loss', patience=5*2, verbose=1)]"
      ],
      "metadata": {
        "id": "XlsA8o9GpyxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with data augmentation\n",
        "history_resnet50_model3 = resnet50_model3.fit(data_gen.flow(X_train2, y_train2, batch_size=100),\n",
        "                                               epochs=50,\n",
        "                                               validation_data=(X_val2, y_val2),\n",
        "                                               callbacks=callbacks_Ped)\n",
        "\n",
        "resnet50_model3.save(resnet50_model3_path_T)\n",
        "\n",
        "test_loss, test_acc = resnet50_model3.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "# Epoch 43: early stopping === Test accuracy: 0.6913999915122986\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZeoXRf9rg8K",
        "outputId": "e384d882-bd6c-4372-fce4-b521e95a36ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "425/425 [==============================] - 101s 130ms/step - loss: 5.7305 - accuracy: 0.5749 - val_loss: 3.1286 - val_accuracy: 0.0961 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "425/425 [==============================] - 54s 128ms/step - loss: 1.0993 - accuracy: 0.7002 - val_loss: 2.3528 - val_accuracy: 0.3619 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "425/425 [==============================] - 54s 127ms/step - loss: 0.9812 - accuracy: 0.7334 - val_loss: 0.9997 - val_accuracy: 0.7121 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "425/425 [==============================] - 50s 118ms/step - loss: 0.9233 - accuracy: 0.7513 - val_loss: 1.0688 - val_accuracy: 0.6996 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "425/425 [==============================] - 50s 118ms/step - loss: 0.8635 - accuracy: 0.7679 - val_loss: 1.0540 - val_accuracy: 0.7063 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "425/425 [==============================] - 52s 122ms/step - loss: 0.8197 - accuracy: 0.7804 - val_loss: 1.0304 - val_accuracy: 0.7187 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "425/425 [==============================] - 50s 118ms/step - loss: 0.7787 - accuracy: 0.7918 - val_loss: 1.2739 - val_accuracy: 0.6680 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "425/425 [==============================] - 49s 114ms/step - loss: 0.7597 - accuracy: 0.7953 - val_loss: 1.1984 - val_accuracy: 0.6940 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "425/425 [==============================] - 52s 123ms/step - loss: 0.5751 - accuracy: 0.8433 - val_loss: 0.6065 - val_accuracy: 0.8287 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "425/425 [==============================] - 51s 119ms/step - loss: 0.5057 - accuracy: 0.8598 - val_loss: 0.5811 - val_accuracy: 0.8308 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "425/425 [==============================] - 54s 126ms/step - loss: 0.4642 - accuracy: 0.8700 - val_loss: 0.5648 - val_accuracy: 0.8383 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "425/425 [==============================] - 50s 117ms/step - loss: 0.4436 - accuracy: 0.8765 - val_loss: 0.5944 - val_accuracy: 0.8265 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "425/425 [==============================] - 56s 131ms/step - loss: 0.4258 - accuracy: 0.8803 - val_loss: 0.5230 - val_accuracy: 0.8473 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "425/425 [==============================] - 52s 123ms/step - loss: 0.4072 - accuracy: 0.8865 - val_loss: 0.5555 - val_accuracy: 0.8392 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "425/425 [==============================] - 49s 115ms/step - loss: 0.3936 - accuracy: 0.8908 - val_loss: 0.5325 - val_accuracy: 0.8445 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "425/425 [==============================] - 51s 119ms/step - loss: 0.3797 - accuracy: 0.8972 - val_loss: 0.5562 - val_accuracy: 0.8385 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "425/425 [==============================] - 52s 121ms/step - loss: 0.3572 - accuracy: 0.9048 - val_loss: 0.5353 - val_accuracy: 0.8468 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "425/425 [==============================] - 55s 130ms/step - loss: 0.3479 - accuracy: 0.9051 - val_loss: 0.5196 - val_accuracy: 0.8523 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "425/425 [==============================] - 54s 126ms/step - loss: 0.3339 - accuracy: 0.9102 - val_loss: 0.5802 - val_accuracy: 0.8372 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "425/425 [==============================] - 54s 127ms/step - loss: 0.3200 - accuracy: 0.9143 - val_loss: 0.5222 - val_accuracy: 0.8548 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "425/425 [==============================] - 50s 117ms/step - loss: 0.3074 - accuracy: 0.9178 - val_loss: 0.5262 - val_accuracy: 0.8520 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "425/425 [==============================] - 52s 122ms/step - loss: 0.2957 - accuracy: 0.9216 - val_loss: 0.5381 - val_accuracy: 0.8499 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "425/425 [==============================] - 51s 119ms/step - loss: 0.2805 - accuracy: 0.9260 - val_loss: 0.5406 - val_accuracy: 0.8511 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "425/425 [==============================] - 56s 131ms/step - loss: 0.2507 - accuracy: 0.9353 - val_loss: 0.5244 - val_accuracy: 0.8568 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "425/425 [==============================] - 52s 122ms/step - loss: 0.2457 - accuracy: 0.9367 - val_loss: 0.5238 - val_accuracy: 0.8551 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "425/425 [==============================] - 50s 118ms/step - loss: 0.2352 - accuracy: 0.9400 - val_loss: 0.5244 - val_accuracy: 0.8559 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "425/425 [==============================] - 52s 123ms/step - loss: 0.2286 - accuracy: 0.9428 - val_loss: 0.5260 - val_accuracy: 0.8549 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "425/425 [==============================] - 49s 115ms/step - loss: 0.2258 - accuracy: 0.9424 - val_loss: 0.5222 - val_accuracy: 0.8564 - lr: 1.0000e-05\n",
            "Epoch 28: early stopping\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5500 - accuracy: 0.8532\n",
            "Test accuracy: 0.8532000184059143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_resnet50_model3.history['accuracy'])\n",
        "plt.plot(history_resnet50_model3.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history_resnet50_model3.history['loss'])\n",
        "plt.plot(history_resnet50_model3.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "6R8-E9cozW8i",
        "outputId": "b51dd6a8-8c8f-49e1-a01c-075b50aca09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRcElEQVR4nO3deXzT9f0H8Nc3d9om6X1BoVxyH45LxBtmAYecUxEdIINNwYnKb455AG4OjzmZ03lNYW4gigpzOkRAQOWQ+xRQEGiBllJKm165v78/vk3a9EzSJN+kfT0fj+8j3+833yTvpNG8+BzfryCKoggiIiKiCKSQuwAiIiKixjCoEBERUcRiUCEiIqKIxaBCREREEYtBhYiIiCIWgwoRERFFLAYVIiIiilgMKkRERBSxGFSIiIgoYjGoEFHYCIKARYsW+f24M2fOQBAELF++vMnjtmzZAkEQsGXLloDqI6LIw6BC1MYsX74cgiBAEAR888039e4XRRFZWVkQBAE/+9nPZKiQiKgGgwpRG6XT6bBy5cp6+7du3Ypz585Bq9XKUBURkTcGFaI2asyYMVi9ejUcDofX/pUrV2LgwIFIT0+XqTIiohoMKkRt1JQpU3D58mVs2LDBs89ms+HDDz/E3Xff3eBjKioq8OijjyIrKwtarRbdu3fHn//8Z9S9CLvVasXDDz+MlJQUGAwG3H777Th37lyDz3n+/Hncd999SEtLg1arRe/evfHOO+8E740CWL16NQYOHAi9Xo/k5GTcc889OH/+vNcxBQUFmDFjBtq3bw+tVouMjAyMGzcOZ86c8RyzZ88e5OTkIDk5GXq9Hp06dcJ9990X1FqJyJtK7gKISB7Z2dkYNmwY3nvvPYwePRoAsG7dOpSWluKuu+7Cyy+/7HW8KIq4/fbbsXnzZsycORMDBgzA+vXr8X//9384f/48XnrpJc+xv/zlL/Hvf/8bd999N6699lp8+eWXuO222+rVcPHiRVxzzTUQBAFz585FSkoK1q1bh5kzZ8JsNmPevHktfp/Lly/HjBkzMHjwYCxZsgQXL17EX//6V2zbtg379+9HfHw8AGDSpEk4evQoHnzwQWRnZ6OwsBAbNmxAbm6uZ/vWW29FSkoKfve73yE+Ph5nzpzBxx9/3OIaiagJIhG1KcuWLRMBiLt37xZfeeUV0WAwiJWVlaIoiuLPf/5z8eabbxZFURQ7duwo3nbbbZ7HrV27VgQg/vGPf/R6vsmTJ4uCIIgnT54URVEUDxw4IAIQH3jgAa/j7r77bhGAuHDhQs++mTNnihkZGWJRUZHXsXfddZdoMpk8dZ0+fVoEIC5btqzJ97Z582YRgLh582ZRFEXRZrOJqampYp8+fcSqqirPcZ9++qkIQHzqqadEURTFK1euiADEF154odHnXrNmjedzI6LwYdcPURt2xx13oKqqCp9++inKysrw6aefNtrt87///Q9KpRK/+c1vvPY/+uijEEUR69at8xwHoN5xdVtHRFHERx99hLFjx0IURRQVFXmWnJwclJaWYt++fS16f3v27EFhYSEeeOAB6HQ6z/7bbrsNPXr0wGeffQYA0Ov10Gg02LJlC65cudLgc7lbXj799FPY7fYW1UVEvmNQIWrDUlJSMHLkSKxcuRIff/wxnE4nJk+e3OCxZ8+eRWZmJgwGg9f+nj17eu533yoUCnTp0sXruO7du3ttX7p0CSUlJXjzzTeRkpLitcyYMQMAUFhY2KL3566p7msDQI8ePTz3a7VaPPfcc1i3bh3S0tJwww034Pnnn0dBQYHn+BtvvBGTJk3C4sWLkZycjHHjxmHZsmWwWq0tqpGImsYxKkRt3N13341Zs2ahoKAAo0eP9rQchJrL5QIA3HPPPZg2bVqDx/Tr1y8stQBSi8/YsWOxdu1arF+/Hk8++SSWLFmCL7/8EldffTUEQcCHH36InTt34r///S/Wr1+P++67Dy+++CJ27tyJuLi4sNVK1JawRYWojZswYQIUCgV27tzZaLcPAHTs2BEXLlxAWVmZ1/7jx4977nffulwunDp1yuu4EydOeG27ZwQ5nU6MHDmywSU1NbVF781dU93Xdu9z3+/WpUsXPProo/jiiy9w5MgR2Gw2vPjii17HXHPNNXjmmWewZ88erFixAkePHsWqVataVCcRNY5BhaiNi4uLw2uvvYZFixZh7NixjR43ZswYOJ1OvPLKK177X3rpJQiC4Jk55L6tO2to6dKlXttKpRKTJk3CRx99hCNHjtR7vUuXLgXydrwMGjQIqampeP311726aNatW4djx455ZiJVVlbCYrF4PbZLly4wGAyex125cqXeNOwBAwYAALt/iEKIXT9E1GjXS21jx47FzTffjMcffxxnzpxB//798cUXX+A///kP5s2b5xmTMmDAAEyZMgV///vfUVpaimuvvRabNm3CyZMn6z3ns88+i82bN2Po0KGYNWsWevXqheLiYuzbtw8bN25EcXFxi96XWq3Gc889hxkzZuDGG2/ElClTPNOTs7Oz8fDDDwMAvv/+e4wYMQJ33HEHevXqBZVKhTVr1uDixYu46667AAD//Oc/8fe//x0TJkxAly5dUFZWhrfeegtGoxFjxoxpUZ1E1DgGFSLyiUKhwCeffIKnnnoK77//PpYtW4bs7Gy88MILePTRR72Ofeedd5CSkoIVK1Zg7dq1uOWWW/DZZ58hKyvL67i0tDTs2rULTz/9ND7++GP8/e9/R1JSEnr37o3nnnsuKHVPnz4dMTExePbZZ/HYY48hNjYWEyZMwHPPPecZj5OVlYUpU6Zg06ZN+Ne//gWVSoUePXrggw8+wKRJkwBIg2l37dqFVatW4eLFizCZTBgyZAhWrFiBTp06BaVWIqpPEOu2ZRIRERFFCI5RISIioojFoEJEREQRi0GFiIiIIpbsQeX8+fO45557kJSUBL1ej759+2LPnj1yl0VEREQRQNZZP1euXMHw4cNx8803Y926dUhJScEPP/yAhIQEOcsiIiKiCCHrrJ/f/e532LZtG77++mu5SiAiIqIIJmtQ6dWrF3JycnDu3Dls3boV7dq1wwMPPIBZs2Y1eLzVavU6A6TL5UJxcTGSkpIgCEK4yiYiIqIWEEURZWVlyMzMhELRzCgUUUZarVbUarXiggULxH379olvvPGGqNPpxOXLlzd4/MKFC0UAXLhw4cKFC5dWsOTl5TWbFWRtUdFoNBg0aBC2b9/u2feb3/wGu3fvxo4dO+odX7dFpbS0FB06dEBeXh6MRmNYaiYiIqKWMZvNyMrKQklJCUwmU5PHyjqYNiMjA7169fLa17NnT3z00UcNHq/VaqHVauvtNxqNDCpERERRxpdhG7JOTx4+fHi9y69///339S69TkRERG2TrEHl4Ycfxs6dO/GnP/0JJ0+exMqVK/Hmm29izpw5cpZFREREEULWoDJ48GCsWbMG7733Hvr06YM//OEPWLp0KaZOnSpnWURERBQhovrqyWazGSaTCaWlpU2OUXE6nbDb7WGsjEJFrVZDqVTKXQYREbWAr7/fgMyDaUNNFEUUFBSgpKRE7lIoiOLj45Gens5z5xARtQGtOqi4Q0pqaipiYmL4wxblRFFEZWUlCgsLAUizxoiIqHVrtUHF6XR6QkpSUpLc5VCQ6PV6AEBhYSFSU1PZDURE1MrJfvXkUHGPSYmJiZG5Ego299+U446IiFq/VhtU3Njd0/rwb0pE1Ha0+qBCRERE0YtBpY3Izs7G0qVL5S6DiIjILwwqEUYQhCaXRYsWBfS8u3fvxuzZs4NbLBERUYi12lk/LeFyiXC4pPPgaVThzXL5+fme9ffffx9PPfWU1/WQ4uLiPOuiKMLpdEKlav7PmJKSEtxCiYiIwoAtKg0oqbLjeIEZ50uqwv7a6enpnsVkMkEQBM/28ePHYTAYsG7dOgwcOBBarRbffPMNTp06hXHjxiEtLQ1xcXEYPHgwNm7c6PW8dbt+BEHAP/7xD0yYMAExMTHo1q0bPvnkkzC/WyIioqa1qaAiiiIqbY5mF6vDCYvdiXJr88f6sgT7KgW/+93v8Oyzz+LYsWPo168fysvLMWbMGGzatAn79+/HqFGjMHbsWOTm5jb5PIsXL8Ydd9yBQ4cOYcyYMZg6dSqKi4uDWisREVFLtKmunyq7E72eWh/21/3u6RzEaIL3UT/99NP46U9/6tlOTExE//79Pdt/+MMfsGbNGnzyySeYO3duo88zffp0TJkyBQDwpz/9CS+//DJ27dqFUaNGBa1WIiKilmhTLSqtxaBBg7y2y8vLMX/+fPTs2RPx8fGIi4vDsWPHmm1R6devn2c9NjYWRqPRc3p6IiKiSNCmWlT0aiW+ezqn2eOsDid+uFgOhSCgV2bTV3X09XWDKTY21mt7/vz52LBhA/785z+ja9eu0Ov1mDx5Mmw2W5PPo1arvbYFQYDL5QpqrURERC3RpoKKIAg+dcFolAroqsOFXq2M+DOhbtu2DdOnT8eECRMASC0sZ86ckbcoIiKiIGDXTwMUippg4nQFdyBsKHTr1g0ff/wxDhw4gIMHD+Luu+9mywgREbUKDCoNUAgCFNWtKK4gz9gJhb/85S9ISEjAtddei7FjxyInJwc/+clP5C6LiIioxQQx2HNnw8hsNsNkMqG0tBRGo/dYEovFgtOnT6NTp07Q6XR+P/d3+WY4nC50S42DPogzdqjlWvq3JSIieTX1+10XW1QaoaxuUXFGbYwjIiKKfgwqjVBWj1NxRcEYFSIiotaKQaUR7vG00TCYloiIqLViUGmEu0XFGb1DeIiIiKIeg0ojPEGFLSpERESyYVBphDKKpicTERG1VgwqjVCwRYWIiEh2DCqNYNcPERGR/BhUGlHT9SNzIURERG0Yg0ojornr56abbsK8efM829nZ2Vi6dGmTjxEEAWvXrm3xawfreYiIiAAGlUZ5zkwb5qAyduxYjBo1qsH7vv76awiCgEOHDvn1nLt378bs2bODUZ7HokWLMGDAgHr78/PzMXr06KC+FhERtV0MKo1QVn8y4Z71M3PmTGzYsAHnzp2rd9+yZcswaNAg9OvXz6/nTElJQUxMTLBKbFJ6ejq0Wm1YXouIiFo/BpVGyNX187Of/QwpKSlYvny51/7y8nKsXr0a48ePx5QpU9CuXTvExMSgb9++eO+995p8zrpdPz/88ANuuOEG6HQ69OrVCxs2bKj3mMceewxXXXUVYmJi0LlzZzz55JOw2+0AgOXLl2Px4sU4ePAgBEGAIAieeut2/Rw+fBi33HIL9Ho9kpKSMHv2bJSXl3vunz59OsaPH48///nPyMjIQFJSEubMmeN5LSIiatva1mWBRRGwV/p0qNLpgmCvhAjAZVVCUd0VFBB1DODj41UqFX7xi19g+fLlePzxxyFUP2716tVwOp245557sHr1ajz22GMwGo347LPPcO+996JLly4YMmRIs8/vcrkwceJEpKWl4dtvv0VpaanXeBY3g8GA5cuXIzMzE4cPH8asWbNgMBjw29/+FnfeeSeOHDmCzz//HBs3bgQAmEymes9RUVGBnJwcDBs2DLt370ZhYSF++ctfYu7cuV5BbPPmzcjIyMDmzZtx8uRJ3HnnnRgwYABmzZrl02dGREStV9sKKvZK4E+ZPh2qAtA3WK/7+wuAJtbnw++77z688MIL2Lp1K2666SYAUrfPpEmT0LFjR8yfP99z7IMPPoj169fjgw8+8CmobNy4EcePH8f69euRmSl9Fn/605/qjSt54oknPOvZ2dmYP38+Vq1ahd/+9rfQ6/WIi4uDSqVCenp6o6+1cuVKWCwWvPvuu4iNld7/K6+8grFjx+K5555DWloaACAhIQGvvPIKlEolevTogdtuuw2bNm1iUCEiInb9RKIePXrg2muvxTvvvAMAOHnyJL7++mvMnDkTTqcTf/jDH9C3b18kJiYiLi4O69evR25urk/PfezYMWRlZXlCCgAMGzas3nHvv/8+hg8fjvT0dMTFxeGJJ57w+TVqv1b//v09IQUAhg8fDpfLhRMnTnj29e7dG0ql0rOdkZGBwsJCv16LiIhap7bVoqKOkVo3fHS8oAx2pwtdU2Kh17Tgo1L7P5B15syZePDBB/Hqq69i2bJl6NKlC2688UY899xz+Otf/4qlS5eib9++iI2Nxbx582Cz2QKvr44dO3Zg6tSpWLx4MXJycmAymbBq1Sq8+OKLQXuN2tRqtde2IAhwuVwheS0iIooubSuoCIJfXTCCxgXR4YRTFQNo1M0/IIjuuOMOPPTQQ1i5ciXeffdd3H///RAEAdu2bcO4ceNwzz33AJDGnHz//ffo1auXT8/bs2dP5OXlIT8/HxkZGQCAnTt3eh2zfft2dOzYEY8//rhn39mzZ72O0Wg0cDqdzb7W8uXLUVFR4WlV2bZtGxQKBbp37+5TvURE1Lax66cJntPoy3DOt7i4ONx5551YsGAB8vPzMX36dABAt27dsGHDBmzfvh3Hjh3Dr371K1y8eNHn5x05ciSuuuoqTJs2DQcPHsTXX3/tFUjcr5Gbm4tVq1bh1KlTePnll7FmzRqvY7Kzs3H69GkcOHAARUVFsFqt9V5r6tSp0Ol0mDZtGo4cOYLNmzfjwQcfxL333usZn0JERNQUBpUmyH29n5kzZ+LKlSvIycnxjCl54okn8JOf/AQ5OTm46aabkJ6ejvHjx/v8nAqFAmvWrEFVVRWGDBmCX/7yl3jmmWe8jrn99tvx8MMPY+7cuRgwYAC2b9+OJ5980uuYSZMmYdSoUbj55puRkpLS4BTpmJgYrF+/HsXFxRg8eDAmT56MESNG4JVXXvH/wyAiojZJEMUwn9EsiMxmM0wmE0pLS2E0Gr3us1gsOH36NDp16gSdThfQ85+9XIHSKjsy4/VIjuNJzCJFMP62REQkn6Z+v+tii0oT5G5RISIiausYVJrgDiouBhUiIiJZMKg0wX02Wmf09o4RERFFNQaVJrDrh4iISF6tPqi0ZKywUmBQiURRPP6biIj81GqDivtsp5WVvl2EsCGeMSr8XYwo7r9p3TPaEhFR69Nqz0yrVCoRHx/vuWZMTEyM50rEvrLbHRAdNthFJyyWVvtRRQ1RFFFZWYnCwkLEx8d7XR+IiIhap1b96+u+sm+gF7izO10oNFullpVynq8jUsTHxzd51WYiImo9WnVQEQQBGRkZSE1Nhd1u9/vx+SVVuP8/30KjUmDdQzeEoELyl1qtZksKEVEb0qqDiptSqQzoxy3BqMD5MicAJ5RqDdTKVjukh4iIKCLxl7cJcdqaHFdmcchYCRERUdska1BZtGgRBEHwWnr06CFnSV5USgViNVJLTJnF/64jIiIiahnZu3569+6NjRs3erZVKtlL8mLQqVFhc8JcxRYVIiKicJM9FahUqoiewWHQqVBgZosKERGRHGQfo/LDDz8gMzMTnTt3xtSpU5Gbmyt3SV4MOinLmTlGhYiIKOxkbVEZOnQoli9fju7duyM/Px+LFy/G9ddfjyNHjsBgMNQ73mq1wmq1erbNZnPIazTopLOfskWFiIgo/GQNKqNHj/as9+vXD0OHDkXHjh3xwQcfYObMmfWOX7JkCRYvXhzOEj0tKpz1Q0REFH6yd/3UFh8fj6uuugonT55s8P4FCxagtLTUs+Tl5YW8ppoWFQYVIiKicIuooFJeXo5Tp04hIyOjwfu1Wi2MRqPXEmpGT4sKu36IiIjCTdagMn/+fGzduhVnzpzB9u3bMWHCBCiVSkyZMkXOsrwY9WxRISIikousY1TOnTuHKVOm4PLly0hJScF1112HnTt3IiUlRc6yvNTM+mGLChERUbjJGlRWrVol58v7hINpiYiI5BNRY1QikUHL6clERERyYVBpBltUiIiI5MOg0gz39GSemZaIiCj8GFSaYeD0ZCIiItkwqDTDWN2iYnW4YHO4ZK6GiIiobWFQaUacrmZiFFtViIiIwotBpRlKhYA4La+gTEREJAcGFR9wnAoREZE8GFR8wCnKRERE8mBQ8UHNFZTZokJERBRODCo+qLneD1tUiIiIwolBxQc1LSoMKkREROHEoOIDDqYlIiKSB4OKD4xsUSEiIpIFg4oPPGNUqtiiQkREFE4MKj4wcnoyERGRLBhUfOAZTGtliwoREVE4Maj4gCd8IyIikgeDig84PZmIiEgeDCo+4PRkIiIieTCo+IBnpiUiIpIHg4oPjHqp68fmcMFid8pcDRERUdvBoOKDOI0KgiCtc5wKERFR+DCo+EChEBCn4TgVIiKicGNQ8RGnKBMREYUfg4qPOEWZiIgo/BhUfMQpykREROHHoOIjdv0QERGFH4OKj9xdP2a2qBAREYUNg4qPjHq2qBAREYUbg4qP2KJCREQUfgwqPuIYFSIiovBjUPFRzfRktqgQERGFC4OKj4xsUSEiIgo7BhUfseuHiIgo/BhUfMSuHyIiovBjUPERW1SIiIjCj0HFR7Wv9SOKoszVEBERtQ0MKj5yD6a1OV2wOlwyV0NERNQ2MKj4KFajgiBI6zzpGxERUXgwqPhIoRAQp+U4FSIionBiUPGDsdY4FSIiIgo9BhU/1Mz8YdcPERFRODCo+IFTlImIiMKLQcUPPOkbERFReDGo+IEtKkREROHFoOIH92BacxVbVIiIiMKBQcUP7hYVM1tUiIiIwoJBxQ8GTk8mIiIKKwYVP3B6MhERUXhFTFB59tlnIQgC5s2bJ3cpjeJgWiIiovCKiKCye/duvPHGG+jXr5/cpTTJc2ZaK1tUiIiIwkH2oFJeXo6pU6firbfeQkJCgtzlNIktKkREROEle1CZM2cObrvtNowcOVLuUppl4PRkIiKisFLJ+eKrVq3Cvn37sHv3bp+Ot1qtsFqtnm2z2Ryq0hpk1Ne0qIiiCEEQwvr6REREbY1sLSp5eXl46KGHsGLFCuh0Op8es2TJEphMJs+SlZUV4iq9uVtUHC4RFrsrrK9NRETUFgmiKIpyvPDatWsxYcIEKJVKzz6n0wlBEKBQKGC1Wr3uAxpuUcnKykJpaSmMRmPIaxZFEV1+/z+4RGDX70cg1ehbwCIiIqIaZrMZJpPJp99v2bp+RowYgcOHD3vtmzFjBnr06IHHHnusXkgBAK1WC61WG64S6xEEAXFaFcwWB8wWB1JDn42IiIjaNNmCisFgQJ8+fbz2xcbGIikpqd7+SGLQqWG2OHjSNyIiojCQfdZPtOEUZSIiovCRddZPXVu2bJG7hGYZeb0fIiKisGGLip9qrqDMrh8iIqJQY1Dxk1HvblFhUCEiIgo1BhU/cYwKERFR+DCo+IlBhYiIKHwYVPzkud4Pu36IiIhCjkHFT2xRISIiCh8GFT8ZdBxMS0REFC4MKn5iiwoREVH4MKj4ycjzqBAREYUNg4qfeGZaIiKi8GFQ8ZOhVlARRVHmaoiIiFo3BhU/uceoOF0iquxOmashIiJq3RhU/BSjUUKpEACw+4eIiCjUGFT8JAgC4rTumT8cUEtERBRKDCoBqLmCMltUiIiIQolBJQAGzvwhIiIKCwaVAHhaVKrY9UNERBRKDCoB4LlUiIiIwoNBJQBGHQfTEhERhQODSgB4vR8iIqLwYFAJAK+gTEREFB4MKgFgiwoREVF4MKgEwN2iwvOoEBERhRaDSgAMHExLREQUFgwqAeCZaYmIiMKDQSUARj0H0xIREYUDg0oAjBxMS0REFBYMKgFwD6YttzogiqLM1RAREbVeDCoBcI9RcbpEVNqcMldDRETUejGoBECvVkKpEACw+4eIiCiUGFQCIAgCpygTERGFAYNKgDhFmYiIKPQYVAJk0LrPTssWFSIiolBhUAmQUc8pykRERKHGoBIgXkGZiIgo9BhUAsQrKBMREYUeg0qAjGxRISIiCjkGlQCxRYWIiCj0GFQCxKBCREQUegwqAeJgWiIiotBjUAmQ54RvVWxRISIiChUGlQC5B9PyhG9EREShw6ASII5RISIiCj0GlQBxjAoREVHoBRRU8vLycO7cOc/2rl27MG/ePLz55ptBKyzSGatbVMqtDoiiKHM1RERErVNAQeXuu+/G5s2bAQAFBQX46U9/il27duHxxx/H008/HdQCZeGwASc+B85sa/QQd4uKSwQqbM5wVUZERNSmBBRUjhw5giFDhgAAPvjgA/Tp0wfbt2/HihUrsHz58mDWJ48dfwPeuxP4+sVGD9GpFVApBADs/iEiIgqVgIKK3W6HVqsFAGzcuBG33347AKBHjx7Iz88PXnVy6TVeuv1xC1Be2OAhgiBwQC0REVGIBRRUevfujddffx1ff/01NmzYgFGjRgEALly4gKSkpKAWKIukLkC7gYDoBI6uafQwd/ePuYotKkRERKEQUFB57rnn8MYbb+Cmm27ClClT0L9/fwDAJ5984ukSinp9fy7dHl7d6CFGPVtUiIiIQimgoHLTTTehqKgIRUVFeOeddzz7Z8+ejddff93n53nttdfQr18/GI1GGI1GDBs2DOvWrQukpODrPREQFMC53UDx6QYPMWh50jciIqJQCiioVFVVwWq1IiEhAQBw9uxZLF26FCdOnEBqaqrPz9O+fXs8++yz2Lt3L/bs2YNbbrkF48aNw9GjRwMpK7gMaUCnG6X1Ix82fAjHqBAREYVUQEFl3LhxePfddwEAJSUlGDp0KF588UWMHz8er732ms/PM3bsWIwZMwbdunXDVVddhWeeeQZxcXHYuXNnIGUFn7v759BqoIFzpdSc9I1BhYiIKBQCCir79u3D9ddfDwD48MMPkZaWhrNnz+Ldd9/Fyy+/HFAhTqcTq1atQkVFBYYNGxbQcwRdz58BSi1QdAIoOFzv7poWFXb9EBERhYIqkAdVVlbCYDAAAL744gtMnDgRCoUC11xzDc6ePevXcx0+fBjDhg2DxWJBXFwc1qxZg169ejV4rNVqhdVq9WybzeZAyvedzgRclQMc+0QaVJvRz+tuI7t+iIiIQiqgFpWuXbti7dq1yMvLw/r163HrrbcCAAoLC2E0Gv16ru7du+PAgQP49ttvcf/992PatGn47rvvGjx2yZIlMJlMniUrKyuQ8v3T7w7p9shHgMvldRev90NERBRaAQWVp556CvPnz0d2djaGDBni6ar54osvcPXVV/v1XBqNBl27dsXAgQOxZMkS9O/fH3/9618bPHbBggUoLS31LHl5eYGU75+uPwW0JsB8Hsjd7nWXu+vHzBYVIiKikAio62fy5Mm47rrrkJ+f7zmHCgCMGDECEyZMaFFBLpfLq3unNq1W6zkjbtiodUCvscD+f0vdP9nXee4y6tmiQkREFEoBBRUASE9PR3p6uucqyu3bt/f7ZG8LFizA6NGj0aFDB5SVlWHlypXYsmUL1q9fH2hZodH3DimoHF0LjH4BUGkAcHoyERFRqAXU9eNyufD000/DZDKhY8eO6NixI+Lj4/GHP/wBrjrjOJpSWFiIX/ziF+jevTtGjBiB3bt3Y/369fjpT38aSFmhk30dEJcOWEqAkxs9uzk9mYiIKLQCalF5/PHH8fbbb+PZZ5/F8OHDAQDffPMNFi1aBIvFgmeeecan53n77bcDefnwUyiBPpOAna9K3T89xgCoPUaFXT9EREShEFBQ+ec//4l//OMfnqsmA0C/fv3Qrl07PPDAAz4HlajSd7IUVE6sA6xlgNbgCSrlVgdcLhEKhSBzkURERK1LQF0/xcXF6NGjR739PXr0QHFxcYuLikiZVwNJXQFHFXD8MwCAsbrrRxSBChu7f4iIiIItoKDSv39/vPLKK/X2v/LKK+jXr18Dj2gFBKHeFZW1KgXUSqkVheNUiIiIgi+grp/nn38et912GzZu3Og5h8qOHTuQl5eH//3vf0EtMKL0mQxsWQKc2gyUX4IQlwKDTo3iChvMFjsyoZe7QiIiolYloBaVG2+8Ed9//z0mTJiAkpISlJSUYOLEiTh69Cj+9a9/BbvGyJHcVeoCEp3Ad2sB8DT6REREoRTweVQyMzPrDZo9ePAg3n77bbz55pstLixi9b0DuLAfOPQBMGQWT6NPREQUQgG1qLRpfSYCEIBzu4Di0zzpGxERUQgxqPjLkA50ukFaP/IRr/dDREQUQgwqgag1+8egdbeosOuHiIgo2PwaozJx4sQm7y8pKWlJLdGj1+3AZ48Cl46ja/IZAGp2/RAREYWAX0HFZDI1e/8vfvGLFhUUFXQm4KpbgWP/xUDzJgCjYK5iiwoREVGw+RVUli1bFqo6ok/fnwPH/oueRV9AwK1sUSEiIgoBjlEJVLccQGtEnLUAg4UTHKNCREQUAgwqgVLrgJ7SRRnHKbezRYWIiCgEGFRaou9kAMAY5beoqqqSuRgiIqLWh0GlJTrdALs+BQlCOXpV7pa7GiIiolaHQaUlFEpUXjUOAHCzfavMxRAREbU+DCot5OojnfztZuyBy1ImczVEREStC4NKC+k7DsJpVxr0gg2WI/+VuxwiIqJWhUGlhXQaFT4TrwMACIdXy1wNERFR68KgEgSbNdJFCnW5W4GKIpmrISIiaj0YVIKgWJ+NQ65OEEQncHSN3OUQERG1GgwqQWDQqfAf57XSBrt/iIiIgoZBJQgMOhU+dQ6DCAHI+xa4ckbukoiIiFoFBpUgMGjVuIhEFCQOlnYc+UjegoiIiFoJBpUgMOiki1AfS86Rdhz+UMZqiIiIWg8GlSAw6NQAgIOG6wGlBij8Dig4InNVRERE0Y9BJQjcLSqXHDFAt1ulnRxUS0RE1GIMKkFg1EstKmUWB9BXOqU+jnwEuFwyVkVERBT9GFSCwN2iUmaxA1flABoDUJoH5O2UuTIiIqLoxqASBEZPUHEAaj3Qc6x0B7t/iIiIWoRBJQjcg2nLLHZpR9/J0u3RNYDDJlNVRERE0Y9BJQgMtVtUAKDTjUBsKlB1Bfhxs4yVERERRTcGlSCoaVGpDipKFdBjjLR+5huZqiIiIop+DCpB4G5RKbc64HSJ0s52g6TbC/tlqoqIiCj6MagEgTuoAEC5u1Ul82rpNv8gpykTEREFiEElCLQqJbQq6aM0uwfUpvQAVDrAagaKf5SxOiIioujFoBIkDY5TSe8rrecfkKcoIiKiKMegEiTG2id9c3N3/3CcChERUUAYVIKk3hRlgEGFiIiohRhUgsTT9WOt1aKSMUC65YBaIiKigDCoBEmDLSrJVwHqGMBWDlw+KVNlRERE0YtBJUjcQcVcVatFRakC0vtJ6+z+ISIi8huDSpDUm/XjxnEqREREAWNQCRJjdVAxM6gQEREFDYNKkBgamp4MAJkDpNuCQ4DLGd6iiIiIohyDSpA0OJgWAJK6Apo4wF4JFH0vQ2VERETRi0ElSGrGqNRpUVEogYz+0jq7f4iIiPzCoBIkxsZaVACOUyEiIgoQg0qQNDrrB6g58RuDChERkV9kDSpLlizB4MGDYTAYkJqaivHjx+PEiRNylhQwz3lU6nb9ADUtKgWHAWcDQYaIiIgaJGtQ2bp1K+bMmYOdO3diw4YNsNvtuPXWW1FRUSFnWQFxB5VKmxMOZ53T5Sd2BrRGwGEBLh2XoToiIqLopJLzxT///HOv7eXLlyM1NRV79+7FDTfcIFNVgXF3/QBAudWB+BhNzZ0KhTSg9szXUvdPeh8ZKiQiIoo+ETVGpbS0FACQmJgocyX+06gU0Kmlj5MDaomIiIJD1haV2lwuF+bNm4fhw4ejT5+GWxysViusVqtn22w2h6s8nxh0aljs1kbGqQyQbvMPhLMkIiKiqBYxLSpz5szBkSNHsGrVqkaPWbJkCUwmk2fJysoKY4XNa/Skb0CtAbVHAIctjFURERFFr4gIKnPnzsWnn36KzZs3o3379o0et2DBApSWlnqWvLy8MFbZvCanKCd0AnQmwGkFLh0Lc2VERETRSdagIooi5s6dizVr1uDLL79Ep06dmjxeq9XCaDR6LZHE2Nj1fgBAEDhOhYiIyE+yBpU5c+bg3//+N1auXAmDwYCCggIUFBSgqqpKzrIC5jmXSlUDQQXgid+IiIj8JGtQee2111BaWoqbbroJGRkZnuX999+Xs6yAGbRNdP0AtVpUDoSnICIioign66wfURTlfPmg8wymtTYTVC4eBRxWQKUNU2VERETRKSIG07YWRn0jV1B2i+8A6BMBl10KK0RERNQkBpUgqrneTyMtKoJQcz4VjlMhIiJqFoNKEDU5PdnN3f3DE78RERE1i0EliAxNTU924xRlIiIinzGoBFGTZ6Z1cweVwmOAPTqnYRMREYULg0oQGau7fho9jwoAGNsBsSmAy8EBtURERM1gUAkin1pUBIEnfiMiIvIRg0oQuQfTVtmdsDtdjR/IE78RERH5hEEliNwtKgBQ7ss4FbaoEBERNYlBJYjUSgX0aiUAHwfUXjoG2CrDUBkREVF0YlAJspqTvjU1oDYDiEsDRBdQcDhMlREREUUfBpUg82lALcATvxEREfmAQSXIas5O20SLCsBxKkRERD5gUAmyZq/348agQkRE1CwGlSAz+tqi4j6XyqUTgLU8tEURERFFKQaVIPN5jIohDTBkAhA5oJaIiKgRDCpBZtT72KICsPuHiIioGQwqQWbQ+tiiAjCoEBERNYNBJch87voBGFSIiIiawaASZO7pyU2e8M0tc4B0e/kkYDGHrigiIqIoxaASZH61qMQmA6YsSANqD4W2MCIioijEoBJkfrWoADWtKuz+ISIiqodBJcj8alEBOE6FiIioCQwqQebzCd/c3Cd+u3AgJPUQERFFMwaVIDPqpRYVi90Fu9PV/APcLSrFp4CqktAVRkREFIUYVIIsrvo8KoCP3T8xiUB8R2k9/2CIqiIiIopODCpBplIqEKNRAvCj+4fjVIiIiBrEoBICHFBLREQUHAwqIeCZolzl5xTl/AMhqYeIiChaMaiEgLtFxexri0pGf+n2yhmgsjg0RREREUUhBpUQMPg7RVmfACR2ltbZqkJEROTBoBICfo9RAThOhYiIqAEMKiFQc9I3P4IKT/xGRERUD4NKCBg9LSo+dv0AtVpUDgS/ICIioijFoBICAXX9uAfUluYCFUUhqIqIiCj6MKiEgGcwrdWPFhWdEUjqJq2zVYWIiAgAg0pIeKYnV/nRogLUOp8KB9TW47ACTj+CHxERtQqq5g8hf/k9Pdkt82rg8Gq2qNR1djuwairgtAHZ1wNdbgG6jpCmdAuC3NUREVEIMaiEQEBjVABOUW7I0bXAx7MBp1Xa/n6dtADSxRzdoaXTDYDOJFuZREQUGgwqIeD3mWnd0vsBEADzeaDsImBIC35x0eTbN4B1jwEQgR4/A657BDi9FTj1JZC7Eyg5C+xdJi2CEmg/WAotXUZI3WgKpdzvgIiIWohBJQSMgXb9aOOAlO7ApePSGWoNOcEvLhq4XMDGhcD2l6Xtwb8ERj8vBY/2A4HrHwGs5cCZb4BTm6TgcvkkkLdTWjY/I53tt/NNUmjpcgtgaifrWyIiosAwqISAO6hYHS7YHC5oVH6MWc4YIAWVCweAq9pgUHHYgP/MAQ5/IG2PeEpqSak7FkUbB3QfJS0AcOWsFFhObQJ+/AqougIcXSMtAJDSQwotN8wHYhLD936IiKhFGFRCIE5X87GWWexIitP6/uDMq4FDq9rmOBWLGXj/Hql7R6ECbv8bMOBu3x6b0BEYNENanA7g/N6a1pbze6Xw517u/Ti074OIiIKGQSUElAoBsRolKmxOlFkc/gcVoO0FFXM+sOLnwMXDgCYOuONdabxJIJQqoMNQabn599IVqU9uAtb8Sgov+YeAjH7BrZ+IiEKC51EJEfcUZbO/41TS+wKCAigvkH6824JLJ4C3fyqFlNhUYPpngYeUhsQkAv1+DvSeIG1v+2vwnpuIiEKKQSVEAp6irImRxlMA0oDa1i53J/D2rUBpHpDUFfjlhpoT3wXb8N9It0fXAFfOhOY1iIgoqBhUQsQQyIUJ3dpK98+x/wLvjgMsJdLU4vu+ABKyQ/d6Gf2lGUCiE9jx99C9DhERBQ2DSoi4u35KKhlUGrTrLeD9ewGHBeg+BvjFJ0BsUuhfd/hD0u2+d4GKy6F/PSIiahEGlRBJjNUAAJ76z1E88sEBHD5X6vuDawcVUQxBdTISRWDjIuB/8wGIwMAZwB3/krq8wqHTjVLLiqMK2P1WeF6TiIgCxlk/ITLr+s44XVSBA3kl+HjfeXy87zwGdUzA9OHZyOmdDrWyiYyY1luanltxCTBfCOxkZdYyIPdbIHeHdPp5rRHQGuos1fs0cTW3ihBmV4cN+ORBafo1ANzyBHD9/PBer0cQgOHzgA9nSGe+vfY34QtJRETkN1mDyldffYUXXngBe/fuRX5+PtasWYPx48fLWVLQ9Mo0Yu2c4difewXLt5/BZ4fysefsFew5ewUZJh3uuaYjpgzp4Gl58aLWAyk9pVkwF/b7FlRsFdLA1DNfS2dsPb9PGovhL03dMFO9xCYDsSnVS+31FEAX33zAsZZJXT0/bpZOd3/734Crp/pfXzD0vF0aC3PlDLD/38DQ2fLUQUREzZI1qFRUVKB///647777MHHiRDlLCZmrOyTg6g4J+P2Ynlix8yxWfJuL/FILXlh/Ai9v+gHjB7TD9OHZ6Jlh9H5g5oCaoNLzZ/Wf2FYJnNsFnP5aCifn9wKuOjOM4jsC2ddJp5O3lkmLrbxm3WquWXc/1lYmLWV+vElBWSu8NBBo9InA1ueAgkOAOlY6R0q3kf58jMGlVAHD5krdTzv+Bgy6T9pHREQRRxDFyBgEIQiC3y0qZrMZJpMJpaWlMBqNzT8gAljsTnx6KB/Ltp3G0Qtmz/5rOidixvBOGNkzDUqFAOx+G/jsEem07/d+DNgttYLJN8D5PYDT5v3kpiwg+3opnHS6Hojv4FtRoigNarWWe4cX92IpBSovS11RFZeAiqKadUuJ728+NgW4+wOg3U98f0yo2KuAl/oAlUXApLeBvpPlroiIqM3w5/eb/4wMM51aickD22PST9phz9krWL7tDD4/WoCdPxZj54/FaJ+gx7Rh2ZjSri/iACBvF7DsNuDcbmmsSW3GdnWCScfAxnsIgtTdpNYDcSn+PdZhazzE1F6PSQLGPA8kdva/vlBQ64Ghv5IuYLhtKdBnUnjHyhARkU+iKqhYrVZYrTU/1mazuYmjI5sgCBicnYjB2Ym4UFKFf+08i/d25eLclSo8879j+JvahX0qNVS2MuDsN9KD4tKlQOIOJ4md5f9xVWkAY4a0RJvBvwS+eQkoOCyNnelyi9wVERFRHVEVVJYsWYLFixfLXUbQZcbr8dioHnhoRDes3X8ey7adwYmLZfi9azqGKo7jsNAdJWnXIK1TbwzISkD/rHhkmHQQ5A4p0S4mEfjJL4BvX5dOq8+gQkQUcaJqjEpDLSpZWVlRNUbFF6IoYsePl/HP7WfwzQ9FqLDVn72TYtCif/t4XN0hHv3bx6NvexNMerUM1Ua5klzgrwOkGVKzt9Scw4aIiEKm1Y5R0Wq10Gr9uBJxlBIEAdd2Sca1XZLhdIk4dakcB3JLcOBcCQ7mleB4QRkulVmx8dhFbDx20fO4zimxGNA+HgOqw0uPDAO0KqWM7yQKxHeQxqcc/gDY9jLw82VyV0RERLXIGlTKy8tx8uRJz/bp06dx4MABJCYmokMHH2estHJKhYCr0gy4Ks2AOwZnAQCqbE58l1+KA3mlOJAnhZfc4kr8eKkCP16qwMf7zwMANEoFemYacXWW1PJydVYCshL17DKqa/hvpKDy3Vqg+CkgsZPcFRERUTVZu362bNmCm2++ud7+adOmYfny5c0+PhqnJ4dKcYUNB6tbXNzh5UoD1xlKitVIoaVDAq7Oike/rHjEaaOqYS00/j0JOLlRGmB724tyV0NE1Kr58/sdMWNUAsGg0jhRFJFXXIX9eVdwIK8E+3NLcPRCKexO7z+3IADd0wyeFperO8SjS0ocFIo21upy+ivgn2MBlQ54+Kh0sjoiIgoJBhVqkMXuxHf5ZuzPLcH+3CvYn1uC8yVV9Y4zaFUY0CG+ustImmXU4Kn+WxNRBN66WToT8I2PATf/Xu6KiIhaLQYV8lmh2YL91S0u+3Ov4NC5UlTZG55l1DUlDl1TvZdUg7b1jHk5uhZYPU265MDDRwFNrNwVERG1SgwqFDCH04UTF8uqg0sJ9uddwY+XKho93qBToUtKHLrVCTDtE2KkSwFEE5cT+NtA4MppYNRzwDW/lrsiIqJWiUGFgqrMYsepSxU4WVjuWU5dKsfZyxVwNfLt0agU6Jwc6wkuXVLi0DklFp2SYxGjieDBu+5rLJmygN/sB5Q8Nw0RUbAxqFBYWB1OnCmqxMnCcvxQWOYJMT8WVcDmcDX6uAyTDp2SpdDSOSUOnavX2yfooVIqwvgOGmCvApb2la5PNPEtoN8d8tZDRNQKMaiQrJwuEeeuVNZrgTldVNHglGk3tVJAh8QYdEqOQ5fq1pdOybHolBKLlLgwjoX56gXgyz8CaX2AX38j//WUiIhaGQYVilhXKmw4fVk6Md3pIim8SOsVsDbRCmPQqpBu0iE+Rg2TXgOTXo34GDXiq2+NejXiYzSe7Xi9BgadKrBp1pXFwEt9AHsFcM9HQNeRLXjHRERUV6s9hT5Fv4RYDRJiNfhJhwSv/S6XiAulVThdVOEJLz8WSWHm3JUqlFkdKCss9+u1BAEw6moCTWKsBncN6YCc3ulNPzAmERg4Hdj5KvDNUgYVIiIZsUWFIp7F7kRucSWKyqwoqbKjpNKOkiobSqvsKK2Utkur7CipsqO00oaSKjsqG7iQo9u4AZlYfHtvxMc0cW6Ykjzg5QGAywHM+hJoNzD4b4yIqI1i1w+1eTaHSwoyVTZPkNl1uhhvff0jXKJ0XphnJ/bFiJ5pjT/Jx78CDq0Ceo0H7vhn2GonImrtGFSIGnEgrwSPfnAAp6rPDTN5YHs8+bNeMOkbmIZ88Sjw2rWAoADm7gGSuoS5WiKi1smf32+Z54IShdeArHh89pvrMfuGzhAE4MO95zBq6VfY+v2l+gen9Qa63QqILmDHK+EvloiIGFSo7dGplfj9mJ5Y/athyE6KQX6pBdPe2YUFHx9GudXhffDwh6Tb/SuA8sLwF0tE1MYxqFCbNSg7Ef976HpMvzYbAPDerlzkvPQVtp8qqjmo43Cg3SDAaQW+fUOeQomI2jAGFWrTYjQqLLq9N96bdQ3aJ+hxvqQKd7/1LRb+5wgqbQ5pjrO7VWX3W4DVvynSRETUMgwqRACGdUnC5/NuwNShHQAA/9xxFqP/+jV2nykGetwGJHYBLKXAvndlrpSIqG1hUCGqFqdV4ZkJffGvmUOQYdLh7OVK3PHGDvzxfydgv2audNCOV4HTXwGXTgBVV4DonTRHRBQVOD2ZqAFmix1//PQ7fLDnHACge7Ianzrvh7qqyPtApQaISwNiU6TbuNQGbqvXNbHhfyMup3SBRfN5wJwPmC9I67Zy6SR2nW4ETO3CXxcRtWk8jwpRkHx5/CJ+99FhFJZZMVK5D08mfol0pRkayyUIllL/nkwTJ4UWfSKgMwE6I6A1Src6E6Ctva/O/VojoFB6P5/DBpQX1ISP2kHEfAEoy5cWl6PhetySukqBpfONQPb10iUEKPK5XMDlH4Bzu4G8XdLfOq2PFEDbDQSMGXJXSNQoBhWiICqptGHxf7/Dmv3nPfsSYzW4LjsON7UTMTjFgfbqMgjlhdIU5opCoPyitO6+tVe2vBCNQQotmjip26niEgAf/vMVFEBcOmDMrF7aAUoVcHY7cGG/dJ6YmoOB9L5SaOl0E9BxWPBbglwu6TMqPS/VEZsCxCQDqiYuaRBMoghYzUBFkfQZOiyAPgGISZJCpCYmPHX4y1IKnNsjBRP30lRYNmQC7QfWBJfMqwGtIXz1EjWBQYUoBL44WoB/7TyLPWeuoMrufS2hFIMW13ROwrDOSRjWJQnZSTEQhFpXbraW14SWqmLAYpZ+LC1mwFJSs241Sz8+tdcdlsaLUmqk8GHI9A4ixozq20wgNlUKBA2xlAJntgGntwI/bgUuHfO+X6EG2g+uDi43Sj94zQUKuwUoPQeU5nnfluRKt+bzgNNW/3FaExCbVBNcYt1LQ9tJgLLW2YQdNqCyOnhUXALKL9WsVxTVX3daG69fpZdalWISpeASk1S9nVRruzrYeMJNrDRDLFhcLqDoe+DcLqm15NxuaVxU3WCq0gPtfgK0HwSYsoCCQ8C5vdLf0SuAAoAApPSoDi7Vj0nt5f05ysFpB2wVUpi3VQKOKqnLUnR5L/X2OaXQ2dD9ClWdFsnqFkq53yt5MKgQhZDN4cLBcyXYceoydpy6jL25V2BzeP8opBt1GNalJrhkJbbgX+kOW01osZoBa5nUNWRsJ/1QBvMHsuyiNFj49Bbgx6+A0lzv+9WxUitLpxuBhGwpdNQOIaV51S09zRAUgCFD+nGpLGq+e6ohunjpc7CUNN2y0BhNnBR6VDqpharyMuCy+/88gPTDqDVKLRbuH0bPurHOurHOj6gBUGqBgsPVLSW7pLBhbeA9JWQD7YcAWUOkoJHWp+EfX2s5kH8QOL8XOL8HOL9P+tvUpdIBGf1rWl1MWVIAcDmlv4n7VnRvO6QQ5V4Xax9XvW6vAuwVUviwVVavV1YHkfJa69XhpKHQGioqff0uVV2dLlf3fco6gdzz35lQf7vR+1BrwL1Ya1ts4r5a3EEM7kAmeq/Xuw/174MgfT8ViupbFSAovfd5tpXS4tmu3heTCCR29uODbh6DClEYWexOHMgrwfZTl7Hz1GXsz7sCu9P7P6t28XpPcPlJxwRkJeihUkb4pDtRBK6cqWltOf2VFCp8oY4F4rOkHz5Te2mJ71C9niWFFHcrj8slhY3Ky96tHp5t974i6fUrLzfQWgDpf67uFhevpXpfXKp3C03dLh5RlH5IKy8DlcXSUlVca/tyne3q9aZaZ1pCHSOFh/aDpHDSfjAQlxL485VdBC7sk7qPzu+VwktDYUguglIKj2pd9Y+nQvrBF5TV69WLQtn8fU67d+ukvULudxfd+kwCJr8T1KdkUCGSUZXNiX25V6QWlx8v42BeCRwu7//M1EoBHRJj0DklDp1TYtElWbrtlByLxFiNd7dRpHC5gMLvqltctkrBoaEQYmovjfkI1XtwOYGqEinAWEqk14pNkVpYFGEOf6IotQxYSqWWrtpdeJ51H/Y7rdK/WNsPAbIGS6EktXfjXXbB4HIBxT9Wt7jslZaKIqmFxvOv7Nr/0q71L2yvf3HX+Ze6Wi91haljpDCojpW2Pesx1ffF1VqPlVowQvWdcTq8P3t362TtLlhrqfd9LkfDLRzSSq3tJlpHAm2Fqb3tDmHux3jWFbW20fB9EKR6PC1jrjotZXW3nd6tY+4Ws+5jgNHP+fmhN41BhSiCVFgd2HO2JricKDDDYm+gRaCaSa9G55RYdK4OL52TY9E5JQ4dk2KgUysbfRxFMZez/qwuolaMQYUogrlcIvLNFvx4qRw/XqqQbosq8OOlClworWr0HHKCALRP0KNzchxSDVokxmoQH6NBQowa8TEaJMbWrMfHqKGO9K4lImqz/Pn9DmG7IhE1RKEQ0C5ej3bxelzfzXvMgcXuxOnq0PLjpXKcLqrAqSJpvcziQF5xFfKKq3x6HYNOhYTqIJMQq0FCdYBx7zPq1TBVL+51o04NjYoBh4giB4MKUQTRqZXomWFEzwzvf2GIooiicht+vFSOM5crUFRuw5UKG65U2lFSaUNxpQ0llXZcqbShtMoOUQTKLA6UWRzILfavBr1aWR1eVDVBRlcrzNQKOCa9GvExNevsmiKiYGNQIYoCgiAgxaBFikGLoZ2TmjzW6RJRWiWFlpJKG4orvNdLKm24UmmDucqB0io7SqvsMFvsKLNIU4Sr7E5U2Z0oMPtfp1al8AouJr3GK8y4b416NeL1ahh0KsRqqxeNCkpFBA4iJiJZMagQtTJKhYDEWGnMij+cLhFlFrsnwJgt9pogU1Vr3eLw2l9S3YrjEgGrw4WLZisumgObsqtTKxCrqR1elIjVqhCnVSGm9rpWWb1PhTit0nN8XPXifmzETwEnomYxqBARACngSANx/T+VvcslotzmQGllTaAprbKjpHq7pMrmCTuefZV2VNgcqLA6POedsdhdsNhtuFwRnJOA6dSKWsHFHWJqAk+sVgWDToWkWA0SY6UByklx7oHJGrbwEEUABhUiajGFQpDGsejUyArg8VaHExVWJyqsDk94cW+XWx2otDlRbpX2115331ZYq/c1EnyKyv0PPoIAxOvVSIqrDjDVrVTu28Q4rWfdoFNBq1JCp1ZAp1ZCpRAi81w4RFGIQYWIZKdVKaFVKf3urmpM7eDjHWrq7LM5YK5yoLjCiuIKqSWnuEIamCyKwJVKO65U+n9afYUgDYzWqZXQqhSeW61aCV2t29r3x2iViNOoEKdTebX4xGmViNOqEVvd3RWrVXHqObUpDCpE1Oq0NPg4nC5cqbRXhxcpxBRX2HC53ObZ514vrrCh3OqAtdb1nlwiUGlzotLmbOJVAqdRKbzG43iN09E0sM/d/VUr7LhvY9RKKNjFRRGMQYWIqA6VUuGZZQUYfHqMKIqwOlyw2l2wOpxSt5PDCWv1rcVee73WMXYnrHYnKmxOlFukVp4KTytQTQtQudXhufilzeFCsUMKScFQe9CyXqNErEYasByrcW8rEVM9QFmvUXm2Y6pbgqQB0NJ9MWol9BqppYjdXxQMDCpEREEgCIKnuwdo4IrGQWB3ury6scqtdq8wUzfgePbbvPdJY4GccFZfg6rCJgWlwrLgXWBRqRCgrw4tMRol9GrpNqY6/MR49kszutz7Yqu7v+KqBzobdCrEadVSl5hGyfDTBjGoEBFFCbVSEfDMrLrcLUC1x/BU2pyeAcvSIgUi922V3Xu70lZzbIXNgUqrEzan1OrjdImelqBgEQRIAUZbO8xIIcagrdmOj1Ej3aRDhkmHdJMOybFadm9FMQYVIqI2qHYLUHKcNmjP63C6UGl3oqpW2KlZl8JOpc3ptc8deKqqA0+FVTqrsjvolFkccLpErzMuo9T3mlQKAWlGKbSkm3TIqF7PMOk9gSbFoOUg5QjFoEJEREGjUipgVCpg1AWv+0sURVjsLpRZ7dI4HqsD5RYHytyBxmKXAk31/svlNhSYLSgotaCwzAKHS8T5kiqcL2n8OlmCAKTEaT2tMLFaFdQKBZRKAWqFAJVSAZVSgEohQKVQQK0UoKy+VSkEKJWKmuMUAtRKBXRqBfRqJbRqpacbTK+umcbOcTy+YVAhIqKIJgiC9COvUSLVt7HNHg6nC5fKrcgvlYKLdFuF/FILLpotnlu7U0RhmRWFZVYcPOdHc00LCAKqg0tNgNFrlNCp3AOSldCopNCjUSqgVlXfKgVoVAqolQrPfTXbNfdplFLQUggClIIAhSCd80ipqF4Xqu9TSLcKBaAUpHMAKRVC9ToQq1UF7dQBgWBQISKiVkulVCDDpEeGSd/oMS6XiMsVtuogU4UCswVVNiccLhF2pwtOlwi7U4TD6YLDJcLhcsHhFKV1pwt2lwinU9pvd4pwukTYnC5Y7dLMLvf1syw2JywOp+eEhGKIp7EHy9j+mfjblKtle30GFSIiatMUipqLfvZtbwr569md0rT0quop61XVY3qqPPuqg43dBbvTBZtDCkDSbfU+Z537nC7YHTX77Q4RVqcLLpcUnFyitLjH+jhrr9e63+Xert7nFEVoVfKO3WFQISIiCiN3l40hiON4WjMOcSYiIqKIxaBCREREEYtBhYiIiCIWgwoRERFFLAYVIiIiilgMKkRERBSxGFSIiIgoYkVEUHn11VeRnZ0NnU6HoUOHYteuXXKXRERERBFA9qDy/vvv45FHHsHChQuxb98+9O/fHzk5OSgsLJS7NCIiIpKZ7EHlL3/5C2bNmoUZM2agV69eeP311xETE4N33nlH7tKIiIhIZrIGFZvNhr1792LkyJGefQqFAiNHjsSOHTtkrIyIiIgigazX+ikqKoLT6URaWprX/rS0NBw/frze8VarFVar1bNtNptDXiMRERHJR/auH38sWbIEJpPJs2RlZcldEhEREYWQrEElOTkZSqUSFy9e9Np/8eJFpKen1zt+wYIFKC0t9Sx5eXnhKpWIiIhkIGvXj0ajwcCBA7Fp0yaMHz8eAOByubBp0ybMnTu33vFarRZardazLYoiAHYBERERRRP377b7d7wpsgYVAHjkkUcwbdo0DBo0CEOGDMHSpUtRUVGBGTNmNPvYsrIyAGAXEBERURQqKyuDyWRq8hjZg8qdd96JS5cu4amnnkJBQQEGDBiAzz//vN4A24ZkZmYiLy8PBoMBgiAEtS6z2YysrCzk5eXBaDQG9bnbGn6WwcXPM3j4WQYXP8/gae2fpSiKKCsrQ2ZmZrPHCqIv7S5tkNlshslkQmlpaav8koQTP8vg4ucZPPwsg4ufZ/Dws6wRVbN+iIiIqG1hUCEiIqKIxaDSCK1Wi4ULF3rNMqLA8LMMLn6ewcPPMrj4eQYPP8saHKNCREREEYstKkRERBSxGFSIiIgoYjGoEBERUcRiUCEiIqKIxaDSgFdffRXZ2dnQ6XQYOnQodu3aJXdJUWnRokUQBMFr6dGjh9xlRYWvvvoKY8eORWZmJgRBwNq1a73uF0URTz31FDIyMqDX6zFy5Ej88MMP8hQbBZr7PKdPn17vuzpq1Ch5io1wS5YsweDBg2EwGJCamorx48fjxIkTXsdYLBbMmTMHSUlJiIuLw6RJk+pdfJZ8+yxvuummet/NX//61zJVLA8GlTref/99PPLII1i4cCH27duH/v37IycnB4WFhXKXFpV69+6N/Px8z/LNN9/IXVJUqKioQP/+/fHqq682eP/zzz+Pl19+Ga+//jq+/fZbxMbGIicnBxaLJcyVRofmPk8AGDVqlNd39b333gtjhdFj69atmDNnDnbu3IkNGzbAbrfj1ltvRUVFheeYhx9+GP/973+xevVqbN26FRcuXMDEiRNlrDoy+fJZAsCsWbO8vpvPP/+8TBXLRCQvQ4YMEefMmePZdjqdYmZmprhkyRIZq4pOCxcuFPv37y93GVEPgLhmzRrPtsvlEtPT08UXXnjBs6+kpETUarXie++9J0OF0aXu5ymKojht2jRx3LhxstQT7QoLC0UA4tatW0VRlL6LarVaXL16teeYY8eOiQDEHTt2yFVmVKj7WYqiKN54443iQw89JF9REYAtKrXYbDbs3bsXI0eO9OxTKBQYOXIkduzYIWNl0euHH35AZmYmOnfujKlTpyI3N1fukqLe6dOnUVBQ4PU9NZlMGDp0KL+nLbBlyxakpqaie/fuuP/++3H58mW5S4oKpaWlAIDExEQAwN69e2G3272+nz169ECHDh34/WxG3c/SbcWKFUhOTkafPn2wYMECVFZWylGebGS/enIkKSoqgtPprHfl5rS0NBw/flymqqLX0KFDsXz5cnTv3h35+flYvHgxrr/+ehw5cgQGg0Hu8qJWQUEBADT4PXXfR/4ZNWoUJk6ciE6dOuHUqVP4/e9/j9GjR2PHjh1QKpVylxexXC4X5s2bh+HDh6NPnz4ApO+nRqNBfHy817H8fjatoc8SAO6++2507NgRmZmZOHToEB577DGcOHECH3/8sYzVhheDCoXM6NGjPev9+vXD0KFD0bFjR3zwwQeYOXOmjJURebvrrrs863379kW/fv3QpUsXbNmyBSNGjJCxssg2Z84cHDlyhGPPgqCxz3L27Nme9b59+yIjIwMjRozAqVOn0KVLl3CXKQt2/dSSnJwMpVJZb3T6xYsXkZ6eLlNVrUd8fDyuuuoqnDx5Uu5Sopr7u8jvaeh07twZycnJ/K42Ye7cufj000+xefNmtG/f3rM/PT0dNpsNJSUlXsfz+9m4xj7LhgwdOhQA2tR3k0GlFo1Gg4EDB2LTpk2efS6XC5s2bcKwYcNkrKx1KC8vx6lTp5CRkSF3KVGtU6dOSE9P9/qems1mfPvtt/yeBsm5c+dw+fJlflcbIIoi5s6dizVr1uDLL79Ep06dvO4fOHAg1Gq11/fzxIkTyM3N5fezjuY+y4YcOHAAANrUd5NdP3U88sgjmDZtGgYNGoQhQ4Zg6dKlqKiowIwZM+QuLerMnz8fY8eORceOHXHhwgUsXLgQSqUSU6ZMkbu0iFdeXu71L6bTp0/jwIEDSExMRIcOHTBv3jz88Y9/RLdu3dCpUyc8+eSTyMzMxPjx4+UrOoI19XkmJiZi8eLFmDRpEtLT03Hq1Cn89re/RdeuXZGTkyNj1ZFpzpw5WLlyJf7zn//AYDB4xp2YTCbo9XqYTCbMnDkTjzzyCBITE2E0GvHggw9i2LBhuOaaa2SuPrI091meOnUKK1euxJgxY5CUlIRDhw7h4Ycfxg033IB+/frJXH0YyT3tKBL97W9/Ezt06CBqNBpxyJAh4s6dO+UuKSrdeeedYkZGhqjRaMR27dqJd955p3jy5Em5y4oKmzdvFgHUW6ZNmyaKojRF+cknnxTT0tJErVYrjhgxQjxx4oS8RUewpj7PyspK8dZbbxVTUlJEtVotduzYUZw1a5ZYUFAgd9kRqaHPEYC4bNkyzzFVVVXiAw88ICYkJIgxMTHihAkTxPz8fPmKjlDNfZa5ubniDTfcICYmJoparVbs2rWr+H//939iaWmpvIWHmSCKohjOYERERETkK45RISIioojFoEJEREQRi0GFiIiIIhaDChEREUUsBhUiIiKKWAwqREREFLEYVIiIiChiMagQUasiCALWrl0rdxlEFCQMKkQUNNOnT4cgCPWWUaNGyV0aEUUpXuuHiIJq1KhRWLZsmdc+rVYrUzVEFO3YokJEQaXVapGenu61JCQkAJC6ZV577TWMHj0aer0enTt3xocffuj1+MOHD+OWW26BXq9HUlISZs+ejfLycq9j3nnnHfTu3RtarRYZGRmYO3eu1/1FRUWYMGECYmJi0K1bN3zyySehfdNEFDIMKkQUVk8++SQmTZqEgwcPYurUqbjrrrtw7NgxAEBFRQVycnKQkJCA3bt3Y/Xq1di4caNXEHnttdcwZ84czJ49G4cPH8Ynn3yCrl27er3G4sWLcccdd+DQoUMYM2YMpk6diuLi4rC+TyIKErmvikhErce0adNEpVIpxsbGei3PPPOMKIrS1WJ//etfez1m6NCh4v333y+Koii++eabYkJCglheXu65/7PPPhMVCoXnasaZmZni448/3mgNAMQnnnjCs11eXi4CENetWxe090lE4cMxKkQUVDfffDNee+01r32JiYme9WHDhnndN2zYMBw4cAAAcOzYMfTv3x+xsbGe+4cPHw6Xy4UTJ05AEARcuHABI0aMaLKGfv36edZjY2NhNBpRWFgY6FsiIhkxqBBRUMXGxtbrigkWvV7v03FqtdprWxAEuFyuUJRERCHGMSpEFFY7d+6st92zZ08AQM+ePXHw4EFUVFR47t+2bRsUCgW6d+8Og8GA7OxsbNq0Kaw1E5F82KJCREFltVpRUFDgtU+lUiE5ORkAsHr1agwaNAjXXXcdVqxYgV27duHtt98GAEydOhULFy7EtGnTsGjRIly6dAkPPvgg7r33XqSlpQEAFi1ahF//+tdITU3F6NGjUVZWhm3btuHBBx8M7xslorBgUCGioPr888+RkZHhta979+44fvw4AGlGzqpVq/DAAw8gIyMD7733Hnr16gUAiImJwfr16/HQQw9h8ODBiImJwaRJk/CXv/zF81zTpk2DxWLBSy+9hPnz5yM5ORmTJ08O3xskorASRFEU5S6CiNoGQRCwZs0ajB8/Xu5SiChKcIwKERERRSwGFSIiIopYHKNCRGHDnmYi8hdbVIiIiChiMagQERFRxGJQISIioojFoEJEREQRi0GFiIiIIhaDChEREUUsBhUiIiKKWAwqREREFLEYVIiIiChi/T/gbPVPHX4jOwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_size = os.path.getsize(resnet50_model3_path_T) / (1024 * 1024)\n",
        "\n",
        "# Calculate the top-1 and top-2 accuracies on the test data\n",
        "top1_accuracy = resnet50_model3.evaluate(X_test, y_test)[1]\n",
        "\n",
        "\n",
        "# Define a function to calculate the top-2 accuracy\n",
        "y_pred = resnet50_model3.predict(X_test)\n",
        "\n",
        "top2_acc = tf.keras.metrics.TopKCategoricalAccuracy(k=2)\n",
        "top2_acc.update_state(y_test, y_pred)\n",
        "top2_accuracy = top2_acc.result().numpy()\n",
        "# print('Top-5 accuracy:', top2_acc.result().numpy())\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the train and validation accuracies\n",
        "train_accuracy = resnet50_model3.evaluate(X_train2, y_train2)[1]\n",
        "val_accuracy = resnet50_model3.evaluate(X_val2, y_val2)[1]\n",
        "\n",
        "# Count the number of trainable and non-trainable parameters in the model\n",
        "num_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in resnet50_model3.trainable_variables])\n",
        "num_non_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in resnet50_model3.non_trainable_variables])\n",
        "num_params = num_trainable_params + num_non_trainable_params\n",
        "\n",
        "# Calculate the depth of the model\n",
        "depth = len(resnet50_model3.layers)\n",
        "\n",
        "# Print the information in the required format\n",
        "print(\"| resnet50_model3 | {:.2f} | {:.4f} | {:.4f} | {:.4f} | {:.4f} | {} | {} |\".format(\n",
        "    model_size, top1_accuracy, top2_accuracy, train_accuracy, val_accuracy, num_params, depth))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6q2cu8mY5EX",
        "outputId": "dfbae139-4245-40c2-dddb-f1f24657afb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5500 - accuracy: 0.8532\n",
            "313/313 [==============================] - 5s 12ms/step\n",
            "1329/1329 [==============================] - 16s 12ms/step - loss: 0.1838 - accuracy: 0.9557\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.5222 - accuracy: 0.8564\n",
            "| resnet50_model3 | 348.54 | 0.8532 | 0.9389 | 0.9557 | 0.8564 | 30412170 | 184 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet34 this model is similar to resnet50_model2\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "############################## resnet34_model1 ################################\n",
        "###############################################################################\n",
        "###############################################################################"
      ],
      "metadata": {
        "id": "WDUKkTRYl0_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32, 32, 3)\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "def conv1x1(inputs, filters, stride=1):\n",
        "  conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=(1, 1), strides=stride,\n",
        "                                padding='same', use_bias=True)(inputs)\n",
        "  BachNor = tf.keras.layers.BatchNormalization()(conv)\n",
        "  RelU = tf.keras.layers.ReLU()(BachNor)\n",
        "  return RelU\n",
        "\n",
        "def conv3x3(inputs, filters, stride=1):\n",
        "  conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=stride,\n",
        "                                padding='same')(inputs)\n",
        "  BachNor = tf.keras.layers.BatchNormalization()(conv)\n",
        "  RelU = tf.keras.layers.ReLU()(BachNor)\n",
        "  return RelU\n",
        "\n",
        "\n",
        "def residual_block(inputs, filters, stride=1):\n",
        "  shortcut = inputs\n",
        "  if stride != 1 or inputs.shape[-1] != filters:\n",
        "    shortcut = conv1x1(inputs, filters, stride)\n",
        "  x = conv3x3(inputs, filters, stride)\n",
        "  x = conv3x3(x, filters, 1)\n",
        " \n",
        "  output = tf.keras.layers.add([x, shortcut])\n",
        "  output = tf.keras.layers.ReLU()(output)\n",
        "  return output\n",
        "\n",
        "def ResNet34(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), strides=2,\n",
        "                               padding='same', use_bias=True)(inputs)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(4, 4),\n",
        "                                  padding='same')(inputs)\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
        "    for filters, stride in [(64, 1), (64, 1), (64, 1), (128, 2), (128, 1), (128, 1), (128, 1), (256, 2), (256, 1), (256, 1), (256, 1), (256, 1), (256, 1), (512, 2), (512, 1), (512, 1)]:\n",
        "      x = residual_block(x, filters, stride=stride)\n",
        "    \n",
        "    \n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    resnet34_model1 = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return resnet34_model1\n",
        "\n",
        "\n",
        "\n",
        "resnet34_model1 = ResNet34(input_shape=input_shape, num_classes=num_classes)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "resnet34_model1.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "resnet34_model1_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/resnet34_model1.h5'\n",
        "resnet34_model1_path = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/resnet34_model1_weights'\n",
        "checkpoint_path = os.path.join(resnet34_model1_path)\n",
        "checkpoint_Ped = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "#                                                  patience=3, min_lr=0.00000000001)\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "    if  epoch < 10:\n",
        "        return 0.01\n",
        "    if  10<= epoch < 25:\n",
        "        return 0.001\n",
        "    if  25<= epoch < 35:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "reduce_lr = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "callbacks_Ped = [checkpoint_Ped, reduce_lr, EarlyStopping(monitor='val_loss', patience=20, verbose=1)]\n",
        "\n",
        "\n",
        "resnet34_model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4jjP78PqQcQ",
        "outputId": "e871da63-52a8-4297-c12c-cdba2a9e7e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   3136        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 32, 32, 64)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 16, 16, 64)   0           ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 64)   36928       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 16, 16, 64)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 64)   36928       ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 16, 16, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 16, 16, 64)   0           ['re_lu_2[0][0]',                \n",
            "                                                                  'max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 16, 16, 64)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 16, 64)   36928       ['re_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 16, 16, 64)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   36928       ['re_lu_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 16, 16, 64)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 16, 16, 64)   0           ['re_lu_5[0][0]',                \n",
            "                                                                  're_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 16, 16, 64)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 64)   36928       ['re_lu_6[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   36928       ['re_lu_7[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 16, 16, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 64)   0           ['re_lu_8[0][0]',                \n",
            "                                                                  're_lu_6[0][0]']                \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 16, 16, 64)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 8, 8, 128)    73856       ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_11[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 8, 8, 128)    8320        ['re_lu_9[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 8, 8, 128)    0           ['re_lu_12[0][0]',               \n",
            "                                                                  're_lu_10[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 8, 8, 128)    0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_13[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 8, 128)   512         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_14[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 8, 8, 128)   512         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 8, 8, 128)    0           ['re_lu_15[0][0]',               \n",
            "                                                                  're_lu_13[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 8, 8, 128)    0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_16[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 8, 8, 128)   512         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_17[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 8, 8, 128)   512         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8, 8, 128)    0           ['re_lu_18[0][0]',               \n",
            "                                                                  're_lu_16[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 8, 8, 128)    0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_19[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 128)   512         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_20[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 128)   512         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8, 8, 128)    0           ['re_lu_21[0][0]',               \n",
            "                                                                  're_lu_19[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 8, 8, 128)    0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 4, 4, 256)    295168      ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_24[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 4, 4, 256)    33024       ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 4, 4, 256)    0           ['re_lu_25[0][0]',               \n",
            "                                                                  're_lu_23[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)                (None, 4, 4, 256)    0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_26[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_27[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 4, 4, 256)    0           ['re_lu_28[0][0]',               \n",
            "                                                                  're_lu_26[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)                (None, 4, 4, 256)    0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_29[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_30[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 4, 4, 256)    0           ['re_lu_31[0][0]',               \n",
            "                                                                  're_lu_29[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)                (None, 4, 4, 256)    0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_32[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_33[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_34 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 4, 4, 256)    0           ['re_lu_34[0][0]',               \n",
            "                                                                  're_lu_32[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_35 (ReLU)                (None, 4, 4, 256)    0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_35[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_36 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_36[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_37 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 4, 4, 256)    0           ['re_lu_37[0][0]',               \n",
            "                                                                  're_lu_35[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_38 (ReLU)                (None, 4, 4, 256)    0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_38[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_39 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_39[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_40 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 4, 4, 256)    0           ['re_lu_40[0][0]',               \n",
            "                                                                  're_lu_38[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_41 (ReLU)                (None, 4, 4, 256)    0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 2, 2, 512)    1180160     ['re_lu_41[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_43 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_43[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 2, 2, 512)    131584      ['re_lu_41[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_44 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_42 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 2, 2, 512)    0           ['re_lu_44[0][0]',               \n",
            "                                                                  're_lu_42[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_45 (ReLU)                (None, 2, 2, 512)    0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_45[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_46 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_46[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_47 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 2, 2, 512)    0           ['re_lu_47[0][0]',               \n",
            "                                                                  're_lu_45[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_48 (ReLU)                (None, 2, 2, 512)    0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_48[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_49 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_49[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_50 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 2, 2, 512)    0           ['re_lu_50[0][0]',               \n",
            "                                                                  're_lu_48[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_51 (ReLU)                (None, 2, 2, 512)    0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 512)         0           ['re_lu_51[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           5130        ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,309,002\n",
            "Trainable params: 21,291,978\n",
            "Non-trainable params: 17,024\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet34_model1 = resnet34_model1.fit(X_train2, y_train2, batch_size=100,\n",
        "                                               epochs=50,\n",
        "                                               validation_data=(X_val2, y_val2),\n",
        "                                               callbacks=callbacks_Ped)\n",
        "\n",
        "resnet34_model1.save(resnet34_model1_path_T)\n",
        "\n",
        "test_loss, test_acc = resnet34_model1.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc) # Epoch 31: early stopping == Test accuracy: 0.7245000004768372"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GH3zxgFqnaH",
        "outputId": "07eb12e8-f861-4af4-99d9-4763a6c97bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "425/425 [==============================] - 49s 38ms/step - loss: 2.3237 - accuracy: 0.2425 - val_loss: 5.6475 - val_accuracy: 0.2187 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "425/425 [==============================] - 14s 33ms/step - loss: 1.4629 - accuracy: 0.4654 - val_loss: 1.7518 - val_accuracy: 0.4420 - lr: 0.0100\n",
            "Epoch 3/50\n",
            "425/425 [==============================] - 14s 33ms/step - loss: 1.1436 - accuracy: 0.5899 - val_loss: 1.2810 - val_accuracy: 0.5433 - lr: 0.0100\n",
            "Epoch 4/50\n",
            "425/425 [==============================] - 14s 33ms/step - loss: 0.9362 - accuracy: 0.6696 - val_loss: 1.0908 - val_accuracy: 0.6055 - lr: 0.0100\n",
            "Epoch 5/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 0.7939 - accuracy: 0.7190 - val_loss: 1.4729 - val_accuracy: 0.5545 - lr: 0.0100\n",
            "Epoch 6/50\n",
            "425/425 [==============================] - 16s 37ms/step - loss: 0.6551 - accuracy: 0.7699 - val_loss: 1.0409 - val_accuracy: 0.6437 - lr: 0.0100\n",
            "Epoch 7/50\n",
            "425/425 [==============================] - 15s 34ms/step - loss: 0.5452 - accuracy: 0.8086 - val_loss: 1.3693 - val_accuracy: 0.5885 - lr: 0.0100\n",
            "Epoch 8/50\n",
            "425/425 [==============================] - 16s 37ms/step - loss: 0.4451 - accuracy: 0.8439 - val_loss: 0.9655 - val_accuracy: 0.7079 - lr: 0.0100\n",
            "Epoch 9/50\n",
            "425/425 [==============================] - 16s 38ms/step - loss: 0.3581 - accuracy: 0.8726 - val_loss: 0.8672 - val_accuracy: 0.7305 - lr: 0.0100\n",
            "Epoch 10/50\n",
            "425/425 [==============================] - 13s 31ms/step - loss: 0.2919 - accuracy: 0.8964 - val_loss: 1.5512 - val_accuracy: 0.6164 - lr: 0.0100\n",
            "Epoch 11/50\n",
            "425/425 [==============================] - 14s 33ms/step - loss: 0.1059 - accuracy: 0.9672 - val_loss: 0.6793 - val_accuracy: 0.8079 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "425/425 [==============================] - 14s 32ms/step - loss: 0.0436 - accuracy: 0.9891 - val_loss: 0.7593 - val_accuracy: 0.8121 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "425/425 [==============================] - 13s 30ms/step - loss: 0.0224 - accuracy: 0.9952 - val_loss: 0.8191 - val_accuracy: 0.8099 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "425/425 [==============================] - 14s 34ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.8958 - val_accuracy: 0.8136 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "425/425 [==============================] - 14s 32ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.9480 - val_accuracy: 0.8141 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "425/425 [==============================] - 14s 33ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 1.0186 - val_accuracy: 0.8168 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "425/425 [==============================] - 13s 30ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 1.1046 - val_accuracy: 0.8076 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "425/425 [==============================] - 13s 31ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 1.1494 - val_accuracy: 0.8112 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 1.2680 - val_accuracy: 0.7947 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 1.2853 - val_accuracy: 0.7951 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 1.3251 - val_accuracy: 0.7989 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 1.4877 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 1.3335 - val_accuracy: 0.8052 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 1.3657 - val_accuracy: 0.8033 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.3475 - val_accuracy: 0.8064 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.3229 - val_accuracy: 0.8115 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.3281 - val_accuracy: 0.8127 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 8.5816e-04 - accuracy: 0.9999 - val_loss: 1.3286 - val_accuracy: 0.8140 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 6.8807e-04 - accuracy: 0.9999 - val_loss: 1.3268 - val_accuracy: 0.8148 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "425/425 [==============================] - 13s 31ms/step - loss: 4.0268e-04 - accuracy: 1.0000 - val_loss: 1.3311 - val_accuracy: 0.8144 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "425/425 [==============================] - 13s 30ms/step - loss: 4.8128e-04 - accuracy: 1.0000 - val_loss: 1.3396 - val_accuracy: 0.8140 - lr: 1.0000e-04\n",
            "Epoch 31: early stopping\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.3768 - accuracy: 0.8026\n",
            "Test accuracy: 0.8026000261306763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_resnet34_model1.history['accuracy'])\n",
        "plt.plot(history_resnet34_model1.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history_resnet34_model1.history['loss'])\n",
        "plt.plot(history_resnet34_model1.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "SbADYUdFDNQa",
        "outputId": "ea290aa6-4912-4c7f-c59a-1e8791533b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet34_model1 with data augmentation\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "############################# resnet34_model2 ###############################\n",
        "###############################################################################\n",
        "###############################################################################"
      ],
      "metadata": {
        "id": "GrvrQREQH3lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32, 32, 3)\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "def conv1x1(inputs, filters, stride=1):\n",
        "  conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=(1, 1), strides=stride,\n",
        "                                padding='same', use_bias=True)(inputs)\n",
        "  BachNor = tf.keras.layers.BatchNormalization()(conv)\n",
        "  RelU = tf.keras.layers.ReLU()(BachNor)\n",
        "  return RelU\n",
        "\n",
        "def conv3x3(inputs, filters, stride=1):\n",
        "  conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=stride,\n",
        "                                padding='same')(inputs)\n",
        "  BachNor = tf.keras.layers.BatchNormalization()(conv)\n",
        "  RelU = tf.keras.layers.ReLU()(BachNor)\n",
        "  return RelU\n",
        "\n",
        "\n",
        "def residual_block(inputs, filters, stride=1):\n",
        "  shortcut = inputs\n",
        "  if stride != 1 or inputs.shape[-1] != filters:\n",
        "    shortcut = conv1x1(inputs, filters, stride)\n",
        "  x = conv3x3(inputs, filters, stride)\n",
        "  x = conv3x3(x, filters, 1)\n",
        " \n",
        "  output = tf.keras.layers.add([x, shortcut])\n",
        "  output = tf.keras.layers.ReLU()(output)\n",
        "  return output\n",
        "\n",
        "def ResNet34(input_shape, num_classes):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), strides=2,\n",
        "                               padding='same', use_bias=True)(inputs)\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(4, 4),\n",
        "                                  padding='same')(inputs)\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
        "    for filters, stride in [(64, 1), (64, 1), (64, 1), (128, 2), (128, 1), (128, 1), (128, 1), (256, 2), (256, 1), (256, 1), (256, 1), (256, 1), (256, 1), (512, 2), (512, 1), (512, 1)]:\n",
        "      x = residual_block(x, filters, stride=stride)\n",
        "    \n",
        "    \n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    resnet34_model2 = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return resnet34_model2\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "  resnet34_model2 = ResNet34(input_shape=input_shape, num_classes=num_classes)\n",
        "  # Compile the model\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "  resnet34_model2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#  Define data augmentation pipelines\n",
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=5,  # rotate images by up to 5 degrees\n",
        "    width_shift_range=0.025,  # shift images horizontally by up to 2.5% of the width\n",
        "    height_shift_range=0.025,  # shift images vertically by up to 2.5% of the height\n",
        "    zoom_range=0.025,  # zoom in on images by up to 2.5%\n",
        "    horizontal_flip=True,  # flip images horizontally\n",
        "    # brightness_range=[0.8, 1.2],  # adjust brightness randomly between 0.8 and 1.2\n",
        "    # shear_range=0.1,  # shear images by up to 10 degrees\n",
        "    fill_mode='nearest'  # fill any pixel that might be lost after rotation or shift with the nearest pixel value\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "resnet34_model2_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/resnet34_model2.h5'\n",
        "resnet34_model2_path = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/resnet34_model2_weights'\n",
        "checkpoint_path = os.path.join(resnet34_model2_path)\n",
        "checkpoint_Ped = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "#                                                  patience=3, min_lr=0.00000000001)\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "    if  epoch < 10:\n",
        "        return 0.01\n",
        "    if  10<= epoch < 15:\n",
        "        return 0.001\n",
        "    if  15<= epoch < 20:\n",
        "        return 0.0001\n",
        "    if  20<= epoch < 25:\n",
        "        return 0.00001\n",
        "    if  25<= epoch < 30:\n",
        "        return 0.000001\n",
        "    else:\n",
        "        return 0.0000001\n",
        "\n",
        "reduce_lr = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "callbacks_Ped = [checkpoint_Ped, reduce_lr, EarlyStopping(monitor='val_loss', patience=7, verbose=1)]\n",
        "\n",
        "\n",
        "resnet34_model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp7gak39kjvD",
        "outputId": "feacfcea-5222-443d-a515-1e3385184304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 32, 32, 64)   3136        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 32, 32, 64)  256         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_52 (ReLU)                (None, 32, 32, 64)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)  0           ['re_lu_52[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 16, 16, 64)   36928       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 16, 16, 64)  256         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_53 (ReLU)                (None, 16, 16, 64)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 16, 16, 64)   36928       ['re_lu_53[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 16, 16, 64)  256         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_54 (ReLU)                (None, 16, 16, 64)   0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 16, 16, 64)   0           ['re_lu_54[0][0]',               \n",
            "                                                                  'max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " re_lu_55 (ReLU)                (None, 16, 16, 64)   0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 16, 16, 64)   36928       ['re_lu_55[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 16, 16, 64)  256         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_56 (ReLU)                (None, 16, 16, 64)   0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 16, 16, 64)   36928       ['re_lu_56[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 16, 16, 64)  256         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_57 (ReLU)                (None, 16, 16, 64)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 16, 16, 64)   0           ['re_lu_57[0][0]',               \n",
            "                                                                  're_lu_55[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_58 (ReLU)                (None, 16, 16, 64)   0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 16, 16, 64)   36928       ['re_lu_58[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 16, 16, 64)  256         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_59 (ReLU)                (None, 16, 16, 64)   0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 16, 16, 64)   36928       ['re_lu_59[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 16, 16, 64)  256         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_60 (ReLU)                (None, 16, 16, 64)   0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 16, 16, 64)   0           ['re_lu_60[0][0]',               \n",
            "                                                                  're_lu_58[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_61 (ReLU)                (None, 16, 16, 64)   0           ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 8, 8, 128)    73856       ['re_lu_61[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 8, 8, 128)   512         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_63 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_63[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 8, 8, 128)    8320        ['re_lu_61[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 8, 8, 128)   512         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 8, 8, 128)   512         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_64 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_62 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 8, 8, 128)    0           ['re_lu_64[0][0]',               \n",
            "                                                                  're_lu_62[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_65 (ReLU)                (None, 8, 8, 128)    0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_65[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 8, 8, 128)   512         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_66 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_66[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 8, 8, 128)   512         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_67 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 8, 8, 128)    0           ['re_lu_67[0][0]',               \n",
            "                                                                  're_lu_65[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_68 (ReLU)                (None, 8, 8, 128)    0           ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_68[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 8, 8, 128)   512         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_69 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_69[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 8, 8, 128)   512         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_70 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 8, 8, 128)    0           ['re_lu_70[0][0]',               \n",
            "                                                                  're_lu_68[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_71 (ReLU)                (None, 8, 8, 128)    0           ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_71[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 8, 8, 128)   512         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_72 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 8, 8, 128)    147584      ['re_lu_72[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 8, 8, 128)   512         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_73 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 8, 8, 128)    0           ['re_lu_73[0][0]',               \n",
            "                                                                  're_lu_71[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_74 (ReLU)                (None, 8, 8, 128)    0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 4, 4, 256)    295168      ['re_lu_74[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_76 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_76[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 4, 4, 256)    33024       ['re_lu_74[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_77 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_75 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 4, 4, 256)    0           ['re_lu_77[0][0]',               \n",
            "                                                                  're_lu_75[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_78 (ReLU)                (None, 4, 4, 256)    0           ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_78[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_79 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_79[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_80 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 4, 4, 256)    0           ['re_lu_80[0][0]',               \n",
            "                                                                  're_lu_78[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_81 (ReLU)                (None, 4, 4, 256)    0           ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_81[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_82 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_82[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_83 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 4, 4, 256)    0           ['re_lu_83[0][0]',               \n",
            "                                                                  're_lu_81[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_84 (ReLU)                (None, 4, 4, 256)    0           ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_84[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_85 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_85[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_86 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 4, 4, 256)    0           ['re_lu_86[0][0]',               \n",
            "                                                                  're_lu_84[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_87 (ReLU)                (None, 4, 4, 256)    0           ['add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_87[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_88 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_88[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_89 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 4, 4, 256)    0           ['re_lu_89[0][0]',               \n",
            "                                                                  're_lu_87[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_90 (ReLU)                (None, 4, 4, 256)    0           ['add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_90[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_91 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 4, 4, 256)    590080      ['re_lu_91[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_92 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 4, 4, 256)    0           ['re_lu_92[0][0]',               \n",
            "                                                                  're_lu_90[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_93 (ReLU)                (None, 4, 4, 256)    0           ['add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 2, 2, 512)    1180160     ['re_lu_93[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_95 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_95[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 2, 2, 512)    131584      ['re_lu_93[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_96 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_94 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 2, 2, 512)    0           ['re_lu_96[0][0]',               \n",
            "                                                                  're_lu_94[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_97 (ReLU)                (None, 2, 2, 512)    0           ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_97[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_98 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_98[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_99 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " add_30 (Add)                   (None, 2, 2, 512)    0           ['re_lu_99[0][0]',               \n",
            "                                                                  're_lu_97[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_100 (ReLU)               (None, 2, 2, 512)    0           ['add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_100[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_101 (ReLU)               (None, 2, 2, 512)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 2, 2, 512)    2359808     ['re_lu_101[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " re_lu_102 (ReLU)               (None, 2, 2, 512)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " add_31 (Add)                   (None, 2, 2, 512)    0           ['re_lu_102[0][0]',              \n",
            "                                                                  're_lu_100[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_103 (ReLU)               (None, 2, 2, 512)    0           ['add_31[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 512)         0           ['re_lu_103[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           5130        ['global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,309,002\n",
            "Trainable params: 21,291,978\n",
            "Non-trainable params: 17,024\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with data augmentation\n",
        "history_resnet34_model2 = resnet34_model2.fit(data_gen.flow(X_train2, y_train2, batch_size=100),\n",
        "                                               epochs=50,\n",
        "                                               validation_data=(X_val2, y_val2),\n",
        "                                               callbacks=callbacks_Ped)\n",
        "\n",
        "\n",
        "resnet34_model2.save(resnet34_model2_path_T)\n",
        "\n",
        "test_loss, test_acc = resnet34_model2.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc) # Epoch 26: early stopping == Test accuracy: 0.730400025844574"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PxHAuhUkjkY",
        "outputId": "f087aaa7-2f25-4c17-d5c8-6da5638bfdcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "425/425 [==============================] - 58s 76ms/step - loss: 2.3855 - accuracy: 0.2328 - val_loss: 2.2120 - val_accuracy: 0.2025 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "425/425 [==============================] - 31s 72ms/step - loss: 1.5563 - accuracy: 0.4270 - val_loss: 2.3706 - val_accuracy: 0.2440 - lr: 0.0100\n",
            "Epoch 3/50\n",
            "425/425 [==============================] - 29s 69ms/step - loss: 1.2248 - accuracy: 0.5593 - val_loss: 1.3832 - val_accuracy: 0.5396 - lr: 0.0100\n",
            "Epoch 4/50\n",
            "425/425 [==============================] - 29s 69ms/step - loss: 1.0364 - accuracy: 0.6310 - val_loss: 1.5406 - val_accuracy: 0.5241 - lr: 0.0100\n",
            "Epoch 5/50\n",
            "425/425 [==============================] - 30s 70ms/step - loss: 0.9004 - accuracy: 0.6829 - val_loss: 0.9025 - val_accuracy: 0.6819 - lr: 0.0100\n",
            "Epoch 6/50\n",
            "425/425 [==============================] - 28s 65ms/step - loss: 0.8152 - accuracy: 0.7101 - val_loss: 1.1253 - val_accuracy: 0.6076 - lr: 0.0100\n",
            "Epoch 7/50\n",
            "425/425 [==============================] - 27s 62ms/step - loss: 0.7178 - accuracy: 0.7490 - val_loss: 1.0205 - val_accuracy: 0.6429 - lr: 0.0100\n",
            "Epoch 8/50\n",
            "425/425 [==============================] - 26s 62ms/step - loss: 0.6493 - accuracy: 0.7723 - val_loss: 1.0833 - val_accuracy: 0.6560 - lr: 0.0100\n",
            "Epoch 9/50\n",
            "425/425 [==============================] - 28s 66ms/step - loss: 0.5895 - accuracy: 0.7949 - val_loss: 0.9023 - val_accuracy: 0.6981 - lr: 0.0100\n",
            "Epoch 10/50\n",
            "425/425 [==============================] - 30s 72ms/step - loss: 0.5337 - accuracy: 0.8141 - val_loss: 0.8076 - val_accuracy: 0.7296 - lr: 0.0100\n",
            "Epoch 11/50\n",
            "425/425 [==============================] - 31s 72ms/step - loss: 0.3634 - accuracy: 0.8739 - val_loss: 0.6311 - val_accuracy: 0.7947 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "425/425 [==============================] - 28s 66ms/step - loss: 0.3146 - accuracy: 0.8908 - val_loss: 0.5053 - val_accuracy: 0.8352 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "425/425 [==============================] - 28s 65ms/step - loss: 0.2821 - accuracy: 0.9025 - val_loss: 0.5265 - val_accuracy: 0.8319 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "425/425 [==============================] - 26s 62ms/step - loss: 0.2619 - accuracy: 0.9085 - val_loss: 0.5715 - val_accuracy: 0.8239 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "425/425 [==============================] - 31s 72ms/step - loss: 0.2398 - accuracy: 0.9159 - val_loss: 0.5034 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "425/425 [==============================] - 30s 71ms/step - loss: 0.2042 - accuracy: 0.9311 - val_loss: 0.5110 - val_accuracy: 0.8455 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "425/425 [==============================] - 27s 63ms/step - loss: 0.1965 - accuracy: 0.9338 - val_loss: 0.5247 - val_accuracy: 0.8399 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "425/425 [==============================] - 32s 75ms/step - loss: 0.1913 - accuracy: 0.9352 - val_loss: 0.5171 - val_accuracy: 0.8421 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "425/425 [==============================] - 31s 73ms/step - loss: 0.1857 - accuracy: 0.9371 - val_loss: 0.5196 - val_accuracy: 0.8425 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "425/425 [==============================] - 27s 63ms/step - loss: 0.1796 - accuracy: 0.9384 - val_loss: 0.5224 - val_accuracy: 0.8429 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "425/425 [==============================] - 27s 63ms/step - loss: 0.1815 - accuracy: 0.9381 - val_loss: 0.5226 - val_accuracy: 0.8432 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "425/425 [==============================] - 28s 65ms/step - loss: 0.1764 - accuracy: 0.9400 - val_loss: 0.5246 - val_accuracy: 0.8424 - lr: 1.0000e-05\n",
            "Epoch 22: early stopping\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.5519 - accuracy: 0.8330\n",
            "Test accuracy: 0.8330000042915344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_resnet34_model2.history['accuracy'])\n",
        "plt.plot(history_resnet34_model2.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history_resnet34_model2.history['loss'])\n",
        "plt.plot(history_resnet34_model2.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "o1W8XH8sH3gv",
        "outputId": "c79cf572-066a-459f-8df1-481685772101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABt3ElEQVR4nO3dd3RU1d7G8e9Mei+kh0DovSglYEFRFFBRFBUVBRH1qoAielUsFL1Xrp2rYH1FrgVEULGDGrGgCArSpNfQEhJKKmkz5/3jkCEhCSQwySST57PWrMycOefMbzLGedh7n70thmEYiIiIiLgJq6sLEBEREXEmhRsRERFxKwo3IiIi4lYUbkRERMStKNyIiIiIW1G4EREREbeicCMiIiJuReFGRERE3IrCjYiIiLgVhRsRcRqLxcLkyZOrfdzOnTuxWCzMmjXL6TWJSMOjcCPiZmbNmoXFYsFisbBkyZJyzxuGQUJCAhaLhSuuuMIFFYqI1CyFGxE35evry+zZs8tt/+mnn9izZw8+Pj4uqEpEpOYp3Ii4qcsuu4x58+ZRXFxcZvvs2bPp1q0bMTExLqqs4cjNzXV1CSINksKNiJu68cYbOXjwIN99951jW2FhIfPnz+emm26q8Jjc3FweeOABEhIS8PHxoU2bNjz//PMYhlFmv4KCAu6//34iIyMJCgriyiuvZM+ePRWec+/evdx2221ER0fj4+NDhw4dmDlz5mm9p0OHDvHggw/SqVMnAgMDCQ4OZuDAgaxevbrcvvn5+UyePJnWrVvj6+tLbGws11xzDdu2bXPsY7fb+e9//0unTp3w9fUlMjKSAQMG8OeffwInHwt04viiyZMnY7FYWL9+PTfddBNhYWGcd955AKxZs4Zbb72V5s2b4+vrS0xMDLfddhsHDx6s8Pc1atQo4uLi8PHxoVmzZtx9990UFhayfft2LBYLL730UrnjfvvtNywWC3PmzKnur1XE7Xi6ugARqRmJiYn07t2bOXPmMHDgQAC++eYbMjMzueGGG3j55ZfL7G8YBldeeSWLFy9m1KhRdO3alUWLFvHPf/6TvXv3lvlCvf3223n//fe56aabOOecc/jhhx+4/PLLy9WQlpZGr169sFgsjBkzhsjISL755htGjRpFVlYW48aNq9Z72r59OwsWLOC6666jWbNmpKWl8cYbb3DBBRewfv164uLiALDZbFxxxRUkJydzww03cN9995Gdnc13333HunXraNGiBQCjRo1i1qxZDBw4kNtvv53i4mJ++eUXfv/9d7p3716t2kpcd911tGrViqefftoRCr/77ju2b9/OyJEjiYmJ4e+//+bNN9/k77//5vfff8disQCwb98+evbsyZEjR7jzzjtp27Yte/fuZf78+eTl5dG8eXPOPfdcPvjgA+6///4yr/vBBx8QFBTEVVdddVp1i7gVQ0TcyjvvvGMAxh9//GFMnz7dCAoKMvLy8gzDMIzrrrvO6Nu3r2EYhtG0aVPj8ssvdxy3YMECAzD+9a9/lTnftddea1gsFmPr1q2GYRjGqlWrDMC45557yux30003GYAxadIkx7ZRo0YZsbGxRkZGRpl9b7jhBiMkJMRR144dOwzAeOedd0763vLz8w2bzVZm244dOwwfHx/jySefdGybOXOmARgvvvhiuXPY7XbDMAzjhx9+MADj3nvvrXSfk9V14nudNGmSARg33nhjuX1L3mdpc+bMMQDj559/dmwbPny4YbVajT/++KPSmt544w0DMDZs2OB4rrCw0IiIiDBGjBhR7jiRhkjdUiJu7Prrr+fo0aN8+eWXZGdn8+WXX1baJfX111/j4eHBvffeW2b7Aw88gGEYfPPNN479gHL7ndgKYxgGH3/8MYMGDcIwDDIyMhy3/v37k5mZycqVK6v1fnx8fLBazf9t2Ww2Dh48SGBgIG3atClzro8//piIiAjGjh1b7hwlrSQff/wxFouFSZMmVbrP6bjrrrvKbfPz83Pcz8/PJyMjg169egE46rbb7SxYsIBBgwZV2GpUUtP111+Pr68vH3zwgeO5RYsWkZGRwc0333zadYu4E4UbETcWGRlJv379mD17Np988gk2m41rr722wn137dpFXFwcQUFBZba3a9fO8XzJT6vV6ujaKdGmTZsyj9PT0zly5AhvvvkmkZGRZW4jR44E4MCBA9V6P3a7nZdeeolWrVrh4+NDREQEkZGRrFmzhszMTMd+27Zto02bNnh6Vt7zvm3bNuLi4ggPD69WDafSrFmzctsOHTrEfffdR3R0NH5+fkRGRjr2K6k7PT2drKwsOnbseNLzh4aGMmjQoDJXwn3wwQfEx8dz0UUXOfGdiNRfGnMj4uZuuukm7rjjDlJTUxk4cCChoaG18rp2ux2Am2++mREjRlS4T+fOnat1zqeffponnniC2267jaeeeorw8HCsVivjxo1zvJ4zVdaCY7PZKj2mdCtNieuvv57ffvuNf/7zn3Tt2pXAwEDsdjsDBgw4rbqHDx/OvHnz+O233+jUqROff/4599xzj6NVS6ShU7gRcXNXX301//jHP/j999+ZO3dupfs1bdqU77//nuzs7DKtNxs3bnQ8X/LTbrc7WkdKbNq0qcz5Sq6kstls9OvXzynvZf78+fTt25e33367zPYjR44QERHheNyiRQuWLVtGUVERXl5eFZ6rRYsWLFq0iEOHDlXaehMWFuY4f2klrVhVcfjwYZKTk5kyZQoTJ050bN+yZUuZ/SIjIwkODmbdunWnPOeAAQOIjIzkgw8+ICkpiby8PG655ZYq1yTi7hTzRdxcYGAgr732GpMnT2bQoEGV7nfZZZdhs9mYPn16me0vvfQSFovFccVVyc8Tr7aaNm1amcceHh4MGTKEjz/+uMIv7PT09Gq/Fw8Pj3KXpc+bN4+9e/eW2TZkyBAyMjLKvRfAcfyQIUMwDIMpU6ZUuk9wcDARERH8/PPPZZ5/9dVXq1Vz6XOWOPH3ZbVaGTx4MF988YXjUvSKagLw9PTkxhtv5KOPPmLWrFl06tSp2q1gIu5MLTciDUBl3UKlDRo0iL59+/LYY4+xc+dOunTpwrfffstnn33GuHHjHGNsunbtyo033sirr75KZmYm55xzDsnJyWzdurXcOf/zn/+wePFikpKSuOOOO2jfvj2HDh1i5cqVfP/99xw6dKha7+OKK67gySefZOTIkZxzzjmsXbuWDz74gObNm5fZb/jw4bz77ruMHz+e5cuXc/7555Obm8v333/PPffcw1VXXUXfvn255ZZbePnll9myZYuji+iXX36hb9++jBkzBjAve//Pf/7D7bffTvfu3fn555/ZvHlzlWsODg6mT58+PPvssxQVFREfH8+3337Ljh07yu379NNP8+2333LBBRdw55130q5dO/bv38+8efNYsmRJmS7F4cOH8/LLL7N48WKeeeaZav0eRdyey67TEpEaUfpS8JM58VJwwzCM7Oxs4/777zfi4uIMLy8vo1WrVsZzzz3nuAy5xNGjR417773XaNSokREQEGAMGjTI2L17d7nLow3DMNLS0ozRo0cbCQkJhpeXlxETE2NcfPHFxptvvunYpzqXgj/wwANGbGys4efnZ5x77rnG0qVLjQsuuMC44IILyuybl5dnPPbYY0azZs0cr3vttdca27Ztc+xTXFxsPPfcc0bbtm0Nb29vIzIy0hg4cKCxYsWKMucZNWqUERISYgQFBRnXX3+9ceDAgUovBU9PTy9X9549e4yrr77aCA0NNUJCQozrrrvO2LdvX4W/r127dhnDhw83IiMjDR8fH6N58+bG6NGjjYKCgnLn7dChg2G1Wo09e/ac9Pcm0tBYDOOEtlIREakXzjrrLMLDw0lOTnZ1KSJ1isbciIjUQ3/++SerVq1i+PDhri5FpM5Ry42ISD2ybt06VqxYwQsvvEBGRgbbt2/H19fX1WWJ1ClquRERqUfmz5/PyJEjKSoqYs6cOQo2IhVQy42IiIi4FbXciIiIiFtRuBERERG30uAm8bPb7ezbt4+goKAzWvlXREREao9hGGRnZxMXF3fKddQaXLjZt28fCQkJri5DRERETsPu3btp3LjxSfdpcOGmZEHA3bt3Exwc7OJqREREpCqysrJISEgos7BvZRpcuCnpigoODla4ERERqWeqMqREA4pFRETErSjciIiIiFtRuBERERG30uDG3FSVzWajqKjI1WWIE3h5eeHh4eHqMkREpJYo3JzAMAxSU1M5cuSIq0sRJwoNDSUmJkZzG4mINAAKNycoCTZRUVH4+/vry7CeMwyDvLw8Dhw4AEBsbKyLKxIRkZqmcFOKzWZzBJtGjRq5uhxxEj8/PwAOHDhAVFSUuqhERNycBhSXUjLGxt/f38WViLOVfKYaRyUi4v4Ubiqgrij3o89URKThULgRERERt6JwI5VKTExk2rRpri5DRESkWhRu3IDFYjnpbfLkyad13j/++IM777zTucWKiIjUMF0t5Qb279/vuD937lwmTpzIpk2bHNsCAwMd9w3DwGaz4el56o8+MjLSuYWKiIhbMgyDgmI7+UU28gptWCwQG+LnsnoUbtxATEyM435ISAgWi8Wx7ccff6Rv3758/fXXPP7446xdu5Zvv/2WhIQExo8fz++//05ubi7t2rVj6tSp9OvXz3GuxMRExo0bx7hx4wCzheitt97iq6++YtGiRcTHx/PCCy9w5ZVX1ur7FRGprwzDoNBmp7DYTkGx+bOw2E6hzU5BkZ1Cm42CE54ruQ9gtYDVYsFiMf+fXPqx1WI5div7nNUKFirexzAMjhbZOHoslJSEk6OF5rYTf+YVFnO0yM7RwuLj2489ZzeOv8+eieF8dFdvF/2WFW5OqeSDdwU/Lw+nXeXzyCOP8Pzzz9O8eXPCwsLYvXs3l112Gf/+97/x8fHh3XffZdCgQWzatIkmTZpUep4pU6bw7LPP8txzz/HKK68wbNgwdu3aRXh4uFPqFBFxhcJie7kv8Yq+6PPKfdmXBILjX/r5RXYKim3lwkmB7XhIcWdeHmaQciWFm1M4WmSj/cRFLnnt9U/2x9/bOR/Rk08+ySWXXOJ4HB4eTpcuXRyPn3rqKT799FM+//xzxowZU+l5br31Vm688UYAnn76aV5++WWWL1/OgAEDnFKniEh+kY3s/GKy84uO/Swmp6C4VIvH8eDgaPU4IUiY+9rKtY6UDhwFxXYKjrVaFJdudqhFXh4WfDw98Pa04u1hxdvTio+n+bNkm4+XB94eFkdLi90A+7GfhmFgOB4f33biPnbHfscf2w2wAH7eHvh5eZT76e947ImflxV/b098vT3wL9mn3H4e+Hp54OXh+uG8CjcNRPfu3cs8zsnJYfLkyXz11Vfs37+f4uJijh49SkpKyknP07lzZ8f9gIAAgoODHUsbiIgU2ewczi0k64Rwkp1fRE5B8Qnbyz5fcr/Q5rrWDQ+rpdyXt593+S/64/fN58p86Xt5lAspFQYYDytWq+bgqgkKN6fg5+XB+if7u+y1nSUgIKDM4wcffJDvvvuO559/npYtW+Ln58e1115LYWHhSc/j5eVV5rHFYsFud/9mVhGpXE5BMYs3HmDhulQWbzpAXqFzuvKDfDwJ9PUkyNeTQB/P4wHB83hA8CkVGMzw4IGPV9ltPo4WEPP50q0iJ7ZWeHu6vtVBzpzCzSlYLBandQ3VJb/++iu33norV199NWC25OzcudO1RYlIvXE4t5DvNqSxaF0qv2zNKDOWxGqBQB9Pgny9CPL1JPjYT/Pm5QgsQb5eBJe6X/pnoLenWjXktLnft7ZUSatWrfjkk08YNGgQFouFJ554Qi0wInJSB7LyWfR3Kgv/TuX37YewlRqn0iwigAEdYxjQIYZO8SEKJuJSCjcN1Isvvshtt93GOeecQ0REBA8//DBZWVmuLktE6pjdh/JYuM4MNCtTDmOUGnfbLjaYAR1iGNgphlZRgVrDTeoMi2EYrhki7iJZWVmEhISQmZlJcHBwmefy8/PZsWMHzZo1w9fX10UVSk3QZytSdVvSsh2B5u99Zf/Rc1aTUAZ0iGFAxxiaNgqo5Awizney7+8TqeVGRKSBMwyDdXuzWPj3fhauS2Vbeq7jOasFkpo1YkDHGPp3iCEmRP84kLpP4UZEpAHKL7Kxdm+m2UKzLpW9R446nvPysHBeywgGdoylX/towgO8XVipSPUp3IiIuLFDuYVsPZDDtvQcth37uTU9hz2Hj5YZP+Pn5cGFbSIZ0DGGvm2jCPb1qvykInWcwo2ISD1nsxvsOZx3LMDkHg8z6Tkcziuq9Lgwfy8ubBPFgI4x9GkViZ+38+bWEnElhRsRkXoir7CY7em5pVphzPvbM3JPumZRfKgfLaMCaREZSIuoAFpEBtIyKpBGAd66wkncksKNiEgdYRgGGTmF7D6cx+5Deew5fJQ9h/PYfegoOzJyy4yLOZG3p5XmEQG0OBZizDATQPOIQLXISIPj8nAzY8YMnnvuOVJTU+nSpQuvvPIKPXv2rHDfoqIipk6dyv/+9z/27t1LmzZteOaZZ7Roo4jUC4ZhkHW02BFedh82A4x53wwy+UUnn0wzPMCbFpEBpQKMeYsP88NDE+eJAC4ON3PnzmX8+PG8/vrrJCUlMW3aNPr378+mTZuIiooqt//jjz/O+++/z1tvvUXbtm1ZtGgRV199Nb/99htnnXWWC96BiEhZuQXFpQKL2eqy5/Cx8HIoj+yC4pMeb7FAbLAvjcP8aRzuR0KYP43D/EiMMAONrlwSOTWXTuKXlJREjx49mD59OgB2u52EhATGjh3LI488Um7/uLg4HnvsMUaPHu3YNmTIEPz8/Hj//fer9JqaxK9h0mcrNeVgTgHLdxzi9+0HWbbjEBtTs095TESgDwnhfjQO8ychzI+EcDPAJIT5Exfqp8UbRSpQLybxKywsZMWKFUyYMMGxzWq10q9fP5YuXVrhMQUFBeW+mPz8/FiyZEmlr1NQUEBBQYHjsZYYqNiFF15I165dmTZtGgCJiYmMGzeOcePGVXqMxWLh008/ZfDgwWf02s46j0htyMgpYNn2kjBzkM1pOeX2CfHzIqFUq0tCuL/jfuMwf42BEalhLgs3GRkZ2Gw2oqOjy2yPjo5m48aNFR7Tv39/XnzxRfr06UOLFi1ITk7mk08+wWazVfo6U6dOZcqUKU6tva4ZNGgQRUVFLFy4sNxzv/zyC3369GH16tV07ty5yuf8448/CAhw7tTqkydPZsGCBaxatarM9v379xMWFubU1xJxlgPZ+aXCzCG2HigfZtrGBJHULJxezRvRo1k4EYE+LqhUREq4fEBxdfz3v//ljjvuoG3btlgsFlq0aMHIkSOZOXNmpcdMmDCB8ePHOx5nZWWRkJBQG+XWmlGjRjFkyBD27NlD48aNyzz3zjvv0L1792oFG4DIyEhnlnhSMTExtfZaIqeSlpXvCDK/bz/I9lJLEZRoGxNEr+aN6NW8ET2bhWscjEgd47KO3YiICDw8PEhLSyuzPS0trdIvu8jISBYsWEBubi67du1i48aNBAYG0rx580pfx8fHh+Dg4DI3d3PFFVcQGRnJrFmzymzPyclh3rx5DB48mBtvvJH4+Hj8/f3p1KkTc+bMOek5ExMTHV1UAFu2bKFPnz74+vrSvn17vvvuu3LHPPzww7Ru3Rp/f3+aN2/OE088QVGROYHYrFmzmDJlCqtXr8ZisWCxWBz1WiwWFixY4DjP2rVrueiii/Dz86NRo0bceeed5OQc/9fyrbfeyuDBg3n++eeJjY2lUaNGjB492vFaItWxP/MoC/7ay4RP1tD3+R9JejqZ+z5cxexlKWxPz8Vigfaxwdx2bjPeuKUbfz1xCQvH9WHylR0Y0DFGwUakDnJZy423tzfdunUjOTnZMdbCbreTnJzMmDFjTnqsr68v8fHxFBUV8fHHH3P99dfXXKGGAUV5NXf+k/HyNy+dOAVPT0+GDx/OrFmzeOyxxxyTcs2bNw+bzcbNN9/MvHnzePjhhwkODuarr77illtuoUWLFpVedl+a3W7nmmuuITo6mmXLlpGZmVnhWJygoCBmzZpFXFwca9eu5Y477iAoKIiHHnqIoUOHsm7dOhYuXMj3338PQEhISLlz5Obm0r9/f3r37s0ff/zBgQMHuP322xkzZkyZ8LZ48WJiY2NZvHgxW7duZejQoXTt2pU77rjjlO9HGjbDMFiZcpgFf+3j5y3p7DpY9u/baoH2ccH0ataIpOaN6JkYToi/liIQqU9c2i01fvx4RowYQffu3enZsyfTpk0jNzeXkSNHAjB8+HDi4+OZOnUqAMuWLWPv3r107dqVvXv3MnnyZOx2Ow899FDNFVmUB0/H1dz5T+bRfeBdtXEvt912G8899xw//fQTF154IWB2SQ0ZMoSmTZvy4IMPOvYdO3YsixYt4qOPPqpSuPn+++/ZuHEjixYtIi7O/F08/fTTDBw4sMx+jz/+uON+YmIiDz74IB9++CEPPfQQfn5+BAYG4unpedJuqNmzZ5Ofn8+7777rGPMzffp0Bg0axDPPPOMYoxUWFsb06dPx8PCgbdu2XH755SQnJyvcSKW2pefw2V97WbBqHymHjgcaqwU6xofQq3kjkpqF0z0xnBA/hRmR+syl4Wbo0KGkp6czceJEUlNT6dq1KwsXLnR8gaWkpGC1Hu85y8/P5/HHH2f79u0EBgZy2WWX8d577xEaGuqid1B3tG3blnPOOYeZM2dy4YUXsnXrVn755ReefPJJbDYbTz/9NB999BF79+6lsLCQgoIC/P39q3TuDRs2kJCQ4Ag2AL179y6339y5c3n55ZfZtm0bOTk5FBcXV7sbcMOGDXTp0qXMYOZzzz0Xu93Opk2bHP9tdOjQAQ+P41ecxMbGsnbt2mq9lri/9OwCvli9jwWr9rJmT6Zje4C3BwM6xnJZpxh6NAvXIpEibsblA4rHjBlTaTfUjz/+WObxBRdcwPr162uhqlK8/M0WFFfwqlr4KDFq1CjGjh3LjBkzeOedd2jRogUXXHABzzzzDP/973+ZNm0anTp1IiAggHHjxlFYWOi0UpcuXcqwYcOYMmUK/fv3JyQkhA8//JAXXnjBaa9RmpdX2S8ji8WC3X7ymV2lYcgtKObb9al8+tc+lmxJx35sJi9Pq4U+rSMZfFY8l7SL1uXYIm7M5eGmzrNYqtw15GrXX3899913H7Nnz+bdd9/l7rvvxmKx8Ouvv3LVVVdx8803A+YYms2bN9O+ffsqnbddu3bs3r2b/fv3ExsbC8Dvv/9eZp/ffvuNpk2b8thjjzm27dq1q8w+3t7eJ71sv+S1Zs2aRW5urqP15tdff8VqtdKmTZsq1SsNT7HNzi9bM/jsr70s+juNo0XH/zs7q0koV58Vz+WdYmmkS7RFGgSFGzcSGBjI0KFDmTBhAllZWdx6660AtGrVivnz5/Pbb78RFhbGiy++SFpaWpXDTb9+/WjdujUjRozgueeeIysrq0yIKXmNlJQUPvzwQ3r06MFXX33Fp59+WmafxMREduzYwapVq2jcuDFBQUH4+JT9shk2bBiTJk1ixIgRTJ48mfT0dMaOHcstt9xSbk4kadgMw2D1nkwW/LWXL9fsIyPneEtks4gAruoax+Cu8SRG1I9/nIiI82iObzczatQoDh8+TP/+/R1jZB5//HHOPvts+vfvz4UXXkhMTEy1ZgO2Wq18+umnHD16lJ49e3L77bfz73//u8w+V155Jffffz9jxoyha9eu/PbbbzzxxBNl9hkyZAgDBgygb9++REZGVng5ur+/P4sWLeLQoUP06NGDa6+9losvvtixRIfIroO5/Pf7LVz0wk8MnvErs37bSUZOIY0CvLn1nEQWjD6XHx64gHH9WivYiDRQLl1byhW0tlTDpM+2fjuYU8BXa/fz6V97+SvliGO7r5eV/h1iGHxWPOe1jMDLQ/9eE3FX9WJtKRGRqvh89T4e/Gg1hTZzwLjVAue1iuTqs+K4tH0MAT7635iIlKX/K4hInbVubyb/nGcGmw5xwVxzdmMGdYklKkitbyJSOYUbEamTDucWctf7KygottO3TSRvj+iB1XrqGbtFRNRBLSJ1js1ucO+Hf7Hn8FGaNvJn2tCzFGxEpMoUbirQwMZYNwj6TOuXF7/bxC9bMvD1svL6zd20tpOIVIvCTSkls97m5blooUypMSWf6YkzG0vds3BdKjMWbwPgmSGdaRdbvSU8REQ05qYUDw8PQkNDOXDgAGDOuWKpwqrcUncZhkFeXh4HDhwgNDS0zHpUUvdsPZDDg/NWA3Dbuc24qmu8iysSkfpI4eYEJStWlwQccQ+hoaEnXY1cXC+noJh/vPcnOQXF9GwWzoTL2rq6JBGppxRuTmCxWIiNjSUqKoqioiJXlyNO4OXlpRabOs4wDP45bzXb0nOJDvZhxk1na0I+ETltCjeV8PDw0BeiSC154+ftfLMuFS8PC6/d3I3IIC1wKSKnT/80EhGXWrIlg2cXbgRg8pUdOLtJmIsrEpH6TuFGRFxmz+E8xs5Zid2A67s35qaeTVxdkoi4AYUbEXGJ/CIbd72/gsN5RXRuHMKTV3XU1Yn1nWFAUT7Yba6uRBo4jbkRkVpnGAZPLFjHur1ZhPl78eqws/H10hg3l7AVQ2E2FORAYc6xn9V9nAMF2eZPezFYPSE4DkKaQEhjCE0wf4Y0Pr7N29/V77zhMoxjNztYLGCxmj/diMKNiNS62ctTmLdiD1YLvHLj2TQO0xddrTEM2PEz/DkTtn5vBhJnsxfDkRTzVhn/RsfCToJ5OzEABUSc3heuYUBx/vHQVZh77Oex+wUnbLMVmV/yJV/2hu3YzxNvhtkiVeFzJ7nZbaXOba/kNYxS+57qnMf2xTj+mJKwUsFzjsel7lfE6nns5gVWD/O+h1ep7cduHp6n2NfD3N6oJVz0WPU/PydRuBGRWrUy5TCTP/8bgIcGtOW8VhEurqiByDsEq+eYoebg1vLPe3iDdyD4BIJ30LGflT0OBJ+gip/3DjBDQ+YeOLIbMktue45vK8yGvIPmbf/qiuv19C0VdhIgIBKKC8oGlcLcYy1GuWUDi2Gv2d+lO7IXmzfynXO+xj0VbkSkYUjPLuDu91dQZDMY2DGGf/Rp7uqS3JthwJ4/zUDz9ydmiwaYIaTz9XDWLRCWaD729Hbe6/qFmqGkSa+Ka8rPPCHwpBy7f2xbdqpZ68GtFQexqvLyPx64HEEs4Phj7wAz1Fmsx29Wj7KPHd02J24v2ddywvaSbR7Hjy93zhP3PdXrn7AfpbuSSt0v97hkX0v54yylhtzabcfCTZH501Z8POzYi44/bzv2vN12fN/K9g+IPP3PzQkUbkSkVhTZ7IyevZK0rAJaRgXy3HVdXDuA+MBGOPA3+IWVvfkE1//xBwXZsHYe/DET0tYe3x7dCXrcBp2uM1teXMFiMcOPXyjEdKp4n+JCyNpbNvDkppcNKz6BZUOKd2DZ57z8zaAgDZLCjYjUiqlfb2T5jkME+njyxi3dCPRx4f9+/ngbvv6nOfbhRBaPY1++YeAXXj78lLsd29c3xPVfpqlrzVaaNR8dH0vj6QsdroHut0Hj7vUjuHl6Q3gz8yZyGhRuRKTGfbZqLzN/3QHAC9d3oUVkoGsKsdvhuydg6XTzcUwns5vk6GHzVpRnBp6S8SDVYjEDjn8jiGgNUW0hqj1EtjUfe/k6/e0AUHQU/l5ghpo9y49vb9TSDDRdbgT/8Jp5bZE6SuFGRGrUhv1ZPPzxGgDG9G1J/w4uWsC0MA8+uQM2fmk+vuhxOP/Bsi0ZRUfh6JHjYafM7VAF246YA3WLcgED8o+Yt0PbYPM3x89rsUJ4czPoRLU/HnzCW5z+WJeMrbDiHVj1gVkLmFertL0CeoyCxPPrRyuNSA1QuBGRGpOZV8Rd768gv8hOn9aR3H9Ja9cUkp0Gc26AfSvNAaSDX4NO15bfz8vPvAXHVu/8xQXHQ1FOGmRshgPrj43rWW8GnpLBsSXhCsww0qhV2VaeqHYQ1sy85PZEtiLY+BX8+bZ5OXeJkATodqs5QDgounq1i7ghi2EYlVz07p6ysrIICQkhMzOT4OBgV5cj4rbsdoNR//uDxZvSaRzmxxdjziMswIlX5FTVgQ3wwfWQmWKOoblhNjTtXXuvbxhm4DmwwbylH/t5YKN5SXRFPHyOdW21M4NPZFvYuxL+es88FwAWaN3f7Hpq2c/1431Ealh1vr/VciMiNeK/yVtYvCkdH08rr9/czTXBZtti+Gg4FGSZXUDD5kGjFrVbg8UCQTHmrUXf49sNw7wiqCT0lASf9E3m2J+0tWWvdCoREAVnD4duIyBUa3GJVEThRkScLnlDGv9N3gLA1Gs60TE+pPaLWPkufHm/OfdGk3Pghg/q1sBai+X4JHWtLjm+3W6HI7sgfePxrq30Dea8IWcPhzaXO3dOGhE3pHAjIk61IyOXcXNXATCid1OuObtx7RZgt8MPT8KSl8zHna6Hq6aDp0/t1nG6rNbjl0G3GejqakTqJYUbEXGavMJi7npvBdn5xXRvGsZjl7ev3QKKjsKCu+HvT83HFzwCFz6iq4ZEGhiFGxE5Y4Zh8NfuI7z47WY2pWUTGeTDq8POxtvTeuqDnSU3A+bcaM71YvWCK1+BrjfW3uuLSJ2hcCMipy2noJgFf+3lg2UpbNifBYCXh4XXhp1NVHANTVpXkfTNMPs6OLzTnEhv6AfQ7Pzae30RqVMUbkSk2tbvy+KDZbtY8NdecgvNJQx8PK0M6hLHyHMT6RBXiwOId/wCc4eZizGGJcJN8yDSRfPpiEidUIttxhWbMWMGiYmJ+Pr6kpSUxPLly0+6/7Rp02jTpg1+fn4kJCRw//33k5/vpCXaRaRS+UU2Pl6xh2te/ZXLXv6FD5alkFtoo3lkAE9c0Z5lj17M89d1qd1gs2oOvHe1GWwa94TbkxVsRMS1LTdz585l/PjxvP766yQlJTFt2jT69+/Ppk2biIqKKrf/7NmzeeSRR5g5cybnnHMOmzdv5tZbb8VisfDiiy+64B2IuL/t6TnMXpbC/JV7OJJXBICn1UL/jjEMS2pC7+aNan91b8OAH6fCT8+Yjztcbc467OVXu3WISJ3k0hmKk5KS6NGjB9Onm4vY2e12EhISGDt2LI888ki5/ceMGcOGDRtITk52bHvggQdYtmwZS5YsqdJraoZikVMrstn5bn0aHyzbxa9bjy8gGR/qx01JTbiue2OigmpxTE1pxQXw2RhY+5H5+LzxcNET5iXUIuK26sUMxYWFhaxYsYIJEyY4tlmtVvr168fSpUsrPOacc87h/fffZ/ny5fTs2ZPt27fz9ddfc8stt9RW2SJube+Ro3y4PIUP/9hNenYBYF5FfVGbKIb1asIFraPwsLrwsuq8Q/DhMEj5zVyX6YqXzIntRERKcVm4ycjIwGazER1ddpG36OhoNm7cWOExN910ExkZGZx33nkYhkFxcTF33XUXjz76aKWvU1BQQEFBgeNxVlaWc96AiJuw2Q1+3pzOB8t28cPGA9iPteVGBPpwQ48EbuiZQOMwf9cWCXBwG3xwnbnitk8wXP9u2eUMRESOqVdXS/344488/fTTvPrqqyQlJbF161buu+8+nnrqKZ544okKj5k6dSpTpkyp5UpF6r707AI++nM3c5ansOfwUcf2c1o0YlhSUy5pH12789SczK6l8OFNcPQQhDSBYR+Zi0qKiFTAZWNuCgsL8ff3Z/78+QwePNixfcSIERw5coTPPvus3DHnn38+vXr14rnnnnNse//997nzzjvJycnBWkGfe0UtNwkJCRpzIw3WzoxcXvtxG5/8tYcim/nnH+LnxbXdGnNTUhNaRAa6uMITbE2GOTeArRDizoab5kJg+QsORMS91YsxN97e3nTr1o3k5GRHuLHb7SQnJzNmzJgKj8nLyysXYDw8PABzhtSK+Pj44ONTT9aUEalBm1KzmbF4K1+u2efoeuqaEMrNvZpyRedYfL08XFtgRbJT4ZM7zWDT9gq45i3wrgNdZCJSp7m0W2r8+PGMGDGC7t2707NnT6ZNm0Zubi4jR44EYPjw4cTHxzN16lQABg0axIsvvshZZ53l6JZ64oknGDRokCPkiEhZq3cfYfrirXy3Ps2xrW+bSMZc1JJuTevQKtknstvh039AXgZEd4JrZ9afxS9FxKVcGm6GDh1Keno6EydOJDU1la5du7Jw4ULHIOOUlJQyLTWPP/44FouFxx9/nL179xIZGcmgQYP497//7aq3IFInGYbBsh2HmLF4K79syQDMq54u6xjL3Re2oGN8LU60d7qWvgLbfwQvfwUbEakWl85z4wqa50bcmWEY/LgpnRmLt/LnrsMAeFgtDO4az90XtqBlVB0bT1OZvSvg7UvBXgyDXoZuI1xdkYi4WL0YcyMizmO3Gyz8O5UZi7fy9z5zugNvTyvXd2/MP/q0ICG8Ho1TKciG+aPMYNP+Ks1jIyLVpnAjUo8V2ex8vmofr/64lW3puQD4e3swLKkJd5zfvHZX5naWr/8Jh3dASAIM+q/ZnyYiUg0KNyL1UH6Rjfkr9vD6T9scc9QE+3py6zmJjDy3GWEB3i6u8DSt+QhWzwGLFYb8H/iFuboiEamHFG5E6pG8wmJmL0vhzZ+3c+DY8giNArwZdX4zbunVlCBfLxdXeAYObYcvx5v3L3gEmvRybT0iUm8p3IjUA5lHi3j3t53M/HUHh4+tzB0b4sudfZpzQ48m+HnX86kQbEXw8e1QmA1NzoE+D7q6IhGpxxRuROqwQ7mFvL1kO+/+tovsgmIAmjby5+4LWnDN2Y3rzvIIZ2rxv80rpHxD4Jo3wVrPw5qIuJTCjUgddDCngLd+2cG7S3eSV2gDoHV0IKP7tuTyTrF4erhJqAFzLpsl08z7V74CoQmurEZE3IDCjUgdkp5dwJs/b+P931M4WmSGmg5xwYy9qBWXto/GanWzK4dyM+CTfwAGdLvVvPRbROQMKdyI1AEHsvJ5/aftzF6+i/wiOwCdG4dw70WtuLhdFBZ3vBzaMOCz0ZCTChFtoP9UV1ckIm5C4UbEhVIz83n9p23MXp5CYbEZaromhHJfv1Zc2DrSPUNNieVvwuaF4OFjLq+gBTFFxEkUbkRcYO+Ro7z+4zbm/rGbQpsZaro1DeO+i1txfqsI9w41AKlr4dsnzPuXPgUxHV1bj4i4FYUbkVq0+1Aer/20jXl/7qbIZi7r1jMxnPv6teKcFo3cP9QAFObB/NvAVgCtB0DPO11dkYi4GYUbkVqQcjCPGYu38vHKPRTbzVDTq3k4913cmt4tGrm4ulq2aAJkbIbAGLjqVS2vICJOp3AjUoN2ZuQyffFWPv1rL7Zjoea8lhGMvaglSc0bWKgB+HsBrJgFWOCaNyCgAf4ORKTGKdyI1IBt6TnM+GErC1bt5VimoU/rSO67uCXdmoa7tjhXObIbvrjXvH/eOGh+oSurERE3pnAj4kRbD2Tzyg9b+WL1Pkeo6dsmknsvbsVZTRrwIpC2YvjkTsjPhPhu0PcxV1ckIm5M4UbECQzD4I2ft/Pswo2OUNOvXRT3XtyKzo1DXVpbnfDL85DyG3gHmat9e9TjBT5FpM5TuBE5Q/lFNh79ZC2f/LUXgH7tohnXrxUd40NcXFkdsWsp/PSMef+KFyG8uWvrERG3p3AjcgYOZOVz53srWLX7CB5WC5MHteeW3omuLqvuOHrYXO3bsEOXG6Hz9a6uSEQaAIUbkdO0dk8md7z7J6lZ+YT4efHqsLM5t2WEq8uqOwwDPr8XsvaYrTWXPefqikSkgVC4ETkNX67Zx4PzVpNfZKdFZABvj+hBYkSAq8uqW1b+DzZ8DlZPc5yNT5CrKxKRBkLhRqQa7HaDad9v5uUftgJwYZtIXr7xLIJ9NUC2jPRN8M0j5v2LJ5pXSImI1BKFG5EqyissZvzc1Sz8OxWAO/s05+EBbfGwaobdMoryzeUVio9C877Qe6yrKxKRBkbhRqQK9hzO4453V7BhfxbeHlaevqYT13Zr7Oqy6qbvJ0HaOvCPgKtfB6vV1RWJSAOjcCNyCn/uPMRd768gI6eQiEBv3rilW8OdZfhUNi2EZa+b9we/BkExrq1HRBokhRuRk/joz9089ulaimwG7WODeWtEd+JD/VxdVt1jt8Mfb8H3k83HSXdD60tdWpKINFwKNyIVsNkNpn69gf9bsgOAgR1jeOH6Lvh760+mnEPb4bOxsGuJ+bh5X7hkimtrEpEGTf+nFjlBVn4RY2f/xU+b0wG47+JW3HdxK6waOFxW6daaojzwCjBDTfdRGmcjIi6lcCNSyo6MXG7/3x9sS8/F18vKC9d15fLOsa4uq+45tAM+G3O8tSbxfLhqOoQlurQsERFQuBFxWLIlg9GzV5J5tIjYEF/eGt5d60OdyG6HP9+G7yZBUS54+cMlT6q1RkTqFIUbafAMw+B/v+3kqa82YLMbnNUklDdu6UZUkK+rS6tbDu2Az8fCzl/Mx03PM1trwpu5ti4RkRMo3EiDVlhsZ9Ln65izfDcA15wdz9NXd8LXy8PFldUhFbXW9JsCPW5Xa42I1EkKN9JgHcot5K73V7B8xyEsFpgwsC13nN8ci0UDhx0O7zTH1pRprXnFXAhTRKSOUriRBmnD/izuePdP9hw+SqCPJy/f2JWL2ka7uqy6Q601IlKPKdxIg5KZV8RL32/mvd93YbMbNG3kz/8N706raK1Y7VCutebcY2Nr1FojIvVDnfgn2IwZM0hMTMTX15ekpCSWL19e6b4XXnghFoul3O3yyy+vxYqlvim22Xlv6U4ufH4xs37bic1ucGn7aBbcc66CTQm7Hf74P3j1HDPYePnDwGdhxJcKNiJSr7i85Wbu3LmMHz+e119/naSkJKZNm0b//v3ZtGkTUVFR5fb/5JNPKCwsdDw+ePAgXbp04brrrqvNsqUe+XVrBk9+sZ5NadkAtI4OZOIVHTivVYSLK6tDDu+Cz8fAjp/Nx03OgcEzFGpEpF6yGIZhuLKApKQkevTowfTp0wGw2+0kJCQwduxYHnnkkVMeP23aNCZOnMj+/fsJCAg45f5ZWVmEhISQmZlJcHDwGdcvddeug7n8+6sNfLs+DYBQfy/GX9Kam3o2wdOjTjRaup5hwJ8z4buJUJgDnn7QbzL0vFNja0SkTqnO97dLW24KCwtZsWIFEyZMcGyzWq3069ePpUuXVukcb7/9NjfccEOlwaagoICCggLH46ysrDMrWuq8nIJipv+wlZlLdlBos+NhtXBLr6aM69eKUH9vV5dXdxxJMcfW7PjJfNzkHHNsTaMWrq1LROQMuTTcZGRkYLPZiI4ue5VKdHQ0GzduPOXxy5cvZ926dbz99tuV7jN16lSmTNEifg2B3W4wf+Uenl24iYwcM9Ce3yqCiVe017iaE234Ej79R6nWmknQ8x9qrRERt+DyMTdn4u2336ZTp0707Nmz0n0mTJjA+PHjHY+zsrJISEiojfKkFv258xBTvljP2r2ZADSLCODxy9txUdsozVtzoj/ehq8fBMMOCb1g8KtqrRERt+LScBMREYGHhwdpaWlltqelpRETE3PSY3Nzc/nwww958sknT7qfj48PPj4+Z1yr1E17jxzlP99s5IvV+wAI8vHk3otbMeKcRLw91QpRhmHAD/+CX543H589Ai5/ETzq9b9xRETKcen/1by9venWrRvJyckMHjwYMAcUJycnM2bMmJMeO2/ePAoKCrj55ptroVKpa44W2nj9p2288fM28ovsWCxwQ48EHri0DRGBCrPl2Irgy3Hw1/vm4wsnwAUPg1q1RMQNufyfbOPHj2fEiBF0796dnj17Mm3aNHJzcxk5ciQAw4cPJz4+nqlTp5Y57u2332bw4ME0atTIFWWLixiGwRdr9vOfrzewLzMfgJ7Nwpl4RXut4F2ZwlyYdyts+RYsVrjiJeh2q6urEhGpMS4PN0OHDiU9PZ2JEyeSmppK165dWbhwoWOQcUpKCtYTBjlu2rSJJUuW8O2337qiZHGRNXuO8OQX6/lz12EA4kP9eOzydgzsGKNxNZXJzYAProN9K82Bw9e9A20GuroqEZEa5fJ5bmqb5rmpfw5k5/Pcwk3MX7kHwwA/Lw/uubAFd/RprtW7T+bQDnj/Gji0HfzC4aaPIKGHq6sSETkt9WaeG5FTWbYtnW/efZY/CttgGLFcfVY8Dw9oS0yIr6tLq9v2/WW22OSmQ0gTuOUTiGjl6qpERGqFwo3UWRv2Z7HgvWlMtbzJAb9I9g37ka4tGru6rLpv6/cwd7i5mndMJxg2H4JOfvWhiIg70bWyUiftPpTHiJnLOd9mLqIaZU+n65YZLq6qHlj9IcweagabZhfArV8r2IhIg6NwI3XOwZwChs9czuHsXC70WHv8iWWvw94VriusLjMMWPKSOeuwvRg6XWe22PhqXJmINDwKN1Kn5BQUM3LWH+zIyOXyoG34cxQCoqDjteaMup/fZ87ZIsfZbfDNQ/D9ZPPxOWPh6jfBU+toiUjDpHAjdUZhsZ2731/Bmj2ZhAd4M7ndHvOJ1pfCgP+AXxikrYWl6p5yKMqH+SNh+Zvm4/5T4dJ/aY0oEWnQ9H9AqRPsdoMH563mly0Z+Ht7MHNEd0JTvjefbD0QAiPh0n+bj3+cal7e3NAdPWJe6r3+M/DwhmtnQu97XF2ViIjLKdyIyxmGwVNfrefz1fvwtFp4/eZudPVNgyO7zC/t5heaO3a9CZr1geJ8+PJ+c5xJQ5W5F2YOgF2/gk8w3PwxdBzi6qpEROoEhRtxudd+2sY7v+4E4IXru9CndSRsXmg+2awP+ASa9y0WuGIaePrC9h9hzVxXlOt6BzbA25dA+gYIjIGR35i/JxERARRuxMU++mM3zy7cBMATV7Tnqq7x5hMl4ab1gLIHNGphLvgIsHCCubxAQ7LrN5jZH7L2QkRruP07iOno6qpEROoUhRtxme/Wp/HIJ2sAuOuCFow6r5n5RN4h2L3MvN+6f/kDzxkL0R3h6CFY9FgtVVsHrP8M3h0M+ZmQkAS3LYLQJq6uSkSkzlG4EZf4c+chxsxeid2A67o15uEBbY4/ueU787LvqA4Vf3l7eMGglwELrPkQtibXWt0us+xN+GgE2Aqg7RUw/DPwD3d1VSIidZLCjdS6TanZ3DbrDwqK7VzcNoqp13Qqu6p3SZdUmwEVnwCgcTdI+od5/8v7oTCv5gp2lfxM2PAFfHwHfPNPwIDut8H174KXn6urExGps7S2lNSqPYfzGD5zGVn5xXRrGsb0m87G06NUxrYVHW+JOXG8zYkuehw2fGleVfXjVLj0qZorvDbYbbB/FWz9AbYlw+7lYNiOP9/3cejzoDmwWkREKqVwI7XmUG4hw2cuJy2rgFZRgbw9ojt+3h5ld0pZCgWZ4B8B8d1OfkKfILj8BZgz1JzYr9O1ENul5t5ATcjaD9uOhZlti81xRKU1agktLob2V0Liea6pUUSknlG4kVqRV2guq7A9PZe4EF/eHdWTUP8KlgfYdKxLqtWlYPUo//yJ2gyADlfD35/C5/fCHT9U7ThXKcqHlN/MQLP1Bzjwd9nnfYLNy7pbXmyGmrCmrqlTRKQeU7iRGldks3P3+ytZvfsIof5evDuqJ7EhlYwZqcp4mxMNeMYMC/tXmYtr9h59xjU7jWFAxmazq21bMuz8FYqPltrBAnFnHQ8zjbubA6ZFROS0KdxIjbLbDR6av4afNqfj5+XBzFt70DIqqOKdM7bAoW1g9YLmfav+IkHRcMlT8MW98MO/zKuJXNnicfQwbP/JDDNbf4CsPWWfD4w5FmYuMt9nQCPX1Cki4qYUbqRGTf1mA5/+tRcPq4VXbz6bs5uEVb5zSatN4nngG1y9FzrrFnPG4l2/wlcPwLB5tT/wdt9fsPBR2P27eSl7CQ8faNrbbJlpeTFEtdegYBGRGqRwIzXmjZ+28dYvOwB4dkhn+raJOvkBmyqZlbgqrFZzaYbXz4Wt38G6j80BxrXBMOCP/4NFj4Kt0NwW0fp4mGl6Lnj7104tIiKicCM1Y/6KPUz9ZiMAj17WliHdGp/8gKOHzSuloOJZiasisjX0+Scs/jcsfMTs9qnpie7yM+HzsebswQBtLocBUzUQWETEhTSJnzjdDxvTePhjc1mFO/s0584+LU590NZkc06XyLYQ3uz0X/zcceY5ctPhuydO/zxVse8veKOPGWysXjDgP3DDBwo2IiIupnAjTrVi12Hu+WAlNrvBNWfF88iAtlU7sLKFMqvL0/vY0gzAX+/Djp/P7HwVMQxzOYS3L4XDO80lIm5bBL3u1lgaEZE6oNrhJjExkSeffJKUlJSaqEfqsS1p5rIK+UV2LmwTyTPXdsZqrcKXva3YXE8KzjzcADRJgu6jzPtf3AdFR0++f3XkZ8JHw83lEGyF5pVZ//jZXA5CRETqhGqHm3HjxvHJJ5/QvHlzLrnkEj788EMKCgpqojapR44W2rjzvRVkHi2ia0Iorw47Gy+PKv7ntXsZ5B8BvzBI6OmcgvpNgqBYOLQdfn7eOecs6Yba8Pnxbqih75t1i4hInXFa4WbVqlUsX76cdu3aMXbsWGJjYxkzZgwrV66siRqlHnjp+83syMglOtiHmbf2wN+7GmPVN39j/qzqrMRV4RsClz1n3v91GqT9fdLdT0rdUCIi9cppj7k5++yzefnll9m3bx+TJk3i//7v/+jRowddu3Zl5syZGIbhzDqlDvsr5TD/98t2AJ6+uhPhARUsq3AymxeZP53RJVVau0Fmt5G92FyawW479TEnUjeUiEi9c9rhpqioiI8++ogrr7ySBx54gO7du/N///d/DBkyhEcffZRhw4Y5s06powqKbTw0fw12AwZ3jePidtHVO8HBbebyBFZPc04YZ7vsOXO9pr1/wh9vV+9YdUOJiNRL1Z7nZuXKlbzzzjvMmTMHq9XK8OHDeemll2jb9vhVMVdffTU9evRwaqFSN72SvJUtB3KICPRm0qAO1T9BSatN03PMriRnC44zx9989QAkT4G2l0HIKebcMQxY/hZ8+5jZWhPaBK6dpdYaEZF6otrhpkePHlxyySW89tprDB48GC+v8ov8NWvWjBtuuMEpBUrdtW5vJq/9tA2Ap67qSFh1u6Pg+HgbZ3dJldbtNljzkTlw+et/wg2zKx8rk58Jn40xW2vA7Ia6arpaa0RE6pFqh5vt27fTtOnJJykLCAjgnXfeOe2ipO4rstn55/w12OwGl3WKYWCn2OqfJD8Tdv1m3q/JcGO1wqD/wuvnw6avzeDS/qry++1dCfNHmoOGrV5w6VOQdJcGDYuI1DPVHnNz4MABli1bVm77smXL+PPPP51SlNR9r/24jQ37swj192LKlR1P7yRbk83Bvo1aQaMqzGJ8JqLawXn3m/e/fgiOHjn+nGHAsjd0NZSIiJuodrgZPXo0u3fvLrd97969jB492ilFSd22KTWbV37YAsDkQR2IDPI5vROVjLdpU4OtNqWd/4AZpHJS4fvJ5rajR+CjW+Cbh8BepKuhRETcQLW7pdavX8/ZZ59dbvtZZ53F+vXrnVKU1F3FNjsPzV9Nkc2gX7soruoad3onsttgy7fm/ZrskirNy9fsnpp1Gax4B6I7wG+vwJFd6oYSEXEj1W658fHxIS0trdz2/fv34+mpRcbd3dtLdrB6TyZBvp78a3AnLKcbBPb8AUcPmVdIJSQ5t8iTSTwXzh5h3v/6QTPYhDaBUeqGEhFxF9UON5deeikTJkwgMzPTse3IkSM8+uijXHLJJdUuYMaMGSQmJuLr60tSUhLLly8/6f5Hjhxh9OjRxMbG4uPjQ+vWrfn666+r/bpSfdvSc3jhu80APHF5e2JCfE//ZCULZba8BDzKX3FXoy6ZAoHH5uNpewX84xeIVzeUiIi7qHZTy/PPP0+fPn1o2rQpZ511FgCrVq0iOjqa9957r1rnmjt3LuPHj+f1118nKSmJadOm0b9/fzZt2kRUVFS5/QsLC7nkkkuIiopi/vz5xMfHs2vXLkJDQ6v7NqSabHaDh+avobDYzvmtIriu+ynmijmVTU5aBfx0+IXB7clwcCs0v1CtNSIibsZinMY6Cbm5uXzwwQesXr0aPz8/OnfuzI033ljhnDcnk5SURI8ePZg+fToAdrudhIQExo4dyyOPPFJu/9dff53nnnuOjRs3Vvu1SmRlZRESEkJmZibBwcGndY6G6J1fdzDli/UEeHuw6P4+NA7zP/2THd4J/+0CFg/451bwD3danSIi4p6q8/19WoNkAgICuPPOO0+ruBKFhYWsWLGCCRMmOLZZrVb69evH0qVLKzzm888/p3fv3owePZrPPvuMyMhIbrrpJh5++GE8PCpecLGgoKDMquVZWVlnVHdDlHIwj2cXbgLgkcvanVmwgeNXSTXppWAjIiJOd9ojgNevX09KSgqFhYVltl955ZVVOj4jIwObzUZ0dNm1iKKjo9m4cWOFx2zfvp0ffviBYcOG8fXXX7N161buueceioqKmDRpUoXHTJ06lSlTplSpJinPMAwe/ngNR4tsJDULZ1jPJmd+0s0u7JISERG3d1ozFF999dWsXbsWi8XiWP275KoZm+00Vl6uIrvdTlRUFG+++SYeHh5069aNvXv38txzz1UabiZMmMD48eMdj7OyskhISKixGt3N7OUpLN1+EF8vK88M6YzVeobjUwqyYecS877CjYiI1IBqXy1133330axZMw4cOIC/vz9///03P//8M927d+fHH3+s8nkiIiLw8PAod1l5WloaMTExFR4TGxtL69aty3RBtWvXjtTU1HItSCV8fHwIDg4uc5Oq2XvkKFO/NlvR/tm/LYkRAWd+0m2LzcUow5tDRKszP5+IiMgJqh1uli5dypNPPklERARWqxWr1cp5553H1KlTuffee6t8Hm9vb7p160ZycrJjm91uJzk5md69e1d4zLnnnsvWrVux2+2ObZs3byY2NhZv79NYtFEqZRgGj36ylpyCYs5uEsqt5yQ658Slu6R0lZKIiNSAaocbm81GUFAQYLa+7Nu3D4CmTZuyadOmap1r/PjxvPXWW/zvf/9jw4YN3H333eTm5jJy5EgAhg8fXmbA8d13382hQ4e477772Lx5M1999RVPP/20ln2oAR+v3MtPm9Px9rTy7LVd8DjT7igAu/34YGJ1SYmISA2p9pibjh07snr1apo1a0ZSUhLPPvss3t7evPnmmzRv3rxa5xo6dCjp6elMnDiR1NRUunbtysKFCx2DjFNSUrBaj+evhIQEFi1axP3330/nzp2Jj4/nvvvu4+GHH67u25CTSMvK58kv/gZgXL9WtIwKdM6J966AvAzwCYYmFbfOiYiInKlqz3OzaNEicnNzueaaa9i6dStXXHEFmzdvplGjRsydO5eLLrqopmp1Cs1zc3KGYXDHuyv4fkManeJD+PSec/D0qHYDX8WSn4JfnocOV8N1s5xzThERaRBqdJ6b/v37O+63bNmSjRs3cujQIcLCwk5/nSGpM75Ys5/vN6Th5WHhues6Oy/YgC4BFxGRWlGtb66ioiI8PT1Zt25dme3h4eEKNm7gYE4Bkz83u6NG921J2xgntmwd2Q1p68BiNdeTEhERqSHVCjdeXl40adKkRueyEdeZ9PnfHMotpG1MEPdc2NK5Jy9ptWncEwIaOffcIiIipVS7z+Gxxx7j0Ucf5dChQzVRj7jIwnWpfLlmPx5WC89d2wVvTyd2R8Hxq6TaqEtKRERqVrXH3EyfPp2tW7cSFxdH06ZNCQgoO7HbypUrnVac1I4jeYU8vsDsavxHn+Z0ahzi3BcozIUdP5v3Nd5GRERqWLXDzeDBg2ugDHGlJ79cT0ZOAS0iA7j34hqYNXj7j2ArgNCmENnW+ecXEREppdrhprI1nKR+WrzxAJ+s3IvFAs9e2wVfr4pXVz8jm74xf2pWYhERqQVOHlgh9UlWfhETPlkLwKhzm9GtaZjzX8Ruhy3fmvc13kZERGpBtVturFbrSS/71pVU9cfUrzeQmpVP00b+PHBpm5p5kf1/QU4aeAdC03Nr5jVERERKqXa4+fTTT8s8Lioq4q+//uJ///sfU6ZMcVphUrOWbMlgzvLdADwzpDN+3jXQHQXHr5JqcRF4+tTMa4iIiJRS7XBz1VVXldt27bXX0qFDB+bOncuoUaOcUpjUnLzCYh75ZA0At/RqSq/mNTjvTOnxNiIiIrXAaWNuevXqRXJysrNOJzXo81X72HP4KHEhvjw8sAavXsraB6lrAAu0urTmXkdERKQUp4Sbo0eP8vLLLxMfH++M00kNW7BqLwA3925KoE+1G++qzjErcXcIjKy51xERESml2t9sJy6QaRgG2dnZ+Pv78/777zu1OHG+fUeOsmyHObv0lV3iavbFSsbbqEtKRERqUbXDzUsvvVQm3FitViIjI0lKSiIsrAYuJRan+nz1PgwDeiaG0zjMv+ZeqDDPnLwPFG5ERKRWVTvc3HrrrTVQhtSWBX+ZXVKDz6rhLsQdP0NxPoQkQHSHmn0tERGRUqo95uadd95h3rx55bbPmzeP//3vf04pSmrGptRsNqZm4+Vh4bJOMTX7YiXjbVr316zEIiJSq6odbqZOnUpERES57VFRUTz99NNOKUpqRslA4gvbRBHq711zL2QYGm8jIiIuU+1wk5KSQrNmzcptb9q0KSkpKU4pSpzPbjf4rKRLqmsNd0mlroHsfeDlD4nn1+xriYiInKDa4SYqKoo1a9aU27569WoaNarByeDkjPyx8xD7MvMJ8vHk4jbh8O0T8MO/IXWd2dLiTJuOdUk17wtevs49t4iIyClUe0DxjTfeyL333ktQUBB9+vQB4KeffuK+++7jhhtucHqB4hwLVu0DYEDHGHx3JMNvL5tP/PwshLeA9leZt9guZz5GpmS8jRbKFBERF6h2uHnqqafYuXMnF198MZ6e5uF2u53hw4drzE0dVVhs5+u1+4FjV0nt/958IiAS8rPg0DZY8qJ5C216LOgMhvizqx90slNh30rzvmYlFhERF6h2uPH29mbu3Ln861//YtWqVfj5+dGpUyeaNm1aE/WJE/y46QCZR4uICvIx15Fas9l8IukuSPqHOfh3/Wew5Ts4ssts1fntZfMy7nZXmmGncQ+wVqEXc8u35s+4syGohq/IEhERqcBpz73fqlUrWrVq5cxapIaUXCV1ZZc4PKwWyNhkPhHZBnyCoNO15q0w1ww46z8zA0/mbvh9hnkLij0edJr0Amslq4iXjLfRVVIiIuIi1R5QPGTIEJ555ply25999lmuu+46pxQlzpOVX8T3Gw4Ax7qkDAMytphPRrQuu7N3AHQYDNe9Aw9tg6EfQKfrwTsIsvfD8jdg1mXwQlv4crw5UZ+t+PjxRfmwfbF5X+NtRETERardcvPzzz8zefLkctsHDhzICy+84IyaxIkWrkulsNhOy6hAOsQFQ9ZeKMwBqyeEN6/8QC8/aHeFeSsugG2LzRadTV9B7gH4823z5h9h7tP+KnO/ojwIioOYzrX3JkVEREqpdrjJycnB27v8BHBeXl5kZWU5pShxns9WlcxtE2euCZZ+rEsqvDl4eFXtJJ4+ZktMmwFQXGi22KxfABu/hLwMWDHLvHFs8LFmJRYREReqdrdUp06dmDt3brntH374Ie3bt3dKUeIcaVn5/LbtIABXlUzcV1mXVFV5ekOrfnDVdHhwC9yyALqNNFtwODZfTrtBZ1S3iIjImah2y80TTzzBNddcw7Zt27jooosASE5OZvbs2cyfP9/pBcrp+3yVuQJ4t6ZhJIQfWwG89GDiM+XhBS36mrfLX4Bdv5mDkltefObnFhEROU3VDjeDBg1iwYIFPP3008yfPx8/Pz+6dOnCDz/8QHh4eE3UKKep5CqpMiuApx+7DPx0W24qY/WAZlpqQUREXO+0LgW//PLLufzyywHIyspizpw5PPjgg6xYsQKbzebUAuX0bD2Qzd/7svC0Wri8U+zxJ0pabpwdbkREROqIao+5KfHzzz8zYsQI4uLieOGFF7jooov4/fffnVmbnIEFf5nLLVzQOpLwgGMDwPMOQW66eV/hRkRE3FS1Wm5SU1OZNWsWb7/9NllZWVx//fUUFBSwYMECDSauQwzDcHRJXVW6S6pkMHFwY/AJdEFlIiIiNa/KLTeDBg2iTZs2rFmzhmnTprFv3z5eeeWVmqxNTtOKXYfZc/goAd4eXNIu+vgTjsHEarURERH3VeVw88033zBq1CimTJnC5ZdfjodHJdPvn4YZM2aQmJiIr68vSUlJLF++vNJ9Z82ahcViKXPz9fV1Wi3uoKTVpn/HGPy8S31OJXPcRDjhSikREZE6qsrhZsmSJWRnZ9OtWzeSkpKYPn06GRkZZ1zA3LlzGT9+PJMmTWLlypV06dKF/v37c+DAgUqPCQ4OZv/+/Y7brl27zrgOd1Fks/PVmmMrgHeNL/tkRsmVUloTTERE3FeVw02vXr1466232L9/P//4xz/48MMPiYuLw263891335GdnX1aBbz44ovccccdjBw5kvbt2/P666/j7+/PzJkzKz3GYrEQExPjuEVHR1e6b0Pz8+Z0DucVERHowzktGpV9Mt2Jc9yIiIjUUdW+WiogIIDbbruNJUuWsHbtWh544AH+85//EBUVxZVXXlmtcxUWFrJixQr69et3vCCrlX79+rF06dJKj8vJyaFp06YkJCRw1VVX8ffff1e6b0FBAVlZWWVu7mzBKvMqqUFdYvH0KPXxFh2FIynmfXVLiYiIGzvtS8EB2rRpw7PPPsuePXuYM2dOtY/PyMjAZrOVa3mJjo4mNTW10tecOXMmn332Ge+//z52u51zzjmHPXv2VLj/1KlTCQkJcdwSEhKqXWd9kVNQzHfrzd/b1Wed0CV1cCtggF8YBETUfnEiIiK15IzCTQkPDw8GDx7M559/7ozTnVTv3r0ZPnw4Xbt25YILLuCTTz4hMjKSN954o8L9J0yYQGZmpuO2e/fuGq/RVRatSyW/yE7ziAA6xYeUfbL0YGItaikiIm7stGYodpaIiAg8PDxIS0srsz0tLY2YmJgqncPLy4uzzjqLrVu3Vvi8j48PPj4+Z1xrfeCY26ZrvLkCeGkaTCwiIg2EU1puTpe3tzfdunUjOTnZsc1ut5OcnEzv3r2rdA6bzcbatWuJjY099c5u7EB2Pr9uNa9eu6prXPkdNJhYREQaCJe23ACMHz+eESNG0L17d3r27Mm0adPIzc1l5MiRAAwfPpz4+HimTp0KwJNPPkmvXr1o2bIlR44c4bnnnmPXrl3cfvvtrnwbLvfl6v3YDeiaEEpiRED5HRwtNwo3IiLi3lweboYOHUp6ejoTJ04kNTWVrl27snDhQscg45SUFKzW4w1Mhw8f5o477iA1NZWwsDC6devGb7/91uCXfyjpkio3kBjAbjs2oBjNTiwiIm7PYhiG4eoialNWVhYhISFkZmYSHBzs6nKcYnt6Dhe98BMeVgvLHr2YiMATxhgd3AavnA2evvDofrC6tDdSRESk2qrz/a1vOTdQMrfN+a0iygcbON4l1aiVgo2IiLg9fdPVc4Zh8NmxLqlyyy2USNeCmSIi0nAo3NRzf+0+wq6Defh5eXBJ+0qWodBgYhERaUAUbuq5z/46tgJ4h2gCfCoZH66WGxERaUAUbuqxIpudL4+tAH5VRVdJARgGZGwx76vlRkREGgCFm3psydYMDuYW0ijAm/NbVrJeVE4aFGSCxQqNWtRugSIiIi6gcFOPlXRJXdH5hBXASyvpkgpLBM+GsQyFiIg0bAo39VRuQTGL/jbX5BpcWZcUaDCxiIg0OAo39dR369M4WmSjaSN/uiaEVr6jBhOLiEgDo3BTT510BfDS1HIjIiINjMJNPZSRU8AvW8wVwAdXtAJ4mZ2PhRutBi4iIg2Ewk099NWa/djsBp0bh9A8MrDyHfMzIdu8VJyIVrVTnIiIiIsp3NRDn/51iuUWSpTMbxMYA74hNVyViIhI3aBwU8/szMhl1e4jWC1wRZfYk++swcQiItIAKdzUM58dWwH83JYRRAX5nnznjGPhRoOJRUSkAVG4qUeqtAJ4aSXdUhpMLCIiDYjCTT2ydm8m2zNy8fWy0r9jzKkPKOmW0mBiERFpQBRu6pGSgcSXtI8hsLIVwEsUF8DhHeZ9dUuJiEgDonBTTxTb7Hyx2rys+5Rz2wAc3AaGHXyCIagKrTwiIiJuQuGmnvht20EycgoI8/eiT+vIUx/gGEzcGk42g7GIiIibUbipJ0qWW7i8cyxela0AXpoGE4uISAOlcFMPHC20sWhdKlDFq6RAg4lFRKTBUripB77bkEZuoY3GYX50axpWtYM0x42IiDRQCjf1wGellls46QrgJex2yNhq3le3lIiINDAKN3XcodxCftqcDsDgs6pwlRRAZgoUHwUPbwhtWoPViYiI1D0KN3XcV2v3U2w36BAXTMuooKodVDKYuFFL8DjFfDgiIiJuRuGmjvt6TcncNlUcSAylBhNrwUwREWl4FG7qsIJiGytTDgNwUbuoqh+YoXAjIiINl8JNHbZmTyYFxXYiAr1pHhFQ9QPTN5s/NZhYREQaIIWbOmz5jkMA9GwWXrWrpAAMQy03IiLSoCnc1GHLSsJNYnjVD8rNgKOHAYsm8BMRkQZJ4aaOKrbZWbGzpOWmUdUPzDjWJRXaBLz8aqAyERGRuk3hpo5avz+L3EIbwb6etImp4iXgoC4pERFp8BRu6qiS8TY9EsPxsFZjVW8NJhYRkQZO4aaOWlZqMHG1qOVGREQauDoRbmbMmEFiYiK+vr4kJSWxfPnyKh334YcfYrFYGDx4cM0WWMvsdoM/dp5muFHLjYiINHAuDzdz585l/PjxTJo0iZUrV9KlSxf69+/PgQMHTnrczp07efDBBzn//PNrqdLas+VADkfyivD39qBjfEjVDyzIgaw95n213IiISAPl8nDz4osvcscddzBy5Ejat2/P66+/jr+/PzNnzqz0GJvNxrBhw5gyZQrNmzevxWprx/IdBwHo1jQML49qfEQHj60p5R8B/tVs8REREXETLg03hYWFrFixgn79+jm2Wa1W+vXrx9KlSys97sknnyQqKopRo0ad8jUKCgrIysoqc6vrfj+d+W1AXVIiIiK4ONxkZGRgs9mIjo4usz06OprU1NQKj1myZAlvv/02b731VpVeY+rUqYSEhDhuCQkJZ1x3TTIMo8zMxNWiwcQiIiKu75aqjuzsbG655RbeeustIiIiqnTMhAkTyMzMdNx2795dw1WemZ0H80jPLsDbw0qXhNDqHVyyGrhabkREpAHzdOWLR0RE4OHhQVpaWpntaWlpxMTElNt/27Zt7Ny5k0GDBjm22e12ADw9Pdm0aRMtWrQoc4yPjw8+Pj41UH3NKBlv0zUhFF8vj+odXDI7sVpuRESkAXNpy423tzfdunUjOTnZsc1ut5OcnEzv3r3L7d+2bVvWrl3LqlWrHLcrr7ySvn37smrVqjrf5VQVpz2/ja0IDm037yvciIhIA+bSlhuA8ePHM2LECLp3707Pnj2ZNm0aubm5jBw5EoDhw4cTHx/P1KlT8fX1pWPHjmWODw0NBSi3vb467fE2h3aAvRi8AiCkcQ1UJiIiUj+4PNwMHTqU9PR0Jk6cSGpqKl27dmXhwoWOQcYpKSlYrfVqaNBp23vkKHsOH8XDauHspmHVO9gxmLgVWKqxXIOIiIibcXm4ARgzZgxjxoyp8Lkff/zxpMfOmjXL+QW5yB/HWm06xgUT6FPNj0aDiUVERIB6drWUuysZb5PUvFH1D9ZgYhEREUDhpk4puVKq2pP3wfFwo5YbERFp4BRu6oj07AK2pedisUCP6oYbw4CMY0svqOVGREQaOIWbOqJkFfA20UGE+HtV7+CsvVCYA1ZPCHe/tbZERESqQ+Gmjii5BDypupeAw/HBxOHNwaOawUhERMTNKNzUEccn79NgYhERkTOhcFMHZOYVsTHVXK28R7Nqzm8DugxcRESkFIWbOuDPXYcwDGgeEUBUkG/1T6DBxCIiIg4KN3XAaS+5UMIxO7HCjYiIiMJNHXDai2UC5B2C3HTzvsKNiIiIwo2r5RYUs25vJnCGMxMHNwafQCdWJiIiUj8p3LjYXylHKLYbxIf6ER/qV/0TOAYTq9VGREQEFG5crmTJhdOa3wZ0GbiIiMgJFG5c7PczHkyscCMiIlKawo0L5RfZWLX7CHAG4UZz3IiIiJShcONCa/ZkUlhsJyLQh2YRAdU/QdFROJJi3o9QuBEREQGFG5cqPd7GYrFU/wQZWwAD/MIgIMK5xYmIiNRTCjcudEbz20DZ8TanE45ERETckMKNixTb7KzYdRjQYGIRERFnUrhxkb/3ZZFXaCPEz4s20UGndxINJhYRESlH4cZFStaT6pEYjtV6ml1KjpYbhRsREZESCjcuUjLe5rQn77MVw8Gt5n3NTiwiIuKgcOMCdrvBHzvPcDDxkV1gKwRPXwhp4sTqRERE6jeFGxfYlJZN5tEi/L096BAXfHonKemSatQKrPoYRURESuhb0QVKxtt0axqGp8dpfgRaMFNERKRCCjcusPxMx9uABhOLiIhUQuGmlhmGUWryvkanfyK13IiIiFRI4aaW7cjIJSOnAG9PK50bh5zeSQxDLTciIiKVULipZSVdUl0TQvH18ji9k+SkQUEWWKzQqIUTqxMREan/FG5qmVPG25R0SYUlgqfPmRclIiLiRhRuatnxyfvOYLyNuqREREQqpXBTi/YczmPvkaN4Wi2c3TT09E+kwcQiIiKVUripRSWzEneMD8Hf2/P0T5RxLNyo5UZERKQchZtatGy7E8bbAKSXdEup5UZEROREdSLczJgxg8TERHx9fUlKSmL58uWV7vvJJ5/QvXt3QkNDCQgIoGvXrrz33nu1WO3pW77jDNeTAsjPhJxU8766pURERMpxebiZO3cu48ePZ9KkSaxcuZIuXbrQv39/Dhw4UOH+4eHhPPbYYyxdupQ1a9YwcuRIRo4cyaJFi2q58uo5kJ3P9oxcLBbo3vRMZibeYv4MjAHf05wnR0RExI25PNy8+OKL3HHHHYwcOZL27dvz+uuv4+/vz8yZMyvc/8ILL+Tqq6+mXbt2tGjRgvvuu4/OnTuzZMmSWq68ev7YcRiAtjHBhPh7nf6JNJhYRETkpFwabgoLC1mxYgX9+vVzbLNarfTr14+lS5ee8njDMEhOTmbTpk306dOnJks9Y8t3HAScMN5Gg4lFRERO6gwu2TlzGRkZ2Gw2oqOjy2yPjo5m48aNlR6XmZlJfHw8BQUFeHh48Oqrr3LJJZdUuG9BQQEFBQWOx1lZWc4pvpqWOWO8DWgwsYiIyCm4NNycrqCgIFatWkVOTg7JycmMHz+e5s2bc+GFF5bbd+rUqUyZMqX2iyzlSF4hm9KyAeiReKYtN8fCjbqlREREKuTScBMREYGHhwdpaWlltqelpRETE1PpcVarlZYtWwLQtWtXNmzYwNSpUysMNxMmTGD8+PGOx1lZWSQkJDjnDVTRnzsPYxjQIjKAyKAzWC6huAAO7zDvq1tKRESkQi4dc+Pt7U23bt1ITk52bLPb7SQnJ9O7d+8qn8dut5fpeirNx8eH4ODgMrfatnxnSZfUGSy5AHBwGxh28AmGoMrDn4iISEPm8m6p8ePHM2LECLp3707Pnj2ZNm0aubm5jBw5EoDhw4cTHx/P1KlTAbObqXv37rRo0YKCggK+/vpr3nvvPV577TVXvo2TWuaMxTKh1GDi1mCxnGFVIiIi7snl4Wbo0KGkp6czceJEUlNT6dq1KwsXLnQMMk5JScFqPd7AlJubyz333MOePXvw8/Ojbdu2vP/++wwdOtRVb+GkcgqKWbc3E3DiYOJIdUmJiIhUxmIYhuHqImpTVlYWISEhZGZm1koX1c+b0xk+czmNw/xY8vBFZ3ay+bfBuo+h32Q4736n1CciIlIfVOf72+WT+Lk7pyy5UKLkSikNJhYREamUwk0NW+6s8TZ2O2RsNe+rW0pERKRSCjc1KL/IxqrdRwAnXCmVmQLFR8HDG0KbnnlxIiIibkrhpgat3n2EQpudyCAfEhv5n9nJSgYTN2oJHi4fBy4iIlJnKdzUoNLjbSxneum24zLwVmdYlYiIiHtTuKlBJZP39dJgYhERkVqjcFNDimx2Vuw6DDhhvA1ojhsREZEqUripIX/vyyKv0EaovxetogLP7GSGUXZ2YhEREamUwk0NWbb9IGCuAm61nuF4m9wMOHoYsJgDikVERKRSCjc1xGnz28DxVpvQBPA+w6uuRERE3JzCTQ2w2Y1SK4E7Idykl3RJabyNiIjIqSjc1IBNqdlk5xcT4O1B+1gnrF+VscX8qcHEIiIip6RwUwOW7zDH23RLDMfTwwm/Yg0mFhERqTKFmxpQ0iXllPE2oMvARUREqkHhxskMw3DuSuAFOZC1x7yvlhsREZFTUrhxsu0ZuWTkFOLjaaVz45AzP2HJzMT+EeDvpJYgERERN6Zw42QlrTZnNQnFx9PjzE+owcQiIiLVonDjZMe7pJyw5AJoMLGIiEg1Kdw4mVMn7yvKhx0/m/fVciMiIlIlCjdOtPtQHnuPHMXTauGsJqFndrK8Q/D+NbDnD7B6QvO+TqlRRETE3Xm6ugB3UtJq06lxCP7eZ/CrPZIC719rdkn5BMPQ9yCqrZOqFBERcW8KN07klEvA962C2ddDThoExcHN8yG6g3MKFBERaQAUbpzojCfv2/I9fDQcinIhqgMMmwch8U6sUERExP0p3DjJgax8dmTkYrFAt6anEW5WvgtfjAPDBs0uMLuifJ0wT46IiEgDo3DjJCtTDgPQLiaYED+vqh9oGPDjVPjpGfNx5xvgylfA07sGqhQREXF/CjdO0r9DDD/980IO5RZW/SBbEXxxH6z6wHx8/oNw0eNgsdRMkSIiIg2Awo2TWCwWmjYKoGmjgKodkJ9ljq/ZvhgsHnD5C9B9ZM0WKSIi0gAo3LhC1j744HpIWwte/nDd/6D1pa6uSkRExC0o3NS2AxvMOWyy9kBAJNz0EcSf7eqqRERE3IbCTW3a8TN8eDMUZEKjVuYcNmGJrq5KRETErSjc1JY182DB3WAvgoRecOMc8HfC+lMiIiJShsJNTTMMWPISJE8xH7e/Cq5+E7x8XVuXiIiIm1K4qUm2YvjmIfjzbfNxr9Fw6b/AqvVKRUREaorCTU0pzIX5o2DzN4AFBkyFXne7uioRERG3p3BTE3LSzcUv960ET1+45k2zO0pERERqXJ3oH5kxYwaJiYn4+vqSlJTE8uXLK933rbfe4vzzzycsLIywsDD69et30v1rXcZWeLufGWz8wmD45wo2IiIitcjl4Wbu3LmMHz+eSZMmsXLlSrp06UL//v05cOBAhfv/+OOP3HjjjSxevJilS5eSkJDApZdeyt69e2u58gqkLIO3L4HDOyG0KYz6DpokuboqERGRBsViGIbhygKSkpLo0aMH06dPB8But5OQkMDYsWN55JFHTnm8zWYjLCyM6dOnM3z48FPun5WVRUhICJmZmQQHB59x/Q5bvoO5N0NxPsSdZU7OFxjlvPOLiIg0YNX5/nZpy01hYSErVqygX79+jm1Wq5V+/fqxdOnSKp0jLy+PoqIiwsMrnjOmoKCArKysMrcaEd4cvAOg9QC49SsFGxERERdxabjJyMjAZrMRHR1dZnt0dDSpqalVOsfDDz9MXFxcmYBU2tSpUwkJCXHcEhISzrjuCjVqYXZDDf3ADDkiIiLiEi4fc3Mm/vOf//Dhhx/y6aef4utb8aR4EyZMIDMz03HbvXt3zRXUqAV46AI0ERERV3LpN3FERAQeHh6kpaWV2Z6WlkZMTMxJj33++ef5z3/+w/fff0/nzp0r3c/HxwcfHx+n1CsiIiJ1n0tbbry9venWrRvJycmObXa7neTkZHr37l3pcc8++yxPPfUUCxcupHv37rVRqoiIiNQTLu9DGT9+PCNGjKB79+707NmTadOmkZuby8iRIwEYPnw48fHxTJ06FYBnnnmGiRMnMnv2bBITEx1jcwIDAwkMDHTZ+xAREZG6weXhZujQoaSnpzNx4kRSU1Pp2rUrCxcudAwyTklJwVpqLabXXnuNwsJCrr322jLnmTRpEpMnT67N0kVERKQOcvk8N7Wtxua5ERERkRpTb+a5EREREXE2hRsRERFxKwo3IiIi4lYUbkRERMStKNyIiIiIW1G4EREREbeicCMiIiJuReFGRERE3IrLZyiubSVzFmZlZbm4EhEREamqku/tqsw93ODCTXZ2NgAJCQkurkRERESqKzs7m5CQkJPu0+CWX7Db7ezbt4+goCAsFotTz52VlUVCQgK7d+/W0g51nD6r+kWfV/2hz6r+qG+flWEYZGdnExcXV2bNyYo0uJYbq9VK48aNa/Q1goOD68V/KKLPqr7R51V/6LOqP+rTZ3WqFpsSGlAsIiIibkXhRkRERNyKwo0T+fj4MGnSJHx8fFxdipyCPqv6RZ9X/aHPqv5w58+qwQ0oFhEREfemlhsRERFxKwo3IiIi4lYUbkRERMStKNyIiIiIW1G4cZIZM2aQmJiIr68vSUlJLF++3NUlSQUmT56MxWIpc2vbtq2ryxLg559/ZtCgQcTFxWGxWFiwYEGZ5w3DYOLEicTGxuLn50e/fv3YsmWLa4qVU35et956a7m/tQEDBrim2AZu6tSp9OjRg6CgIKKiohg8eDCbNm0qs09+fj6jR4+mUaNGBAYGMmTIENLS0lxU8ZlTuHGCuXPnMn78eCZNmsTKlSvp0qUL/fv358CBA64uTSrQoUMH9u/f77gtWbLE1SUJkJubS5cuXZgxY0aFzz/77LO8/PLLvP766yxbtoyAgAD69+9Pfn5+LVcqcOrPC2DAgAFl/tbmzJlTixVKiZ9++onRo0fz+++/891331FUVMSll15Kbm6uY5/777+fL774gnnz5vHTTz+xb98+rrnmGhdWfYYMOWM9e/Y0Ro8e7Xhss9mMuLg4Y+rUqS6sSioyadIko0uXLq4uQ04BMD799FPHY7vdbsTExBjPPfecY9uRI0cMHx8fY86cOS6oUEo78fMyDMMYMWKEcdVVV7mkHjm5AwcOGIDx008/GYZh/i15eXkZ8+bNc+yzYcMGAzCWLl3qqjLPiFpuzlBhYSErVqygX79+jm1Wq5V+/fqxdOlSF1YmldmyZQtxcXE0b96cYcOGkZKS4uqS5BR27NhBampqmb+zkJAQkpKS9HdWh/34449ERUXRpk0b7r77bg4ePOjqkgTIzMwEIDw8HIAVK1ZQVFRU5u+rbdu2NGnSpN7+fSncnKGMjAxsNhvR0dFltkdHR5OamuqiqqQySUlJzJo1i4ULF/Laa6+xY8cOzj//fLKzs11dmpxEyd+S/s7qjwEDBvDuu++SnJzMM888w08//cTAgQOx2WyuLq1Bs9vtjBs3jnPPPZeOHTsC5t+Xt7c3oaGhZfatz39fDW5VcGnYBg4c6LjfuXNnkpKSaNq0KR999BGjRo1yYWUi7uWGG25w3O/UqROdO3emRYsW/Pjjj1x88cUurKxhGz16NOvWrXP7sYZquTlDEREReHh4lBtVnpaWRkxMjIuqkqoKDQ2ldevWbN261dWlyEmU/C3p76z+at68OREREfpbc6ExY8bw5ZdfsnjxYho3buzYHhMTQ2FhIUeOHCmzf33++1K4OUPe3t5069aN5ORkxza73U5ycjK9e/d2YWVSFTk5OWzbto3Y2FhXlyIn0axZM2JiYsr8nWVlZbFs2TL9ndUTe/bs4eDBg/pbcwHDMBgzZgyffvopP/zwA82aNSvzfLdu3fDy8irz97Vp0yZSUlLq7d+XuqWcYPz48YwYMYLu3bvTs2dPpk2bRm5uLiNHjnR1aXKCBx98kEGDBtG0aVP27dvHpEmT8PDw4MYbb3R1aQ1eTk5OmX/V79ixg1WrVhEeHk6TJk0YN24c//rXv2jVqhXNmjXjiSeeIC4ujsGDB7uu6AbsZJ9XeHg4U6ZMYciQIcTExLBt2zYeeughWrZsSf/+/V1YdcM0evRoZs+ezWeffUZQUJBjHE1ISAh+fn6EhIQwatQoxo8fT3h4OMHBwYwdO5bevXvTq1cvF1d/mlx9uZa7eOWVV4wmTZoY3t7eRs+ePY3ff//d1SVJBYYOHWrExsYa3t7eRnx8vDF06FBj69atri5LDMNYvHixAZS7jRgxwjAM83LwJ554woiOjjZ8fHyMiy++2Ni0aZNri27ATvZ55eXlGZdeeqkRGRlpeHl5GU2bNjXuuOMOIzU11dVlN0gVfU6A8c477zj2OXr0qHHPPfcYYWFhhr+/v3H11Vcb+/fvd13RZ8hiGIZR+5FKREREpGZozI2IiIi4FYUbERERcSsKNyIiIuJWFG5ERETErSjciIiIiFtRuBERERG3onAjIiIibkXhRkQaPIvFwoIFC1xdhog4icKNiLjUrbfeisViKXcbMGCAq0sTkXpKa0uJiMsNGDCAd955p8w2Hx8fF1UjIvWdWm5ExOV8fHyIiYkpcwsLCwPMLqPXXnuNgQMH4ufnR/PmzZk/f36Z49euXctFF12En58fjRo14s477yQnJ6fMPjNnzqRDhw74+PgQGxvLmDFjyjyfkZHB1Vdfjb+/P61ateLzzz+v2TctIjVG4UZE6rwnnniCIUOGsHr1aoYNG8YNN9zAhg0bAMjNzaV///6EhYXxxx9/MG/ePL7//vsy4eW1115j9OjR3Hnnnaxdu5bPP/+cli1blnmNKVOmcP3117NmzRouu+wyhg0bxqFDh2r1fYqIk7h65U4RadhGjBhheHh4GAEBAWVu//73vw3DMFc0vuuuu8ock5SUZNx9992GYRjGm2++aYSFhRk5OTmO57/66ivDarU6VqGOi4szHnvssUprAIzHH3/c8TgnJ8cAjG+++cZp71NEao/G3IiIy/Xt25fXXnutzLbw8HDH/d69e5d5rnfv3qxatQqADRs20KVLFwICAhzPn3vuudjtdjZt2oTFYmHfvn1cfPHFJ62hc+fOjvsBAQEEBwdz4MCB031LIuJCCjci4nIBAQHluomcxc/Pr0r7eXl5lXlssViw2+01UZKI1DCNuRGROu/3338v97hdu3YAtGvXjtWrV5Obm+t4/tdff8VqtdKmTRuCgoJITEwkOTm5VmsWEddRy42IuFxBQQGpqalltnl6ehIREQHAvHnz6N69O+eddx4ffPABy5cv5+233wZg2LBhTJo0iREjRjB58mTS09MZO3Yst9xyC9HR0QBMnjyZu+66i6ioKAYOHEh2dja//vorY8eOrd03KiK1QuFGRFxu4cKFxMbGltnWpk0bNm7cCJhXMn344Yfcc889xMbGMmfOHNq3bw+Av78/ixYt4r777qNHjx74+/szZMgQXnzxRce5RowYQX5+Pi+99BIPPvggERERXHvttbX3BkWkVlkMwzBcXYSISGUsFguffvopgwcPdnUpIlJPaMyNiIiIuBWFGxEREXErGnMjInWaes5FpLrUciMiIiJuReFGRERE3IrCjYiIiLgVhRsRERFxKwo3IiIi4lYUbkRERMStKNyIiIiIW1G4EREREbeicCMiIiJu5f8B0SC9HVeWt+sAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = os.path.getsize(resnet34_model2_path_T) / (1024 * 1024)\n",
        "\n",
        "# Calculate the top-1 and top-2 accuracies on the test data\n",
        "top1_accuracy = resnet34_model2.evaluate(X_test, y_test)[1]\n",
        "\n",
        "\n",
        "# Define a function to calculate the top-2 accuracy\n",
        "y_pred = resnet34_model2.predict(X_test)\n",
        "\n",
        "top2_acc = tf.keras.metrics.TopKCategoricalAccuracy(k=2)\n",
        "top2_acc.update_state(y_test, y_pred)\n",
        "top2_accuracy = top2_acc.result().numpy()\n",
        "# print('Top-5 accuracy:', top2_acc.result().numpy())\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the train and validation accuracies\n",
        "train_accuracy = resnet34_model2.evaluate(X_train2, y_train2)[1]\n",
        "val_accuracy = resnet34_model2.evaluate(X_val2, y_val2)[1]\n",
        "\n",
        "# Count the number of trainable and non-trainable parameters in the model\n",
        "num_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in resnet34_model2.trainable_variables])\n",
        "num_non_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in resnet34_model2.non_trainable_variables])\n",
        "num_params = num_trainable_params + num_non_trainable_params\n",
        "\n",
        "# Calculate the depth of the model\n",
        "depth = len(resnet34_model2.layers)\n",
        "\n",
        "# Print the information in the required format\n",
        "print(\"| resnet34_model2 | {:.2f} | {:.4f} | {:.4f} | {:.4f} | {:.4f} | {} | {} |\".format(\n",
        "    model_size, top1_accuracy, top2_accuracy, train_accuracy, val_accuracy, num_params, depth))"
      ],
      "metadata": {
        "id": "qLuQsa_NH3c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60ef377-f30e-459f-a817-d1f295d44c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5519 - accuracy: 0.8330\n",
            "313/313 [==============================] - 3s 7ms/step\n",
            "1329/1329 [==============================] - 12s 9ms/step - loss: 0.1588 - accuracy: 0.9471\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.5246 - accuracy: 0.8424\n",
            "| resnet34_model2 | 244.35 | 0.8330 | 0.9324 | 0.9471 | 0.8424 | 21309002 | 144 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The choice of using grid search versus other optimization techniques depends on \n",
        "# the problem at hand and the resources available. Grid search is a simple and \n",
        "# straightforward method for hyperparameter tuning and is widely used in practice. However, it may not be the most efficient method for high-dimensional hyperparameter spaces or if the number of samples is large.\n",
        "\n",
        "# Other optimization techniques such as random search, Bayesian optimization,\n",
        "# or gradient-based methods may be more efficient in these cases.\n",
        "# It's important to note that no single method is universally better,\n",
        "# and the choice of optimization technique should be based on the specific problem and available resources.\n",
        "\n",
        "# In the case of the soft voting weights for multiple models, grid search may be\n",
        "#  a reasonable choice if the hyperparameter space is not too large."
      ],
      "metadata": {
        "id": "Gh8xa-kCiUmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the weights for soft voting\n",
        "################################################################################\n",
        "################################################################################\n",
        "############################### Grid Search ####################################\n",
        "################################################################################\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "LaGh5fnLiUaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_model3_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/CNN_model3.h5'\n",
        "CNN_model3 = tf.keras.models.load_model(CNN_model3_path_T)\n",
        "\n",
        "\n",
        "resnet50_model3_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/resnet50_model3.h5'\n",
        "resnet50_model3 = tf.keras.models.load_model(resnet50_model3_path_T)\n",
        "\n",
        "\n",
        "resnet34_model2_path_T = '/content/drive/MyDrive/Colab Notebooks/DataSet1/Pedram/resnet34_model2.h5'\n",
        "resnet34_model2 = tf.keras.models.load_model(resnet34_model2_path_T)"
      ],
      "metadata": {
        "id": "LK-Hk3nCndvg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the weights for the three models to be optimized\n",
        "w1_range = np.linspace(0, 1, num=11)\n",
        "w2_range = np.linspace(0, 1, num=11)\n",
        "w3_range = np.linspace(0, 1, num=11)\n",
        "\n",
        "# Define a variable to store the best accuracy found so far\n",
        "best_acc = 0\n",
        "\n",
        "# Loop over all possible combinations of weights\n",
        "for w1 in w1_range:\n",
        "    for w2 in w2_range:\n",
        "        for w3 in w3_range:\n",
        "            print(\"Current weights: w1={:.2f}, w2={:.2f}, w3={:.2f}\".format(w1, w2, w3))\n",
        "            \n",
        "            # Compute the weighted average of the predictions for the current weights\n",
        "            ensemble_preds = w1 * CNN_model3.predict(X_val2) + w2 * resnet50_model3.predict(X_val2) + w3 * resnet34_model2.predict(X_val2)\n",
        "\n",
        "            # Get the predicted class for each input by taking the index of the maximum probability\n",
        "            ensemble_classes = np.argmax(ensemble_preds, axis=1)\n",
        "            \n",
        "            # Compute the accuracy of the ensemble model on the validation set\n",
        "            acc = np.mean(np.argmax(y_val2, axis=1) == ensemble_classes)\n",
        "            \n",
        "            # Update the best accuracy and weights if a better accuracy is found\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                print(\"Current Best Accuracy: {:.2f}%\".format(best_acc * 100))\n",
        "                best_w1, best_w2, best_w3 = w1, w2, w3\n",
        "            \n",
        "            del ensemble_preds\n",
        "            del ensemble_classes\n",
        "\n",
        "# Print the best accuracy and the corresponding weights\n",
        "print(\"Best accuracy: {:.2f}%\".format(best_acc * 100))\n",
        "print(\"Best weights: w1={:.2f}, w2={:.2f}, w3={:.2f}\".format(best_w1, best_w2, best_w3))\n"
      ],
      "metadata": {
        "id": "4ofVpoG6kF_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc925588-069b-43cd-c594-6a3c2976cb8e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.00, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current Best Accuracy: 91.73%\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current Best Accuracy: 92.25%\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current Best Accuracy: 92.81%\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.10, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.20, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.30, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.40, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.50, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 2s 7ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.60, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 2s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 2s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.70, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 2s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.80, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=0.90, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.10, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.20, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.30, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.40, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.50, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.60, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.70, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.80, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=0.90, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.10\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.20\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.30\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.40\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.50\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.60\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.70\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.80\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=0.90\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Current weights: w1=1.00, w2=1.00, w3=1.00\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "Best accuracy: 92.81%\n",
            "Best weights: w1=0.10, w2=0.10, w3=0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best accuracy and the corresponding weights\n",
        "print(\"Best accuracy: {:.2f}%\".format(best_acc * 100))\n",
        "print(\"Best weights: w1={:.2f}, w2={:.2f}, w3={:.2f}\".format(best_w1, best_w2, best_w3))"
      ],
      "metadata": {
        "id": "4LdTpxN0t70b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b05b39-c1ae-435c-d707-77a865abc15d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy: 92.81%\n",
            "Best weights: w1=0.30, w2=0.40, w3=0.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with optimization \n",
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEpnSvg9rxlC",
        "outputId": "2d16ef90-e711-4f1e-a48e-30ff17ffc772"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n",
            "Collecting colorama>=0.4.6 (from bayesian-optimization)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# Define the objective function to be optimized\n",
        "def ensemble_accuracy(w1, w2, w3):\n",
        "    # Compute the weighted average of the predictions for the current weights\n",
        "    ensemble_preds = w1 * CNN_model3.predict(X_val2) + w2 * resnet50_model3.predict(X_val2) + w3 * resnet34_model2.predict(X_val2)\n",
        "\n",
        "    # Get the predicted class for each input\n",
        "    ensemble_classes = np.argmax(ensemble_preds, axis=1)\n",
        "    \n",
        "    # Compute the accuracy of the ensemble model on the validation set\n",
        "    acc = np.mean(np.argmax(y_val2, axis=1) == ensemble_classes)\n",
        "    del ensemble_preds\n",
        "    del ensemble_classes\n",
        "\n",
        "    return acc\n",
        "\n",
        "# Define the search space\n",
        "pbounds = {'w1': (0, 1), 'w2': (0, 1), 'w3': (0, 1)}\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = BayesianOptimization(f=ensemble_accuracy, pbounds=pbounds, random_state=42)\n",
        "\n",
        "# Initialize the optimizer with an initial guess\n",
        "optimizer.probe(\n",
        "    params={'w1': best_w1, 'w2': best_w2, 'w3': best_w3},\n",
        "    lazy=True\n",
        ")\n",
        "\n",
        "# Optimize the weights using Bayesian optimization\n",
        "optimizer.maximize(init_points=5, n_iter=20)\n",
        "\n",
        "# Print the best accuracy and the corresponding weights\n",
        "print(\"Best accuracy: {:.2f}%\".format(optimizer.max['target'] * 100))\n",
        "print(\"Best weights: w1={:.2f}, w2={:.2f}, w3={:.2f}\".format(optimizer.max['params']['w1'], optimizer.max['params']['w2'], optimizer.max['params']['w3']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw5PERuOrxOB",
        "outputId": "ff2ce4a2-ddaa-419f-9f4d-426fef665e7f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   |    w1     |    w2     |    w3     |\n",
            "-------------------------------------------------------------\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m0.9085   \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m0.4      \u001b[0m | \u001b[0m0.3      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0m0.8935   \u001b[0m | \u001b[0m0.3745   \u001b[0m | \u001b[0m0.9507   \u001b[0m | \u001b[0m0.732    \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[95m3        \u001b[0m | \u001b[95m0.9209   \u001b[0m | \u001b[95m0.5987   \u001b[0m | \u001b[95m0.156    \u001b[0m | \u001b[95m0.156    \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0m0.8768   \u001b[0m | \u001b[0m0.05808  \u001b[0m | \u001b[0m0.8662   \u001b[0m | \u001b[0m0.6011   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m0.9008   \u001b[0m | \u001b[0m0.7081   \u001b[0m | \u001b[0m0.02058  \u001b[0m | \u001b[0m0.9699   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[95m6        \u001b[0m | \u001b[95m0.9211   \u001b[0m | \u001b[95m0.8324   \u001b[0m | \u001b[95m0.2123   \u001b[0m | \u001b[95m0.1818   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[95m7        \u001b[0m | \u001b[95m0.9248   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m0.8131   \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m0.9179   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.523    \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m0.09613  \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m0.8845   \u001b[0m | \u001b[0m0.4191   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.02244  \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m0.914    \u001b[0m | \u001b[0m0.6942   \u001b[0m | \u001b[0m0.4892   \u001b[0m | \u001b[0m0.6263   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m0.9208   \u001b[0m | \u001b[0m0.6077   \u001b[0m | \u001b[0m0.1317   \u001b[0m | \u001b[0m0.1943   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m0.8559   \u001b[0m | \u001b[0m0.01421  \u001b[0m | \u001b[0m0.3043   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m0.9113   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m0.9159   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.4269   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0m0.874    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0m0.8812   \u001b[0m | \u001b[0m0.3083   \u001b[0m | \u001b[0m0.8611   \u001b[0m | \u001b[0m0.09384  \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m0.9216   \u001b[0m | \u001b[0m0.9951   \u001b[0m | \u001b[0m0.01285  \u001b[0m | \u001b[0m0.6992   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m0.9145   \u001b[0m | \u001b[0m0.6925   \u001b[0m | \u001b[0m0.4915   \u001b[0m | \u001b[0m0.617    \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0m0.9225   \u001b[0m | \u001b[0m0.6124   \u001b[0m | \u001b[0m0.06151  \u001b[0m | \u001b[0m0.4249   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[95m21       \u001b[0m | \u001b[95m0.9271   \u001b[0m | \u001b[95m0.6436   \u001b[0m | \u001b[95m0.5939   \u001b[0m | \u001b[95m0.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m0.8925   \u001b[0m | \u001b[0m0.4123   \u001b[0m | \u001b[0m0.5831   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m0.9173   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m0.8732   \u001b[0m | \u001b[0m0.3363   \u001b[0m | \u001b[0m0.05813  \u001b[0m | \u001b[0m0.8785   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m0.9072   \u001b[0m | \u001b[0m0.6655   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.3162   \u001b[0m |\n",
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m0.9003   \u001b[0m | \u001b[0m0.338    \u001b[0m | \u001b[0m0.4866   \u001b[0m | \u001b[0m0.6017   \u001b[0m |\n",
            "=============================================================\n",
            "Best accuracy: 92.71%\n",
            "Best weights: w1=0.64, w2=0.59, w3=0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from BayesianOptimization\n",
        "f_w1=0.64\n",
        "f_w2=0.59\n",
        "f_w3=0.00\n",
        "\n",
        "# # from grid search\n",
        "# f_w1=best_w1\n",
        "# f_w2=best_w2\n",
        "# f_w3=best_w3\n",
        "\n",
        "# Compute the weighted average of the predictions for the current weights\n",
        "ensemble_preds = f_w1 * CNN_model3.predict(X_val2) + f_w2 * resnet50_model3.predict(X_val2) + f_w3 * resnet34_model2.predict(X_val2)\n",
        "\n",
        "# Get the predicted class for each input by taking the index of the maximum probability\n",
        "ensemble_classes = np.argmax(ensemble_preds, axis=1)\n",
        "            \n",
        "# Compute the accuracy of the ensemble model on the validation set\n",
        "acc = np.mean(np.argmax(y_val2, axis=1) == ensemble_classes)\n",
        "\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xRt4y0CaNcC",
        "outputId": "ec33a135-3ece-481c-e925-b4a9a441943f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 1s 3ms/step\n",
            "235/235 [==============================] - 1s 6ms/step\n",
            "235/235 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9270666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from BayesianOptimization\n",
        "f_w1=0.64\n",
        "f_w2=0.59\n",
        "f_w3=0.00\n",
        "\n",
        "# # from grid search\n",
        "# f_w1=best_w1\n",
        "# f_w2=best_w2\n",
        "# f_w3=best_w3\n",
        "\n",
        "# Compute the weighted average of the predictions for the current weights\n",
        "ensemble_preds = f_w1 * CNN_model3.predict(X_test) + f_w2 * resnet50_model3.predict(X_test) + f_w3 * resnet34_model2.predict(X_test)\n",
        "\n",
        "# Get the predicted class for each input by taking the index of the maximum probability\n",
        "ensemble_classes = np.argmax(ensemble_preds, axis=1)\n",
        "            \n",
        "# Compute the accuracy of the ensemble model on the validation set\n",
        "acc = np.mean(np.argmax(y_test, axis=1) == ensemble_classes)\n",
        "\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85m3bhaLpaUK",
        "outputId": "d325aef3-5ed5-480f-bbee-d0d9fb8826e1"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "313/313 [==============================] - 2s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8903"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input tensor\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "# Get outputs from the three models\n",
        "output1 = CNN_model3(inputs)\n",
        "output2 = resnet50_model3(inputs)\n",
        "output3 = resnet34_model2(inputs)\n",
        "\n",
        "# Soft voting\n",
        "output = (output1 * f_w1) + (output2 * f_w2) + (output3 * f_w3)\n",
        "\n",
        "# Define new model\n",
        "ensemble_model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "# Compile model\n",
        "optimizer = keras.optimizers.Adam()\n",
        "ensemble_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "test_loss, test_acc = ensemble_model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "val_loss, val_acc = ensemble_model.evaluate(X_val2, y_val2)\n",
        "print('Val accuracy:', val_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEJErASgWkIO",
        "outputId": "b06b3808-8868-4842-a6b6-91d6c72b7b0f"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 7s 13ms/step - loss: 0.4010 - accuracy: 0.8903\n",
            "Test accuracy: 0.8902999758720398\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.3021 - accuracy: 0.9271\n",
            "Val accuracy: 0.9270666837692261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2wCriittqqWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4AeNuL1qqJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# since the weight for this model is zero 0 * os.path.getsize(resnet34_model2_path_T)\n",
        "model_size = (os.path.getsize(CNN_model3_path_T) +  os.path.getsize(resnet50_model3_path_T)  + 0 * os.path.getsize(resnet34_model2_path_T) )/ (1024 * 1024)\n",
        "\n",
        "# Calculate the top-1 and top-2 accuracies on the test data\n",
        "top1_accuracy = ensemble_model.evaluate(X_test, y_test)[1]\n",
        "\n",
        "# Define a function to calculate the top-2 accuracy\n",
        "y_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "top2_acc = tf.keras.metrics.TopKCategoricalAccuracy(k=2)\n",
        "top2_acc.update_state(y_test, y_pred)\n",
        "top2_accuracy = top2_acc.result().numpy()\n",
        "# print('Top-2 accuracy:', top2_acc.result().numpy())\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the train and validation accuracies\n",
        "train_accuracy = ensemble_model.evaluate(X_train2, y_train2)[1]\n",
        "val_accuracy = ensemble_model.evaluate(X_val2, y_val2)[1]\n",
        "\n",
        "# Count the number of trainable and non-trainable parameters in the model\n",
        "num_trainable_params1 = np.sum([np.prod(v.get_shape().as_list()) for v in CNN_model3.trainable_variables])\n",
        "num_non_trainable_params1 = np.sum([np.prod(v.get_shape().as_list()) for v in CNN_model3.non_trainable_variables])\n",
        "\n",
        "num_trainable_params2 = np.sum([np.prod(v.get_shape().as_list()) for v in resnet50_model3.trainable_variables])\n",
        "num_non_trainable_params2 = np.sum([np.prod(v.get_shape().as_list()) for v in resnet50_model3.non_trainable_variables])\n",
        "\n",
        "# since the weight for resnet34_model2 is zero\n",
        "num_trainable_params3 = 0\n",
        "num_non_trainable_params3 = 0\n",
        "# parameter from optimization\n",
        "opt_par = 3\n",
        "\n",
        "num_params = num_trainable_params1 + num_non_trainable_params1 + num_trainable_params2 + num_non_trainable_params2 + num_trainable_params3 + num_non_trainable_params3 + opt_par\n",
        "\n",
        "# Calculate the depth of the model\n",
        "depth1 = len(CNN_model3.layers)\n",
        "depth2 = len(resnet50_model3.layers)\n",
        "depth = max (depth1, depth2)\n",
        "\n",
        "# Print the information in the required format\n",
        "print(\"| ensemble_model | {:.2f} | {:.4f} | {:.4f} | {:.4f} | {:.4f} | {} | {} |\".format(\n",
        "    model_size, top1_accuracy, top2_accuracy, train_accuracy, val_accuracy, num_params, depth))"
      ],
      "metadata": {
        "id": "sGL5h4x2lUui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9964d323-9c1a-48cb-ad11-3f8b87c7c69e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4010 - accuracy: 0.8903\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "1329/1329 [==============================] - 18s 14ms/step - loss: 0.0828 - accuracy: 0.9999\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.3021 - accuracy: 0.9271\n",
            "| ensemble_model | 377.27 | 0.8903 | 0.9563 | 0.9999 | 0.9271 | 32906007 | 184 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finish!! Finally :("
      ],
      "metadata": {
        "id": "H9ulKzQ78WZA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}